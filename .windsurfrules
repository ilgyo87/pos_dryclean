1. This is an amplify app in react native gen 2
2. I am going to give you most of the docs from amplify so you can create better code, each page begins with - and ends with - on the same line, for example: '- title -' :
 
- Set up Amplify Auth -
Amplify Auth is powered by Amazon Cognito. Cognito is a robust user directory service that handles user registration, authentication, account recovery, and other operations. Review the concepts to learn more.

To get started with defining your authentication resource, open or create the auth resource file:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
})
By default, your auth resource is scaffolded using email as the default login mechanism. You can also configure your auth resource to allow signing in with phone numbers or an external provider such as Google, Facebook, Amazon, or Sign in with Apple.

Note: At a minimum you will need to pass a loginWith value to set up how your users sign in to your app. Signing in with email and password is configured by default if you do not provide any value.

Deploy auth resource
After you have chosen and defined your authentication resource, run the following command to create your resource in your personal cloud sandbox.

Terminal
npx ampx sandbox
After a successful deployment, this command also generates an outputs file (amplify_outputs.json) to enable your frontend app to connect to your backend resources. The values you configure in your backend authentication resource are set in the generated outputs file to automatically configure the frontend Authenticator connected component.

Connect your application code to your auth resource
Creating and correctly implementing the sign-in flow can be challenging and time-consuming. Amplify's Authenticator UI component streamlines this by enabling you to rapidly build the entire authentication flow for your app. The component works seamlessly with configuration in amplify/auth/resource.ts to automatically connect with your backend resources.

Amplify has pre-built UI components for React, Vue, Angular, React Native, Swift, Android, and Flutter. In this guide, we are focusing on those for web applications.

First, install the @aws-amplify/ui-react-native library:

Terminal
npm add \
  @aws-amplify/react-native \
  @aws-amplify/ui-react-native \
  aws-amplify \
  @react-native-community/netinfo \
  @react-native-async-storage/async-storage \
  react-native-safe-area-context@^4.2.5 \
  react-native-get-random-values
If your project will support Federated Sign In using the React Native Authenticator the @aws-amplify/rtn-web-browser package is also required:

Terminal
npm add @aws-amplify/rtn-web-browser
Then install the iOS cocoapods by running:

Terminal
npx pod-install
For calling native libraries and platform dependencies from Expo, you need to run the prebuild command for generating the folders for related platforms.

Terminal
npx expo prebuild
Next, update the App.tsx file with the following to set up the authentication flow:

import React from "react";
import { Button, View, StyleSheet } from "react-native";
import { Amplify } from "aws-amplify";
import { Authenticator, useAuthenticator } from "@aws-amplify/ui-react-native";
import outputs from "./amplify_outputs.json";

Amplify.configure(outputs);

const SignOutButton = () => {
  const { signOut } = useAuthenticator();

  return (
    <View style={styles.signOutButton}>
      <Button title="Sign Out" onPress={signOut} />
    </View>
  );
};

const App = () => {
  return (
    <Authenticator.Provider>
      <Authenticator>
        <SignOutButton />
      </Authenticator>
    </Authenticator.Provider>
  );
};

const styles = StyleSheet.create({
  signOutButton: {
    alignSelf: "flex-end",
  },
});

export default App;
Once you add the Authenticator component to your app, you can test the sign-up, sign-in, and sign-out functionality. You can also customize the Authenticator connected component to adjust colors and styling as needed.

Next steps
Now that you have completed setting up authentication in your Amplify app with email and password, you may also want to add some additional features. We recommend you learn more about:

- Concepts -
Amplify helps you secure your application while providing an easy sign-in experience for your users. This experience is influenced by your security strategy. This security strategy includes the authentication method, security credentials, and enabling additional verification when needed.

Authentication is a process to validate who you are (abbreviated as AuthN). The system that does this validation is referred to as an Identity Provider or IdP. This can be your own self-hosted IdP or a cloud service. Oftentimes, this IdP is an external provider such as Apple, Facebook, Google, or Amazon.
Authorization is the process of validating what you can access (abbreviated as AuthZ). This is sometimes done by looking at tokens with custom logic, predefined rules, or signed requests with policies.
Common authentication methods and associated risks include:

External provider federation which enables easier access for your users but shares data with third parties.
You can improve security credentials and verification for these authentication methods by:

Modifying the default password policy to ensure your users create stronger passwords.
Requiring additional contact information from users before they can reset passwords.
Enabling multi-factor authentication (MFA) which adds a layer of security at sign-in but may also add friction for your users.
What is Amazon Cognito?
Amplify Auth is powered by Amazon Cognito. Amazon Cognito is an identity and access management service, enabling you to secure your web or mobile applications, and is comprised of two services:

Amazon Cognito User Pools is a full-featured user directory service to handle user registration, authentication, and account recovery
Amazon Cognito Federated Identities or Identity Pools is a service used to authorize your users to interact with other AWS services
Amplify interfaces with User Pools to store your user information, including federation with other OpenID providers like Apple, Facebook, Google, or Amazon, and leverages federated identities to manage user access to AWS resources.

Authorization is often done in one of two ways:

Clients pass the tokens to the backend that perform custom logic to allow or deny actions
Clients sign the requests and the backend validates the signature, allowing or denying actions depending on predefined policy. The predefined rules, known as IAM access policies, are automatically configured by Amplify.
The first is a common authorization method for HTTP or GraphQL APIs, while the second is necessary for interfacing with AWS services such as Amazon S3, Amazon Pinpoint, and others.

Before you build
Amazon Cognito can be customized based on your security strategy for authentication. However, some initial configuration options cannot be changed after the backend resources are configured:

User attributes that are used to identify your individual users (such as email and phone) cannot be renamed or deleted.
Sign-in methods (including username, email, and phone) cannot be added or changed after the initial configuration. This includes both defining which attributes are used to sign in and which attributes are required. Required attributes must have a value for all users once set.
Verification methods (including username and email) are the same as required attributes and cannot be removed once configured.
The sub attribute is a unique identifier within each user pool that cannot be modified and can be used to index and search users.
If MFA is set to required with phone number for all users, you will need to include MFA setup (i.e. mandating phone number) when users sign up.
Visit the Amazon Cognito documentation for more details on these settings, including User pool attributes and Adding MFA to a user pool.

- Email -
By default Amplify Auth is scaffolded with email as the default method for user sign-in.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
})
This will configure an email attribute that is required for sign-up and cannot be changed.

- Phone -
By default Amplify Auth is scaffolded with email as the default method for user sign-in, however this can be changed or extended to also allow your users to sign in using their phone number.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    phone: true,
  },
})
This will configure the phone_number attribute that is required for sign-up and cannot be changed.

- Passwordless -
Amplify supports the use of passwordless authentication flows using the following methods:

SMS-based one-time password (SMS OTP)
Email-based one-time password (Email OTP)
WebAuthn passkey
Passwordless authentication removes the security risks and user friction associated with traditional passwords.

Warning: Passwordless configuration is currently not available in defineAuth. We are currently working towards enabling support for passwordless configurations. Visit the GitHub issue to track the progress

Learn how to implement passwordless sign-in flows by overriding the Cognito UserPool to enable the sign-in methods below.

SMS OTP
SMS-based authentication uses phone numbers as the identifier and text messages as the verification channel. At a high level end users will perform the following steps to authenticate:

User enters their phone number to sign up/sign in
They receive a text message with a time-limited code
After the user enters their code they are authenticated
SMS-based one-time password requires your Amazon Cognito user pool to be configured to use Amazon Simple Notification Service (SNS) to send text messages. Learn how to configure your auth resource with SNS.

Learn more about using SMS OTP in your application code.

Email OTP
Email-based authentication uses email addresses for identification and verification. At a high level end users will perform the following steps to authenticate:

User enters their email address to sign up/sign in
They receive an email message with a time-limited code
After the users enters their code they are authenticated
Email-based one-time password requires your Amazon Cognito user pool to be configured to use Amazon Simple Email Service (SES) to send email messages. Learn how to configure your auth resource with SES.

Learn more about using email OTP in your application code.

WebAuthn Passkey
WebAuthn uses biometrics or security keys for authentication, leveraging device-specific security features. At a high level end users will perform the following steps to authenticate:

User chooses to register a passkey
Their device prompts for biometric/security key verification
For future logins, they'll authenticate using the same method
Learn more about using WebAuthn passkeys in your application code.

Managing credentials
Learn more about managing WebAuthn credentials.

- User attributes -
Amplify Auth stores user profile information in user attributes. When the default method for user sign-in, Amplify Auth will automatically configure an email or phoneNumber attribute that is required for sign-in.

To extend a user profile beyond the default email or phoneNumber attribute that is automatically configured when specified in your auth resource's loginWith property, you can configure attributes with the userAttributes property:

Warning: After you create your auth resource, you cannot switch an attribute between required and not required.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    // this configures a required "email" attribute
    email: true,
  },
  userAttributes: {
    // specify a "birthdate" attribute
    birthdate: {
      mutable: true,
      required: false,
    }
  },
})
Standard attributes
User attributes are defined as Cognito Standard Attributes. Attributes can be configured to be required for user sign-up in addition to whether the values are mutable. When configuring your resource to allow your users to login with email, an email must be specified for user sign-up and cannot be changed later. However additional attributes can be configured to be optional, and mutable after sign-up.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend";

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  userAttributes: {
    // Maps to Cognito standard attribute 'address'
    address: {
      mutable: true,
      required: true,
    },
    // Maps to Cognito standard attribute 'birthdate'
    birthdate: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'email'
    email: {
      mutable: true,
      required: true,
    },
    // Maps to Cognito standard attribute 'family_name'
    familyName: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'gender'
    gender: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'given_name'
    givenName: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'locale'
    locale: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'middle_name'
    middleName: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'name'
    fullname: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'nickname'
    nickname: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'phone_number'
    phoneNumber: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'picture'
    profilePicture: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'preferred_username'
    preferredUsername: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'profile'
    profilePage: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'zoneinfo'
    timezone: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'updated_at'
    lastUpdateTime: {
      mutable: true,
      required: false,
    },
    // Maps to Cognito standard attribute 'website'
    website: {
      mutable: true,
      required: false,
    },
  },
});
Custom attributes
In addition to the provided standard attributes, you can configure Custom Attributes. These are attributes that are typically unique to your use case, such as a tenant ID or a user's display name. Custom attributes are identified by the custom: prefix:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    // this configures a required "email" attribute
    email: true,
  },
  userAttributes: {
    "custom:display_name": {
      dataType: "String",
      mutable: true,
      maxLen: 16,
      minLen: 1,
    },
    "custom:favorite_number": {
      dataType: "Number",
      mutable: true,
      min: 1,
      max: 100,
    },
    "custom:is_beta_user": {
      dataType: "Boolean",
      mutable: true,
    },
    "custom:started_free_trial": {
      dataType: "DateTime",
      mutable: true,
    },
  },
})
Unlike standard attributes, custom attributes cannot natively be required for sign-up, however can be codified to require some value by validating user attributes upon sign-up with a pre sign-up trigger.

Custom attributes can also be configured with specific data types. The following data types are supported:

String
Number
Boolean
DateTime
Shown in the snippet above, String and Number can be assigned minimum and maximum constraints. This is useful to defer simple validations to the underlying service, although does not extend to complex validations such as matching against a regular expression.

- Multi-factor authentication - 
Amplify Auth supports multi-factor authentication (MFA) for user sign-in flows. MFA is an extra layer of security used to make sure that users trying to gain access to an account are who they say they are. It requires users to provide additional information to verify their identity. Amplify Auth supports MFA with time-based one-time passwords (TOTP), text messages (SMS), and email.

In this guide we will review how you can set up MFA with each of these methods and the discuss tradeoffs between them to help you choose the right setup for your application. We will also review how to set up MFA to remember a device and reduce sign-in friction for your users.

Configure multi-factor authentication
Use defineAuth to enable MFA for your app. The example below is setting up MFA with TOTP but not SMS as you can see that the phone number is not a required attribute.

If you plan to use SMS for MFA, then the phoneNumber attribute must be marked as required in your userAttributes. Note that if you have loginWith.phone as true this attribute will automatically be marked as required.
If you plan to use email for MFA, then the email attribute must also be true must be marked as required in your userAttributes. Note that if you have loginWith.email as true this attribute will automatically be marked as required.
amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true
  },
  multifactor: {
    mode: 'OPTIONAL',
    totp: true,
  },
  userAttributes: {
    phoneNumber: { 
      required: true
    }
  }
});
Note: Email-based MFA is currently not supported with defineAuth. We are working towards supporting this feature. For more information, visit the feature request in GitHub.

To take advantage of this feature with an Amplify generated backend, the underlying CDK construct can be extended manually. See overriding Cognito User Pool multi-factor authentication options for more information.

When MFA is REQUIRED with SMS in your backend auth resource, you will need to pass the phone number during sign-up API call. If you are using the email or username as the primary sign-in mechanism, you will need to pass the phone_number attribute as a user attribute.

Similarly, when MFA is REQUIRED with email as your delivery mechanism, you will need to pass an email address during the sign-up API call. If you are using phoneNumber or username as the primary sign-in mechanism, you will need to pass the email attribute as a user attribute.

This configuration may change depending on the combination of MFA methods enabled in your user pool.

Understand your MFA options
When enabling MFA you will have two key decisions to make:

MFA enforcement: As part of this setup you will determine how MFA is enforced. If you require MFA by setting MFA mode to REQUIRED, all your users will need to complete MFA to sign in. If you keep it OPTIONAL, your users will have the choice whether to enable MFA or not for their account.
MFA methods: You will also specify which MFA method you are using: TOTP (Time-based One-time Password), SMS (text message), email, or any combination thereof. We recommend that you use TOTP-based MFA as it is more secure and you can reserve SMS or email for account recovery.
Learn more
Compare TOTP, SMS, and EMAIL MFA methods
If multiple MFA methods are enabled for the user, and none are set as preferred, the signIn API will return CONTINUE_SIGN_IN_WITH_MFA_SELECTION as the next step in the auth flow. During this scenario, the user should be prompted to select the MFA method they want to use to sign in and their preference should be passed to confirmSignIn.

import { confirmSignIn, type SignInOutput } from 'aws-amplify/auth';

function handleSignInNextSteps(output: SignInOutput) {
	const { nextStep } = output;
	switch (nextStep.signInStep) {
		// ...
		case 'CONTINUE_SIGN_IN_WITH_MFA_SELECTION':
			const allowedMFATypes = nextStep.allowedMFATypes;
			const mfaType = promptUserForMFAType(allowedMFATypes);
		case 'CONFIRM_SIGN_IN_WITH_SMS_CODE':
			// prompt user to enter otp code delivered via SMS
			break;
		case 'CONFIRM_SIGN_IN_WITH_TOTP_CODE':
			// prompt user to enter otp code from their authenticator app
			break;
		case 'CONFIRM_SIGN_IN_WITH_EMAIL_CODE':
			// prompt user to enter otp code delivered via EMAIL
			break;
		// ...
	}
}

type MfaType = 'SMS' | 'TOTP' | 'EMAIL';

function promptUserForMFAType(allowedMFATypes?: MfaType[]): MfaType {
	// Prompt user to select MFA type
}

async function handleMFASelection(mfaType: MfaType) {
	try {
		const output = await confirmSignIn({
			challengeResponse: mfaType,
		});
		handleSignInNextSteps(output);
	} catch (error) {
		console.log(error);
	}
}
Multi-factor authentication with SMS
Once you have setup SMS as your second layer of authentication with MFA as shown above, your users will get an authentication code via a text message to complete sign-in after they sign in with their username and password.

Warning: In order to send SMS authentication codes, you must request an origination number. Learn more about configuring your auth resource for production workloads.

Enable SMS MFA during sign-up
You will need to pass phone_number as a user attribute to enable SMS MFA for your users during sign-up. However, if the primary sign-in mechanism for your Cognito resource is phone_number (without enabling username), then you do not need to pass it as an attribute.

By default, you have to verify a user account after they sign up using the confirmSignUp API, which will send a one-time password to the user's phone number or email, depending on your Amazon Cognito configuration.

Manage SMS MFA during sign-in
After a user signs in, if they have MFA enabled for their account, a challenge will be returned that you would need to call the confirmSignIn API where the user provides their confirmation code sent to their phone number.

If MFA is ON or enabled for the user, you must call confirmSignIn with the OTP sent to their phone.

After a user has been signed in, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.

Multi-factor authentication with TOTP
You can use Time-based One-Time Password (TOTP) for multi-factor authentication (MFA) in your web or mobile applications. The Amplify Auth category includes support for TOTP setup and verification using authenticator apps, offering an integrated solution and enhanced security for your users. These apps, such as Google Authenticator, Microsoft Authenticator, have the TOTP algorithm built-in and work by using a shared secret key and the current time to generate short-lived, six digit passwords.

Set up TOTP for a user
The TOTP code can be obtained from the user via a text field or any other means. Once the user provides the TOTP code, call confirmSignIn with the TOTP code as the challengeResponse parameter.

After a user has been signed in, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.

Enable TOTP after a user is signed in
TOTP MFA can be set up after a user has signed in. This can be done when the following conditions are met:

MFA is marked as Optional or Required in your user pool.
TOTP is marked as an enabled MFA method in your user pool.
TOTP can be set up by calling the setUpTOTP and verifyTOTPSetup APIs in the Auth category.

Invoke the setUpTOTP API to generate a TOTPSetupDetails object which should be used to configure an Authenticator app like Microsoft Authenticator or Google Authenticator. TOTPSetupDetails provides a helper method called getSetupURI which generates a URI that can be used, for example, in a button to open the user's installed Authenticator app. For more advanced use cases, TOTPSetupDetails also contains a sharedSecret which can be used to either generate a QR code or be manually entered into an Authenticator app.

that contains the sharedSecret which will be used to either to generate a QR code or can be manually entered into an Authenticator app.

Once the Authenticator app is set up, the user must generate a TOTP code and provide it to the library. Pass the code to verifyTOTPSetup to complete the TOTP setup process.

After TOTP setup is complete, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.

Recover from a lost TOTP device
If a user loses access to their TOTP device, they will need to contact an administrator to get help accessing their account. Based on the Cognito user pool configuration, the administrator can use the AdminSetUserMFAPreference to either change the MFA preference to a different MFA method or to disable MFA for the user.

In a scenario where MFA is marked as "Required" in the Cognito User Pool and another MFA method is not set up, the administrator would need to first initiate an AdminUpdateUserAttributes call and update the user's phone number attribute. Once this is complete, the administrator can continue changing the MFA preference to SMS as suggested above.

Multi-factor authentication with EMAIL
Once you have setup email as your second layer of authentication with MFA as shown above, your users will get an authentication code via email to complete sign-in after they sign in with their username and password.

In order to send email authentication codes, the following prerequisites must be met:

Cognito must be configured to send emails using Amazon Simple Email Service (Amazon SES).
Advanced Security Features (ASF) must be enabled in your user pool.
If account recovery is enabled in Cognito, the delivery method for recovery messages cannot be set to Email only
Additional pricing applies for ASF. Learn more about Amazon Cognito pricing

Enable EMAIL MFA during sign-up
You will need to pass email as a user attribute to enable email MFA for your users during sign-up. However, if the primary sign-in mechanism for your Cognito resource is already email (without enabling username), then you do not need to pass it as an attribute.

By default, you have to verify a user account after they sign up using the confirmSignUp API. Following the initial signUp request, a one-time passcode will be sent to the user's phone number or email, depending on your Amazon Cognito configuration.

Manage EMAIL MFA during sign-in
After a user signs in, if they have MFA enabled for their account, a challenge will be issued that requires calling the confirmSignIn API with the user provided confirmation code sent to their email address.

If MFA is ON or enabled for the user, you must call confirmSignIn with the OTP sent to their email address.

After a user has been signed in, call updateMFAPreference to record the MFA type as enabled for the user and optionally set it as preferred so that subsequent logins default to using this MFA type.

Set up a user's preferred MFA method
Depending on your user pool configuration, it's possible that multiple MFA options may be available to a given user. In order to avoid requiring your users to select an MFA method each time they sign-in to your application, Amplify provides two utility APIs to manage an individual user's MFA preferences.

Fetch the current user's MFA preferences
Invoke the following API to get the current MFA preference and enabled MFA types, if any, for the current user.

Update the current user's MFA preferences
Invoke the following API to update the MFA preference for the current user.

Only one MFA method can be marked as preferred at a time. If the user has multiple MFA methods enabled and tries to mark more than one MFA method as preferred, the API will throw an error.

Remember a device
Remembering a device is useful in conjunction with MFA because it allows the second factor requirement to be automatically met when your user signs in on that device and reduces friction in their sign-in experience. By default, this feature is turned off.

Note: The device tracking and remembering features are not available if any of the following conditions are met:

the federated OAuth flow with Cognito User Pools or Hosted UI is used, or
when the signIn API uses the USER_PASSWORD_AUTH as the authFlowType.
Configure device tracking
You can configure device tracking with deviceTracking construct.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';

const backend = defineBackend({
  auth,
  data
});

const { cfnUserPool } = backend.auth.resources.cfnResources;

cfnUserPool.addPropertyOverride('DeviceConfiguration', {
  ChallengeRequiredOnNewDevice: true,
  DeviceOnlyRememberedOnUserPrompt: false
});
Learn more
Understand key terms used for tracking devices

- External identity providers - 
Before you configure external sign-in with Amplify Auth you will need to set up your developer account with each provider you are using.

Note: Amazon Cognito provides first class support for Facebook Login, Google Sign-In, Login with Amazon, and Sign in with Apple for seamless setup. However you can configure other Identity Providers that support SAML or OpenID Connect (OIDC).

Warning: When configuring external sign-in it's important to exercise caution when designating attributes as "required." Different external identity providers have varied scopes in terms of the information they respond back to Cognito with. User pool attributes that are initially set up as "required" cannot be changed later, and may require you to migrate the users or create a new user pool.

Facebook Login
Google Sign-In
Login with Amazon
Sign in with Apple
Create a developer account with Facebook.
Sign in with your Facebook credentials.
Choose My Apps from the top navigation bar, and on the page that loads choose Create App. Create App button in the My Apps page of the Facebook developer account.
For your use case, choose Set up Facebook Login. Set up Facebook Login option selected from list.
For platform, choose Website and select No, I'm not building a game.
Give your Facebook app a name and choose Create app. Form fields for the Facebook create app form.
On the left navigation bar, choose Settings and then Basic. App ID and App Secret in the basic settings tab of the dashboard.
Note the App ID and the App Secret. You will use them in the next section in the CLI flow.
Your developer accounts with the external providers are now set up and you can return to the Amplify specific configuration.

Configure external sign-in backend
In amplify/auth/resource.ts the external providers need to be added.

The following is an example of how you would set up access to all of the external providers supported by Amplify Auth. Please note you will need to configure your callbackUrls and logoutUrls URLs for your application, which will inform your backend resources how to behave when initiating sign in and sign out operations in your app.

Secrets must be created manually with ampx sandbox secret for use with cloud sandbox, or via the Amplify Console for branch environments.

amplify/auth/resource.ts
import { defineAuth, secret } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      google: {
        clientId: secret('GOOGLE_CLIENT_ID'),
        clientSecret: secret('GOOGLE_CLIENT_SECRET')
      },
      signInWithApple: {
        clientId: secret('SIWA_CLIENT_ID'),
        keyId: secret('SIWA_KEY_ID'),
        privateKey: secret('SIWA_PRIVATE_KEY'),
        teamId: secret('SIWA_TEAM_ID')
      },
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET')
      },
      facebook: {
        clientId: secret('FACEBOOK_CLIENT_ID'),
        clientSecret: secret('FACEBOOK_CLIENT_SECRET')
      },
      callbackUrls: ["myapp://callback/"],
      logoutUrls: ["myapp://signout/"],
    }
  }
});
You need to now inform your external provider of the newly configured authentication resource and its OAuth redirect URI:

Facebook Login
Google Sign-In
Login with Amazon
Sign in with Apple
Sign In to your Facebook developer account with your Facebook credentials.

Choose My Apps from the top navigation bar, and on the Apps page, choose your app you created before.

On the left navigation bar, choose Products. Add Facebook Login if it isn't already added.

If already added, choose Settings under the Configure dropdown. The Settings option is circled from the configure dropdown.

Under Valid OAuth Redirect URIs type your user pool domain with the /oauth2/idpresponse endpoint.

https://<your-user-pool-domain>/oauth2/idpresponse

Userpool domain is pasted into the text field with /oauth2/ endpoint.

Save your changes.
Learn more about using social identity providers with user pool

Customizing scopes for retrieving user data from external providers
You can determine the pieces of data you want to retrieve from each external provider when setting them up in the amplify/auth/resource.ts file using scopes.

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),
        scopes: ['email']
      },
      callbackUrls: ["myapp://callback/"],
      logoutUrls: ["myapp://signout/"],
    }
  }
});
Attribute mapping
Identity provider (IdP) services store user attributes in different formats. When using external IdPs with Amazon Cognito user pools, attribute mapping allows you to standardize these varying formats into a consistent schema.

Learn more about mapping IdP attributes to user pool profiles and tokens.

Note: When a federated user signs in to your application, a mapping must be present for each attribute that your user pool requires. Additionally, you must also ensure that the target of each attribute mapping is mutable. Amazon Cognito will attempt to update each mapped attribute when a user signs in regardless of whether the latest value already matches the existing information. If these criteria are not met, Amazon Cognito will return an error and the sign in attempt will fail.

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      loginWithAmazon: {
        clientId: secret('LOGINWITHAMAZON_CLIENT_ID'),
        clientSecret: secret('LOGINWITHAMAZON_CLIENT_SECRET'),
        attributeMapping: {
          email: 'email'
        }
      },
      callbackUrls: ["myapp://callback/"],
      logoutUrls: ["myapp://signout/"],
    }
  }
});
Configure OIDC provider
To setup a OIDC provider, you can configure them in your amplify/auth/resource.ts file. For example, if you would like to setup a Microsoft EntraID provider, you can do so as follows:

amplify/auth/resource.ts
import { defineAuth, secret } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      oidc: [
        {
          name: 'MicrosoftEntraID',
          clientId: secret('MICROSOFT_ENTRA_ID_CLIENT_ID'),
          clientSecret: secret('MICROSOFT_ENTRA_ID_CLIENT_SECRET'),
          issuerUrl: '<your-issuer-url>',
        },
      ],
      callbackUrls: ["myapp://callback/"],
      logoutUrls: ["myapp://signout/"],
    },
  },
});
Configure SAML provider
To setup a SAML provider, you can configure them in your amplify/auth/resource.ts file. For example, if you would like to setup a Microsoft EntraID provider, you can do so as follows:

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      saml: {
        name: 'MicrosoftEntraIDSAML',
        metadata: {
          metadataContent: '<your-url-hosting-saml-metadata>', // or content of the metadata file
          metadataType: 'URL', // or 'FILE'
        },
      },
      callbackUrls: ["myapp://callback/"],
      logoutUrls: ["myapp://signout/"],
    },
  },
});
Set up your frontend
If you are using the Authenticator component with Amplify, this feature works without any additional code. The guide below is for writing your own implementation.

Use the signInWithRedirect API to initiate sign-in with an external identity provider.

src/my-client-side-js.js
import { signInWithRedirect } from 'aws-amplify/auth';

signInWithRedirect({
  provider: 'Apple'
});
Redirect URLs
Sign in & Sign out redirect URL(s) are used to redirect end users after the sign in or sign out operation has occurred. You may want to specify multiple URLs for various use-cases such as having different URLs for development/ production or redirect users to an intermediate URL before returning them to the app.

Specifying a redirect URL on sign out
If you have multiple sign out redirect URLs configured, you may choose to override the default behavior of selecting a redirect URL and provide the one of your choosing when calling signOut. The provided redirect URL should match at least one of the configured redirect URLs. If no redirect URL is provided to signOut, the first item from the the configured redirect URLs list that does not contain a HTTP nor HTTPS prefix will be picked.

import { signOut } from 'aws-amplify/auth';

// Assuming the following URLS were provided manually or via the Amplify configuration file,
// redirectSignOut: 'myDevApp://,https://authProvider/logout?logout_uri=myDevApp://'

signOut({
  global: false,
  oauth: {
    redirectUrl: 'https://authProvider/logout?logout_uri=myapp://'
  }
});
Irrespective of whether a redirectUrl is provided to signOut, a URL that does not contain http or https is expected to be present in the configured redirect URL list. This is because iOS requires an appScheme when creating the web session.

- Guest access -
Amplify Auth can be configured to automatically obtain guest credentials once the device is online so that you are able to use other categories "anonymously" without the need to sign in. You will not be able to perform user specific methods while in this state such as updating attributes, changing your password, or getting the current user. However, you can obtain the unique Identity ID which is assigned to the device through the fetchAuthSession method described here.

Amplify Gen 2 enables guest access by default. To disable it, you can update the backend.ts file with the following changes:

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend'
import { auth } from './auth/resource'
import { data } from './data/resource'

const backend = defineBackend({
  auth,
  data,
});

const { cfnIdentityPool } = backend.auth.resources.cfnResources;
cfnIdentityPool.allowUnauthenticatedIdentities = false;

- Tokens and credentials - 
Amplify Auth interacts with its underlying Amazon Cognito user pool as an OpenID Connect (OIDC) provider. When users successfully authenticate you receive OIDC-compliant JSON web tokens (JWT). These tokens are used to identity your user, and access resources.

Access tokens are used to verify the bearer of the token (i.e. the Cognito user) is authorized to perform an action against a resource. Below is an example payload of an access token vended by Cognito:

{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "client_id": "1sg675g08g6g0e9f64grv9n5sk",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "access",
  "scope": "aws.cognito.signin.user.admin",
  "auth_time": 1714241873,
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "57f10a4d-a1f2-453b-8672-d1cfa8187047",
  "username": "54288468-e051-706d-a73f-03892273d7e9"
}
ID tokens are intended to be used within your frontend application only. This token contains personally identifiable information (PII) and should not be used to authorize access against a resource. Below is an example of an ID token with the default Amplify Auth configuration of email and password auth.

{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "email_verified": true,
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "cognito:username": "54288468-e051-706d-a73f-03892273d7e9",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "aud": "1sg675g08g6g0e9f64grv9n5sk",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "id",
  "auth_time": 1714241873,
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "bb69af10-3ce0-47c2-8d8d-5bdc8630ab58",
  "email": "hello@mycompany.com"
}
When additional user attributes are specified for Amplify Auth, their values will be found in the ID token. For example, if a nickname attribute is requested it will be available on the ID token with the nickname claim:

{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "email_verified": true,
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "cognito:username": "54288468-e051-706d-a73f-03892273d7e9",
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "aud": "1sg675g08g6g0e9f64grv9n5sk",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "id",
  "auth_time": 1714241873,
+ "nickname": "hello",
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "bb69af10-3ce0-47c2-8d8d-5bdc8630ab58",
  "email": "hello@mycompany.com"
}
Conversely, user pool group claims are found in both the access token and ID token on the cognito:groups claim:

{
  "sub": "54288468-e051-706d-a73f-03892273d7e9",
  "email_verified": true,
  "iss": "https://cognito-idp.us-east-1.amazonaws.com/us-east-1_yoKn9s4Tq",
  "cognito:username": "54288468-e051-706d-a73f-03892273d7e9",
  "cognito:groups": ["ADMINS"],
  "origin_jti": "0eadb994-a6e0-419e-b309-a7a0d522d72f",
  "aud": "1sg675g08g6g0e9f64grv9n5sk",
  "event_id": "b180897a-181c-4f73-94bb-a2946e8b4ef1",
  "token_use": "id",
  "auth_time": 1714241873,
  "nickname": "hello",
  "exp": 1714245473,
  "iat": 1714241873,
  "jti": "bb69af10-3ce0-47c2-8d8d-5bdc8630ab58",
  "email": "hello@mycompany.com"
}
Visit the AWS documentation for using tokens with Cognito user pools to learn more about tokens, how they're used with Cognito, and their intended usage.

Understand token management options
Token keys are automatically rotated for you for added security but you can update how they are stored, customize the refresh rate and expiration times, and revoke tokens on sign-out.

Update your token-saving mechanism
You can update the storage mechanism to choose where and how tokens are persisted in your application. The default option is localStorage. Additionally, you can import the sessionStorage, sharedInMemoryStorage or CookieStorage options as well.

If you want to customize your own mechanism, you can import the KeyValueStorageInterface interface and implement it in your own class.

Browser Local Storage
In Amplify the localStorage is the default storage mechanism. It saves the tokens in the browser's localStorage. This local storage will persist across browser sessions and tabs. You can explicitly set to this storage by calling:

import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { defaultStorage } from 'aws-amplify/utils';

cognitoUserPoolsTokenProvider.setKeyValueStorage(defaultStorage);
Cookie Storage
CookieStorage saves the tokens in the browser's Cookies. The cookies will persist across browser sessions and tabs. You can explicitly set to this storage by calling:

import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { CookieStorage } from 'aws-amplify/utils';

cognitoUserPoolsTokenProvider.setKeyValueStorage(new CookieStorage());
Browser Session Storage
sessionStorage saves the tokens in the browser's sessionStorage and these tokens will clear when a tab is closed. The benefit to this storage mechanism is that the session only lasts as long as the browser is open and you can sign out users when they close the tab. You can update to this storage by calling:

import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { sessionStorage } from 'aws-amplify/utils';

cognitoUserPoolsTokenProvider.setKeyValueStorage(sessionStorage);
Custom Storage
You can implement your own custom storage mechanism by creating a class that implements the storage interface. Here is an example that uses memory storage:

import { cognitoUserPoolsTokenProvider } from 'aws-amplify/auth/cognito';
import { KeyValueStorageInterface } from 'aws-amplify/utils';

class MyCustomStorage implements KeyValueStorageInterface {
  storageObject: Record<string, string> = {};
  async setItem(key: string, value: string): Promise<void> {
    this.storageObject[key] = value;
  }
  async getItem(key: string): Promise<string | null> {
    return this.storageObject[key];
  }
  async removeItem(key: string): Promise<void> {
    delete this.storageObject[key];
  }
  async clear(): Promise<void> {
    this.storageObject = {};
  }
}

cognitoUserPoolsTokenProvider.setKeyValueStorage(new MyCustomStorage());
When you get the current user session, the tokens will be saved in your custom location.

Token Revocation 

- Using the Authenticator - 
The Authenticator component is automatically configured based on the outputs generated from your backend. To learn more about the Authenticator and how to customize its appearance, visit the Amplify UI documentation.

- Sign-up - 
Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth.

To get started, you can use the signUp() API to create a new user in your backend:

The signUp API response will include a nextStep property, which can be used to determine if further action is required. It may return the following next steps:

Next Step	Description
CONFIRM_SIGN_UP	The sign up needs to be confirmed by collecting a code from the user and calling confirmSignUp.
DONE	The sign up process has been fully completed.
COMPLETE_AUTO_SIGN_IN	The sign up process needs to complete by invoking the autoSignIn API.
Confirm sign-up
By default, each user that signs up remains in the unconfirmed status until they verify with a confirmation code that was sent to their email or phone number. The following are the default verification methods used when either phone or email are used as loginWith options.

Login option	User account verification channel
phone	Phone Number
email	Email
email and phone	Email
You can confirm the sign-up after receiving a confirmation code from the user:

import { confirmSignUp } from 'aws-amplify/auth';

const { isSignUpComplete, nextStep } = await confirmSignUp({
  username: "hello@mycompany.com",
  confirmationCode: "123456"
});
Sign up with passwordless methods
Your application's users can also sign up using passwordless methods. To learn more, visit the concepts page for passwordless.

SMS OTP
// Sign up using a phone number
const { nextStep: signUpNextStep } = await signUp({
	username: 'hello',
	options: {
		userAttributes: {
			phone_number: '+15555551234',
		},
	},
});

if (signUpNextStep.signUpStep === 'DONE') {
	console.log(`SignUp Complete`);
}

if (signUpNextStep.signUpStep === 'CONFIRM_SIGN_UP') {
	console.log(
		`Code Delivery Medium: ${signUpNextStep.codeDeliveryDetails.deliveryMedium}`,
	);
	console.log(
		`Code Delivery Destination: ${signUpNextStep.codeDeliveryDetails.destination}`,
	);
}

// Confirm sign up with the OTP received
const { nextStep: confirmSignUpNextStep } = await confirmSignUp({
	username: 'hello',
	confirmationCode: '123456',
});

if (confirmSignUpNextStep.signUpStep === 'DONE') {
	console.log(`SignUp Complete`);
}
Email OTP
// Sign up using an email address
const { nextStep: signUpNextStep } = await signUp({
	username: 'hello',
	options: {
		userAttributes: {
			email: 'hello@example.com',
		},
	},
});

if (signUpNextStep.signUpStep === 'DONE') {
	console.log(`SignUp Complete`);
}

if (signUpNextStep.signUpStep === 'CONFIRM_SIGN_UP') {
	console.log(
		`Code Delivery Medium: ${signUpNextStep.codeDeliveryDetails.deliveryMedium}`,
	);
	console.log(
		`Code Delivery Destination: ${signUpNextStep.codeDeliveryDetails.destination}`,
	);
}

// Confirm sign up with the OTP received
const { nextStep: confirmSignUpNextStep } = await confirmSignUp({
	username: 'hello',
	confirmationCode: '123456',
});

if (confirmSignUpNextStep.signUpStep === 'DONE') {
	console.log(`SignUp Complete`);
}
Auto Sign In
// Call `signUp` API with `USER_AUTH` as the authentication flow type for `autoSignIn`
const { nextStep: signUpNextStep } = await signUp({
	username: 'hello',
	options: {
		userAttributes: {
			email: 'hello@example.com',
			phone_number: '+15555551234',
		},
		autoSignIn: {
			authFlowType: 'USER_AUTH',
		},
	},
});

if (signUpNextStep.signUpStep === 'CONFIRM_SIGN_UP') {
	console.log(
		`Code Delivery Medium: ${signUpNextStep.codeDeliveryDetails.deliveryMedium}`,
	);
	console.log(
		`Code Delivery Destination: ${signUpNextStep.codeDeliveryDetails.destination}`,
	);
}

// Call `confirmSignUp` API with the OTP received
const { nextStep: confirmSignUpNextStep } = await confirmSignUp({
	username: 'hello',
	confirmationCode: '123456',
});

if (confirmSignUpNextStep.signUpStep === 'COMPLETE_AUTO_SIGN_IN') {
	// Call `autoSignIn` API to complete the flow
	const { nextStep } = await autoSignIn();

	if (nextStep.signInStep === 'DONE') {
		console.log('Successfully signed in.');
	}
}

- Sign-in - 
Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth.

Using the signIn API
import { signIn } from 'aws-amplify/auth'

await signIn({
  username: "hello@mycompany.com",
  password: "hunter2",
})
The signIn API response will include a nextStep property, which can be used to determine if further action is required. It may return the following next steps:

Next Step	Description
CONFIRM_SIGN_IN_WITH_NEW_PASSWORD_REQUIRED	The user was created with a temporary password and must set a new one. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE	The sign-in must be confirmed with a custom challenge response. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_TOTP_CODE	The sign-in must be confirmed with a TOTP code from the user. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_SMS_CODE	The sign-in must be confirmed with an SMS code from the user. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_EMAIL_CODE	The sign-in must be confirmed with an EMAIL code from the user. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_PASSWORD	The sign-in must be confirmed with the password from the user. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION	The user must select their mode of first factor authentication. Complete the process by passing the desired mode to the challengeResponse field of confirmSignIn.
CONTINUE_SIGN_IN_WITH_MFA_SELECTION	The user must select their mode of MFA verification before signing in. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_MFA_SETUP_SELECTION	The user must select their mode of MFA verification to setup. Complete the process by passing either "EMAIL" or "TOTP" to confirmSignIn.
CONTINUE_SIGN_IN_WITH_TOTP_SETUP	The TOTP setup process must be continued. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_EMAIL_SETUP	The EMAIL setup process must be continued. Complete the process by passing a valid email address to confirmSignIn.
RESET_PASSWORD	The user must reset their password via resetPassword.
CONFIRM_SIGN_UP	The user hasn't completed the sign-up flow fully and must be confirmed via confirmSignUp.
DONE	The sign in process has been completed.
For more information on handling the MFA steps that may be returned, see multi-factor authentication.

With multi-factor auth enabled
When you have Email or SMS MFA enabled, Cognito will send messages to your users on your behalf. Email and SMS messages require that your users have email address and phone number attributes respectively. It is recommended to set these attributes as required in your user pool if you wish to use either Email MFA or SMS MFA. When these attributes are required, a user must provide these details before they can complete the sign up process.

If you have set MFA to be required and you have activated more than one authentication factor, Cognito will prompt new users to select an MFA factor they want to use. Users must have a phone number to select SMS and an email address to select email MFA.

If a user doesn't have the necessary attributes defined for any available message based MFA, Cognito will prompt them to set up TOTP.

Visit the multi-factor authentication documentation to learn more about enabling MFA on your backend auth resource.

Confirm sign-in
Following sign in, you will receive a nextStep in the sign-in result of one of the following types. Collect the user response and then pass to the confirmSignIn API to complete the sign in flow.

Next Step	Description
CONFIRM_SIGN_IN_WITH_TOTP_CODE	The sign-in must be confirmed with a TOTP code from the user. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_SMS_CODE	The sign-in must be confirmed with a SMS code from the user. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_EMAIL_CODE	The sign-in must be confirmed with a EMAIL code from the user. Complete the process with confirmSignIn.
CONFIRM_SIGN_IN_WITH_PASSWORD	The sign-in must be confirmed with the password from the user. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION	The user must select their mode of first factor authentication. Complete the process by passing the desired mode to the challengeResponse field of confirmSignIn.
CONTINUE_SIGN_IN_WITH_MFA_SELECTION	The user must select their mode of MFA verification before signing in. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_MFA_SETUP_SELECTION	The user must select their mode of MFA verification to setup. Complete the process by passing either "EMAIL" or "TOTP" to confirmSignIn.
CONTINUE_SIGN_IN_WITH_TOTP_SETUP	The TOTP setup process must be continued. Complete the process with confirmSignIn.
CONTINUE_SIGN_IN_WITH_EMAIL_SETUP	The EMAIL setup process must be continued. Complete the process by passing a valid email address to confirmSignIn.
Note: you must call confirmSignIn in the same app session as you call signIn. If you close the app, you will need to call signIn again. As a result, for testing purposes, you'll at least need an input field where you can enter the code sent via SMS and pass it to confirmSignIn.

src/main.ts
import { confirmSignIn, signIn } from "aws-amplify/auth";

const { nextStep } = await signIn({
  username: "hello@mycompany.com",
  password: "hunter2",
});

if (
  nextStep.signInStep === "CONFIRM_SIGN_IN_WITH_SMS_CODE" ||
  nextStep.signInStep === "CONFIRM_SIGN_IN_WITH_EMAIL_CODE" ||
  nextStep.signInStep === "CONFIRM_SIGN_IN_WITH_TOTP_CODE"
) {
  // collect OTP from user
  await confirmSignIn({
    challengeResponse: "123456",
  });
}

if (nextStep.signInStep === "CONTINUE_SIGN_IN_WITH_MFA_SELECTION") {
  // present nextStep.allowedMFATypes to user
  // collect user selection
  await confirmSignIn({
    challengeResponse: "EMAIL", // 'EMAIL', 'SMS', or 'TOTP'
  });
}

if (nextStep.signInStep === "CONTINUE_SIGN_IN_WITH_MFA_SETUP_SELECTION") {
  // present nextStep.allowedMFATypes to user
  // collect user selection
  await confirmSignIn({
    challengeResponse: "EMAIL", // 'EMAIL' or 'TOTP'
  });
}

if (nextStep.signInStep === "CONTINUE_SIGN_IN_WITH_EMAIL_SETUP") {
  // collect email address from user
  await confirmSignIn({
    challengeResponse: "hello@mycompany.com",
  });
}

if (nextStep.signInStep === "CONTINUE_SIGN_IN_WITH_TOTP_SETUP") {
  // present nextStep.totpSetupDetails.getSetupUri() to user
  // collect OTP from user
  await confirmSignIn({
    challengeResponse: "123456",
  });
}
Note: The Amplify authentication flow will persist relevant session data throughout the lifespan of a page session. This enables the confirmSignIn API to be leveraged even after a full page refresh in a multi-page application, such as when redirecting from a login page to a sign in confirmation page.

Sign in with an external identity provider
To sign in using an external identity provider such as Google, use the signInWithRedirect function.

For guidance on configuring an external Identity Provider with Amplify see External Identity Providers

import { signInWithRedirect } from "aws-amplify/auth"

signInWithRedirect({ provider: "Google" })
Note: if you do not pass an argument to signInWithRedirect it will redirect your users to the Cognito Hosted UI, which has limited support for customization.

Alternatively if you have configured OIDC or SAML-based identity providers in your auth resource, you can specify a "custom" provider in signInWithRedirect:

import { signInWithRedirect } from "aws-amplify/auth"

signInWithRedirect({ provider: {
  custom: "MyOidcProvider"
}})
Auto sign-in
The autoSignIn API will automatically sign-in a user when it was previously enabled by the signUp API and after any of the following cases has completed:

User confirmed their account with a verification code sent to their phone or email (default option).
User confirmed their account with a verification link sent to their phone or email. In order to enable this option you need to go to the Amazon Cognito console, look for your userpool, then go to the Messaging tab and enable link mode inside the Verification message option. Finally you need to define the signUpVerificationMethod to link inside the Cognito option of your Auth config.
src/main.ts
import { autoSignIn } from 'aws-amplify/auth';

await autoSignIn();
Note: When MFA is enabled, your users may be presented with multiple consecutive steps that require them to enter an OTP to proceed with the sign up and subsequent sign in flow. This requirement is not present when using the USER_AUTH flow.

Install native module
signInWithRedirect displays the sign-in UI inside a platform-dependent webview. On iOS devices, an ASWebAuthenticationSession will be launched and, on Android, a Custom Tab. After the sign-in process is complete, the sign-in UI will redirect back to your app.

To enable this capability, an additional dependency must be installed.

Terminal
npm add @aws-amplify/rtn-web-browser
Platform Setup
On iOS, there are no additional setup steps.

Android
After a successful sign-in, the sign-in UI will attempt to redirect back to your application. To register the redirect URI scheme you configured above with the device, an intent-filter must be added to your application's AndroidManifest.xml file which should be located in your React Native app's android/app/src/main directory.

Add the intent-filter to your application's main activity, replacing myapp with your redirect URI scheme as necessary.

android/app/src/main/AndroidManifest.xml
<application ...>
    <activity android:name=".MainActivity" ...>
        ...
        <intent-filter>
            <action android:name="android.intent.action.VIEW" />
            <category android:name="android.intent.category.DEFAULT" />
            <category android:name="android.intent.category.BROWSABLE" />
            <data android:scheme="myapp" />
        </intent-filter>
        ...
    </activity>
</application>
Sign in with passwordless methods
Your application's users can also sign in using passwordless methods. To learn more, visit the concepts page for passwordless.

SMS OTP
Pass SMS_OTP as the preferredChallenge when calling the signIn API in order to initiate a passwordless authentication flow with SMS OTP.

const { nextStep: signInNextStep } = await signIn({
	username: '+15551234567',
	options: {
		authFlowType: 'USER_AUTH',
		preferredChallenge: 'SMS_OTP',
	},
});

if (signInNextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_SMS_CODE') {
	// prompt user for otp code delivered via SMS
	const { nextStep: confirmSignInNextStep } = await confirmSignIn({
		challengeResponse: '123456',
	});

	if (confirmSignInNextStep.signInStep === 'DONE') {
		console.log('Sign in successful!');
	}
}
Email OTP
Pass EMAIL_OTP as the preferredChallenge when calling the signIn API in order to initiate a passwordless authentication flow using email OTP.

const { nextStep: signInNextStep } = await signIn({
	username: 'hello@example.com',
	options: {
		authFlowType: 'USER_AUTH',
		preferredChallenge: 'EMAIL_OTP',
	},
});

if (signInNextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_EMAIL_CODE') {
	// prompt user for otp code delivered via email
	const { nextStep: confirmSignInNextStep } = await confirmSignIn({
		challengeResponse: '123456',
	});

	if (confirmSignInNextStep.signInStep === 'DONE') {
		console.log('Sign in successful!');
	}
}
WebAuthn Passkeys
Pass WEB_AUTHN as the preferredChallenge in order to initiate the passwordless authentication flow using a WebAuthn credential.

const { nextStep: signInNextStep } = await signIn({
	username: 'hello@example.com',
	options: {
		authFlowType: 'USER_AUTH',
		preferredChallenge: 'WEB_AUTHN',
	},
});

if (signInNextStep.signInStep === 'DONE') {
	console.log('Sign in successful!');
}
Password
Pass either PASSWORD or PASSWORD_SRP as the preferredChallenge in order to initiate a traditional password based authentication flow.

const { nextStep: signInNextStep } = await signIn({
	username: 'hello@example.com',
	password: 'example-password',
	options: {
		authFlowType: 'USER_AUTH',
		preferredChallenge: 'PASSWORD_SRP', // or 'PASSWORD'
	},
});

if (confirmSignInNextStep.signInStep === 'DONE') {
	console.log('Sign in successful!');
}
First Factor Selection
Omit the preferredChallenge parameter to discover what first factors are available for a given user.

The confirmSignIn API can then be used to select a challenge and initiate the associated authentication flow.

const { nextStep: signInNextStep } = await signIn({
	username: '+15551234567',
	options: {
		authFlowType: 'USER_AUTH',
	},
});

if (
	signInNextStep.signInStep === 'CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION'
) {
	// present user with list of available challenges
	console.log(`Available Challenges: ${signInNextStep.availableChallenges}`);

	// respond with user selection using `confirmSignIn` API
	const { nextStep: nextConfirmSignInStep } = await confirmSignIn({
		challengeResponse: 'SMS_OTP', // or 'EMAIL_OTP', 'WEB_AUTHN', 'PASSWORD', 'PASSWORD_SRP'
	});
} 

- Switching authentication flows - 
For client side authentication there are four different flows:

USER_SRP_AUTH: The USER_SRP_AUTH flow uses the SRP protocol (Secure Remote Password) where the password never leaves the client and is unknown to the server. This is the recommended flow and is used by default.

USER_PASSWORD_AUTH: The USER_PASSWORD_AUTH flow will send user credentials to the backend without applying SRP encryption. If you want to migrate users to Cognito using the "Migration" trigger and avoid forcing users to reset their passwords, you will need to use this authentication type because the Lambda function invoked by the trigger needs to verify the supplied credentials.

CUSTOM_WITH_SRP & CUSTOM_WITHOUT_SRP: Allows for a series of challenge and response cycles that can be customized to meet different requirements.

USER_AUTH: The USER_AUTH flow is a choice-based authentication flow that allows the user to choose from the list of available authentication methods. This flow is useful when you want to provide the user with the option to choose the authentication method. The choices that may be available to the user are EMAIL_OTP, SMS_OTP, WEB_AUTHN, PASSWORD or PASSWORD_SRP.

The Auth flow can be customized when calling signIn, for example:

src/main.ts
await signIn({
  username: "hello@mycompany.com",
  password: "hunter2",
  options: {
      authFlowType: 'USER_AUTH'
  }
})
For more information about authentication flows, please visit AWS Cognito developer documentation

USER_AUTH flow
The USER_AUTH sign in flow supports the following methods as first factors for authentication: WEB_AUTHN, EMAIL_OTP, SMS_OTP, PASSWORD, and PASSWORD_SRP.

If the desired first factor is known when authentication is initiated, it can be passed to the signIn API as the preferredChallenge to initiate the corresponding authentication flow.

// PASSWORD_SRP / PASSWORD
// sign in with preferred challenge as password
// note password must be provided in same step
const { nextStep } = await signIn({
    username: "hello@mycompany.com",
    password: "hunter2",
    options: {
        authFlowType: "USER_AUTH",
        preferredChallenge: "PASSWORD_SRP" // or "PASSWORD"
    },
});

// WEB_AUTHN / EMAIL_OTP / SMS_OTP
// sign in with preferred passwordless challenge
// no additional user input required at this step 
const { nextStep } = await signIn({
    username: "hello@example.com",
    options: {
        authFlowType: "USER_AUTH",
        preferredChallenge: "WEB_AUTHN" // or "EMAIL_OTP" or "SMS_OTP"
    },
});
If the desired first factor is not known or you would like to provide users with the available options, preferredChallenge can be omitted from the initial signIn API call.

This allows you to discover which authentication first factors are available for a user via the CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION step. You can then present the available options to the user and use the confirmSignIn API to respond with the user's selection.

const { nextStep: signInNextStep } = await signIn({
	username: '+15551234567',
	options: {
		authFlowType: 'USER_AUTH',
	},
});

if (
	signInNextStep.signInStep === 'CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION'
) {
	// present user with list of available challenges
	console.log(`Available Challenges: ${signInNextStep.availableChallenges}`);

	// respond with user selection using `confirmSignIn` API
	const { nextStep: nextConfirmSignInStep } = await confirmSignIn({
		challengeResponse: 'SMS_OTP', // or 'EMAIL_OTP', 'WEB_AUTHN', 'PASSWORD', 'PASSWORD_SRP'
	});
}
Also, note that if the preferredChallenge passed to the initial signIn API call is unavailable for the user, Amplify will also respond with the CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION next step.

For more information about determining a first factor, and signing in with passwordless authentication factors, please visit the Passwordless concepts page.

USER_PASSWORD_AUTH flow
A use case for the USER_PASSWORD_AUTH authentication flow is migrating users into Amazon Cognito

Set up auth backend
In order to use the authentication flow USER_PASSWORD_AUTH, your Cognito app client has to be configured to allow it. In the AWS Console, this is done by ticking the checkbox at General settings > App clients > Show Details (for the affected client) > Enable username-password (non-SRP) flow. If you're using the AWS CLI or CloudFormation, update your app client by adding USER_PASSWORD_AUTH to the list of "Explicit Auth Flows".

Migrate users with Amazon Cognito
Amazon Cognito provides a trigger to migrate users from your existing user directory seamlessly into Cognito. You achieve this by configuring your User Pool's "Migration" trigger which invokes a Lambda function whenever a user that does not already exist in the user pool authenticates, or resets their password.

In short, the Lambda function will validate the user credentials against your existing user directory and return a response object containing the user attributes and status on success. An error message will be returned if an error occurs. Visit Amazon Cognito user pools import guide for migration flow and more detailed instruction, and Amazon Cognito Lambda trigger guide on how to set up lambda to handle request and response objects.

CUSTOM_WITH_SRP & CUSTOM_WITHOUT_SRP flows
Amazon Cognito user pools supports customizing the authentication flow to enable custom challenge types, in addition to a password in order to verify the identity of users. These challenge types may include CAPTCHAs or dynamic challenge questions. The CUSTOM_WITH_SRP flow requires a password when calling signIn. Both of these flows map to the CUSTOM_AUTH flow in Cognito.

To define your challenges for custom authentication flow, you need to implement three Lambda triggers for Amazon Cognito. Please visit AWS Amplify Custom Auth Challenge example for set up instructions.

For more information about working with Lambda Triggers for custom authentication challenges, please visit Amazon Cognito Developer Documentation.

Custom authentication flow
To initiate a custom authentication flow in your app, call signIn without a password. A custom challenge needs to be answered using the confirmSignIn API:

src/main.ts
import { signIn, confirmSignIn } from 'aws-amplify/auth';

const challengeResponse = 'the answer for the challenge';

const { nextStep } = await signIn({
  username,
  options: {
    authFlowType: 'CUSTOM_WITHOUT_SRP',
  },
});

if (nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE') {
  // to send the answer of the custom challenge
  await confirmSignIn({ challengeResponse });
}
CAPTCHA authentication
To create a CAPTCHA challenge with a Lambda Trigger, please visit AWS Amplify Google reCAPTCHA challenge example for detailed examples.

For more information about working with Lambda Triggers for custom authentication challenges, please visit Amazon Cognito Developer Documentation.

- Sign-out
Amplify provides a client library that enables you to interact with backend resources such as Amplify Auth.

To sign a user out of your application use the signOut API.

import { signOut } from 'aws-amplify/auth';

await signOut();
You can also sign out users from all devices by performing a global sign-out. This will also invalidate all refresh tokens issued to a user. The user's current access and ID tokens will remain valid on other devices until the refresh token expires (access and ID tokens expire one hour after they are issued).

import { signOut } from 'aws-amplify/auth';

await signOut({ global: true });

- Manage user sessions -
Amplify Auth provides access to current user sessions and tokens to help you retrieve your user's information to determine if they are signed in with a valid session and control their access to your app.

Retrieve your current authenticated user
You can use the getCurrentUser API to get information about the currently authenticated user including the username, userId and signInDetails.

import { getCurrentUser } from 'aws-amplify/auth';

const { username, userId, signInDetails } = await getCurrentUser();

console.log("username", username);
console.log("user id", userId);
console.log("sign-in details", signInDetails);
This method can be used to check if a user is signed in. It throws an error if the user is not authenticated.

The user's signInDetails are not supported when using the Hosted UI or the signInWithRedirect API.

Retrieve a user session
Your user's session is their signed-in state, which grants them access to your app. When your users sign in, their credentials are exchanged for temporary access tokens. You can get session details to access these tokens and use this information to validate user access or perform actions unique to that user.

If you only need the session details, you can use the fetchAuthSession API which returns a tokens object containing the JSON Web Tokens (JWT).

import { fetchAuthSession } from 'aws-amplify/auth';

const session = await fetchAuthSession();

console.log("id token", session.tokens.idToken)
console.log("access token", session.tokens.accessToken)
Refreshing sessions
The fetchAuthSession API automatically refreshes the user's session when the authentication tokens have expired and a valid refreshToken is present. Additionally, you can also refresh the session explicitly by calling the fetchAuthSession API with the forceRefresh flag enabled.

import { fetchAuthSession } from 'aws-amplify/auth';

await fetchAuthSession({ forceRefresh: true });
Warning: by default, sessions from external identity providers cannot be refreshed.

- Manage user attributes -
User attributes such as email address, phone number help you identify individual users. Defining the user attributes you include for your user profiles makes user data easy to manage at scale. This information will help you personalize user journeys, tailor content, provide intuitive account control, and more. You can capture information upfront during sign-up or enable customers to update their profile after sign-up. In this section we take a closer look at working with user attributes, how to set them up and manage them.

Pass user attributes during sign-up
You can create user attributes during sign-up or when the user is authenticated. To do this as part of sign-up you can pass them in the userAttributes object of the signUp API:

import { signUp } from "aws-amplify/auth";

await signUp({
  username: "jdoe",
  password: "mysecurerandompassword#123",
  options: {
    userAttributes: {
      email: "me@domain.com",
      phone_number: "+12128601234", // E.164 number convention
      given_name: "Jane",
      family_name: "Doe",
      nickname: "Jane",
    },
  },
});
Configure custom user attributes during sign-up
Custom attributes can be passed in with the userAttributes option of the signUp API:

import { signUp } from "aws-amplify/auth";

await signUp({
  username: 'john.doe@example.com',
  password: 'hunter2',
  options: {
    userAttributes: {
      'custom:display_name': 'john_doe123',
    }
  }
});
Retrieve user attributes
You can retrieve user attributes for your users to read in their profile using the fetchUserAttributes API. This helps you personalize their frontend experience as well as control what they will see.

import { fetchUserAttributes } from 'aws-amplify/auth';

await fetchUserAttributes();
Update user attribute
You can use the updateUserAttribute API to create or update existing user attributes.

TypeScript
JavaScript
import {
  updateUserAttribute,
  type UpdateUserAttributeOutput
} from 'aws-amplify/auth';

async function handleUpdateUserAttribute(attributeKey: string, value: string) {
  try {
    const output = await updateUserAttribute({
      userAttribute: {
        attributeKey,
        value
      }
    });
    handleUpdateUserAttributeNextSteps(output);
  } catch (error) {
    console.log(error);
  }
}

function handleUpdateUserAttributeNextSteps(output: UpdateUserAttributeOutput) {
  const { nextStep } = output;

  switch (nextStep.updateAttributeStep) {
    case 'CONFIRM_ATTRIBUTE_WITH_CODE':
      const codeDeliveryDetails = nextStep.codeDeliveryDetails;
      console.log(
        `Confirmation code was sent to ${codeDeliveryDetails?.deliveryMedium}.`
      );
      // Collect the confirmation code from the user and pass to confirmUserAttribute.
      break;
    case 'DONE':
      console.log(`attribute was successfully updated.`);
      break;
  }
}
Note: If you change an attribute that requires confirmation (i.e. email or phone_number), the user will receive a confirmation code either to their email or cellphone. This code can be used with the confirmUserAttribute API to confirm the change.

Update user attributes
You can use the updateUserAttributes API to create or update multiple existing user attributes.

import { updateUserAttributes, type UpdateUserAttributesOutput } from "aws-amplify/auth";

await updateUserAttributes({
  userAttributes: {
    email: "me@domain.com",
    name: "Jon Doe",
  },
});
Verify user attribute
Some attributes require confirmation for the attribute update to complete. If the attribute needs to be confirmed, part of the result of the updateUserAttribute or updateUserAttributes APIs will be CONFIRM_ATTRIBUTE_WITH_CODE. A confirmation code will be sent to the delivery medium mentioned in the delivery details. When the user gets the confirmation code, you can present a UI to the user to enter the code and invoke the confirmUserAttribute API with their input:

import {
  confirmUserAttribute,
  type ConfirmUserAttributeInput
} from 'aws-amplify/auth';

async function handleConfirmUserAttribute({
  userAttributeKey,
  confirmationCode
}: ConfirmUserAttributeInput) {
  try {
    await confirmUserAttribute({ userAttributeKey, confirmationCode });
  } catch (error) {
    console.log(error);
  }
}
Send user attribute verification code
If an attribute needs to be verified while the user is authenticated, invoke the sendUserAttributeVerificationCode API as shown below:

import {
  sendUserAttributeVerificationCode,
  type VerifiableUserAttributeKey
} from 'aws-amplify/auth';

async function handleSendUserAttributeVerificationCode(
  key: VerifiableUserAttributeKey
) {
  try {
    await sendUserAttributeVerificationCode({
      userAttributeKey: key
    });
  } catch (error) {
    console.log(error);
  }
}
Delete user attributes
The deleteUserAttributes API allows to delete one or more user attributes.

import {
  deleteUserAttributes,
  type DeleteUserAttributesInput
} from 'aws-amplify/auth';

async function handleDeleteUserAttributes(
  keys: DeleteUserAttributesInput['userAttributeKeys']
) {
  try {
    await deleteUserAttributes({
      userAttributeKeys: ['custom:my_custom_attribute', ...keys]
    });
  } catch (error) {
    console.log(error);
  }
}

- Listen to auth events -
Amplify Auth emits events during authentication flows, which enables you to react to user flows in real time and trigger custom business logic. For example, you may want to capture data, synchronize your app's state, and personalize the user's experience. You can listen to and respond to events across the Auth lifecycle such as sign-in and sign-out.

Expose hub events triggered in response to auth actions
You can use Amplify Hub with its built in Amplify Auth events to subscribe a listener using a publish-subscribe pattern and capture events between different parts of your application. The Amplify Auth category publishes in the auth channel when auth events such as signedIn or signedOut happen independent from your app code.

You can review the Amplify Hub guide to learn more.

Channels are logical group names that help you organize dispatching and listening. However, some channels are protected and cannot be used to publish custom events, and auth is one of these channels. Sending unexpected payloads to protected channels can have undesirable side effects such as impacting authentication flows. See the Amplify Hub guide for more protected channels.

Here is a basic example of setting up a listener that logs an event emitted through the auth channel:

import { Hub } from 'aws-amplify/utils';

Hub.listen('auth', (data) => {
  console.log(data)
});
Once your app is set up to subscribe and listen to specific event types from the auth channel, the listeners will be notified asynchronously when an event occurs. This pattern allows for a one-to-many relationship where one auth event can be shared with many different listeners that have been subscribed. This lets your app react based on the event rather than proactively poll for information.

Additionally, you can set up your listener to extract data from the event payload and execute a callback that you define. For example, you might update UI elements in your app to reflect your user's authenticated state after the signedIn or signedOut events.

Listen to and log auth events
One of the most common workflows will be to log events. In this example you can see how you can listen and target specific auth events using a switch to log your own messages.

import { Hub } from 'aws-amplify/utils';

Hub.listen('auth', ({ payload }) => {
  switch (payload.event) {
    case 'signedIn':
      console.log('user have been signedIn successfully.');
      break;
    case 'signedOut':
      console.log('user have been signedOut successfully.');
      break;
    case 'tokenRefresh':
      console.log('auth tokens have been refreshed.');
      break;
    case 'tokenRefresh_failure':
      console.log('failure while refreshing auth tokens.');
      break;
    case 'signInWithRedirect':
      console.log('signInWithRedirect API has successfully been resolved.');
      break;
    case 'signInWithRedirect_failure':
      console.log('failure while trying to resolve signInWithRedirect API.');
      break;
    case 'customOAuthState':
      logger.info('custom state returned from CognitoHosted UI');
      break;
  }
});
Stop listening to events
You can also stop listening for messages by calling the result of the Hub.listen() function. This may be useful if you no longer need to receive messages in your application flow. This can also help you avoid any memory leaks on low powered devices when you are sending large amounts of data through Amplify Hub on multiple channels.

To stop listening to a certain event, you need to wrap the listener function with a variable and call it once you no longer need it:

/* start listening for messages */
const hubListenerCancelToken = Hub.listen('auth', (data) => {
  console.log('Listening for all auth events: ', data.payload.data);
});

/* later */
hubListenerCancelToken(); // stop listening for messages
You now have a few use cases and examples for listening to and responding to auth events.

- Delete user account - 
Empowering users to delete their account can improve trust and transparency. You can programmatically enable self-service account deletion with Amplify Auth.

If you have not yet created an Amplify Gen 2 app, visit the quickstart.

Allow users to delete their account
You can quickly set up account deletion for your users with the Amplify Libraries. Invoking the deleteUser API to delete a user from the Auth category will also sign out your user.

If your application uses a Cognito User Pool, which is the default configuration, this action will only delete the user from the Cognito User Pool. It will have no effect if you are federating with a Cognito Identity Pool alone.

Before invoking the deleteUser API, you may need to first delete associated user data that is not stored in Cognito. For example, if you are using Amplify Data to persist user data, you could follow these instructions to delete associated user data. This allows you to address any guidelines (such as GDPR) that require your app to delete data associated with a user who deletes their account.

You can enable account deletion using the following method:

import { deleteUser } from 'aws-amplify/auth';

async function handleDeleteUser() {
  try {
    await deleteUser();
  } catch (error) {
    console.log(error);
  }
}
We recommend you update your UI to let your users know that their account is deleted and test the functionality with a test user. Note that your user will be signed out of your application when they delete their account. 

- Multi-step sign-in - 
After a user has finished signup, they can proceed to sign in. Amplify Auth signin flows can be multi-step processes. The required steps are determined by the configuration provided when you define your auth resources. See the multi-factor authentication page for more information.

Depending on the configuration, you may need to call various APIs to finish authenticating a user's signin attempt. To identify the next step in a signin flow, inspect the nextStep parameter of the signin result.

import {
	confirmSignIn,
	confirmSignUp,
	resetPassword,
	signIn,
} from 'aws-amplify/auth';

const { nextStep } = await signIn({
	username: 'hello@mycompany.com',
	password: 'hunter2',
});

if (
	nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_SMS_CODE' ||
	nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_EMAIL_CODE' ||
	nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_TOTP_CODE'
) {
	// collect OTP from user
	await confirmSignIn({
		challengeResponse: '123456',
	});
}

if (nextStep.signInStep === 'CONTINUE_SIGN_IN_WITH_MFA_SELECTION') {
	// present nextStep.allowedMFATypes to user
	// collect user selection
	await confirmSignIn({
		challengeResponse: 'EMAIL', // 'EMAIL', 'SMS', or 'TOTP'
	});
}

if (nextStep.signInStep === 'CONTINUE_SIGN_IN_WITH_MFA_SETUP_SELECTION') {
	// present nextStep.allowedMFATypes to user
	// collect user selection
	await confirmSignIn({
		challengeResponse: 'EMAIL', // 'EMAIL' or 'TOTP'
	});
}

if (nextStep.signInStep === 'CONTINUE_SIGN_IN_WITH_EMAIL_SETUP') {
	// collect email address from user
	await confirmSignIn({
		challengeResponse: 'hello@mycompany.com',
	});
}

if (nextStep.signInStep === 'CONTINUE_SIGN_IN_WITH_TOTP_SETUP') {
	// present nextStep.totpSetupDetails.getSetupUri() to user
	// collect OTP from user
	await confirmSignIn({
		challengeResponse: '123456',
	});
}

if (nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_PASSWORD') {
    // collect password from user
    await confirmSignIn({
        challengeResponse: 'hunter2',
    });
}

if (nextStep.signInStep === 'CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION') {
    // present nextStep.availableChallenges to user
    // collect user selection
    await confirmSignIn({
        challengeResponse: 'SMS_OTP', // or 'EMAIL_OTP', 'WEB_AUTHN', 'PASSWORD', 'PASSWORD_SRP'
    });
}

if (nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE') {
	// collect custom challenge answer from user
	await confirmSignIn({
		challengeResponse: 'custom-challenge-answer',
	});
}

if (nextStep.signInStep === 'CONFIRM_SIGN_IN_WITH_NEW_PASSWORD_REQUIRED') {
	// collect new password from user
	await confirmSignIn({
		challengeResponse: 'new-password',
	});
}

if (nextStep.signInStep === 'RESET_PASSWORD') {
	// initiate reset password flow
	await resetPassword({
		username: 'username',
	});
}

if (nextStep.signInStep === 'CONFIRM_SIGN_UP') {
	// user was not confirmed during sign up process
	// if user has confirmation code, invoke `confirmSignUp` api
	// otherwise, invoke `resendSignUpCode` to resend the code
	await confirmSignUp({
		username: 'username',
		confirmationCode: '123456',
	});
}

if (nextStep.signInStep === 'DONE') {
	// signin complete
}
Confirm sign-in with SMS MFA
If the next step is CONFIRM_SIGN_IN_WITH_SMS_CODE, Amplify Auth has sent the user a random code over SMS and is waiting for the user to verify that code. To handle this step, your app's UI must prompt the user to enter the code. After the user enters the code, pass the value to the confirmSignIn API.

The result includes an AuthCodeDeliveryDetails member. It includes additional information about the code delivery, such as the partial phone number of the SMS recipient, which can be used to prompt the user on where to look for the code.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONFIRM_SIGN_IN_WITH_SMS_CODE': {
			const { codeDeliveryDetails } = result.nextStep;
			// OTP has been delivered to user via SMS
			// Inspect codeDeliveryDetails for additional delivery information
			console.log(
				`A confirmation code has been sent to ${codeDeliveryDetails?.destination}`,
			);
			console.log(
				`Please check your ${codeDeliveryDetails?.deliveryMedium} for the code.`,
			);
			break;
		}
	}
}

async function confirmMfaCode(mfaCode: string) {
	const result = await confirmSignIn({ challengeResponse: mfaCode });

	return handleSignInResult(result);
}
Confirm sign-in with TOTP MFA
If the next step is CONFIRM_SIGN_IN_WITH_TOTP_CODE, you should prompt the user to enter the TOTP code from their associated authenticator app during set up. The code is a six-digit number that changes every 30 seconds. The user must enter the code before the 30-second window expires.

After the user enters the code, your implementation must pass the value to Amplify Auth confirmSignIn API.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONFIRM_SIGN_IN_WITH_TOTP_CODE': {
			// Prompt user to open their authenticator app to retrieve the code
			console.log(
				`Enter a one-time code from your registered authenticator app`,
			);
			break;
		}
	}
}
// Then, pass the TOTP code to `confirmSignIn`
async function confirmTotpCode(totpCode: string) {
	const result = await confirmSignIn({ challengeResponse: totpCode });

	return handleSignInResult(result);
}
Confirm sign-in with Email MFA
If the next step is CONFIRM_SIGN_IN_WITH_EMAIL_CODE, Amplify Auth has sent the user a random code to their email address and is waiting for the user to verify that code. To handle this step, your app's UI must prompt the user to enter the code. After the user enters the code, pass the value to the confirmSignIn API.

The result includes an AuthCodeDeliveryDetails member. It includes additional information about the code delivery, such as the partial email address of the recipient, which can be used to prompt the user on where to look for the code.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONFIRM_SIGN_IN_WITH_EMAIL_CODE': {
			const { codeDeliveryDetails } = result.nextStep;
			// OTP has been delivered to user via Email
			// Inspect codeDeliveryDetails for additional delivery information
			console.log(
				`A confirmation code has been sent to ${codeDeliveryDetails?.destination}`,
			);
			console.log(
				`Please check your ${codeDeliveryDetails?.deliveryMedium} for the code.`,
			);
			break;
		}
	}
}

async function confirmMfaCode(mfaCode: string) {
	const result = await confirmSignIn({ challengeResponse: mfaCode });

	return handleSignInResult(result);
}
Continue sign-in with MFA Selection
If the next step is CONTINUE_SIGN_IN_WITH_MFA_SELECTION, the user must select the MFA method to use. Amplify Auth currently supports SMS, TOTP, and EMAIL as MFA methods. After the user selects an MFA method, your implementation must pass the selected MFA method to Amplify Auth using confirmSignIn API.

The MFA types which are currently supported by Amplify Auth are:

SMS
TOTP
EMAIL
Once Amplify receives the users selection, you can expect to handle a follow up nextStep corresponding with the selected MFA type for setup:

If SMS is selected, CONFIRM_SIGN_IN_WITH_SMS_CODE will be the next step.
If TOTP is selected, CONFIRM_SIGN_IN_WITH_TOTP_CODE will be the next step.
If EMAIL is selected, CONFIRM_SIGN_IN_WITH_EMAIL_CODE will be the next step.
import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONTINUE_SIGN_IN_WITH_MFA_SELECTION': {
			const { allowedMFATypes } = result.nextStep;
			// Present available MFA options to user
			// Prompt for selection
			console.log(`There are multiple MFA options available for sign in.`);
			console.log(`Select an MFA type from the allowedMfaTypes list.`);
			break;
		}
	}
}

type MfaType = 'SMS' | 'TOTP' | 'EMAIL';

async function handleMfaSelection(mfaType: MfaType) {
	const result = await confirmSignIn({ challengeResponse: mfaType });

	return handleSignInResult(result);
}
Continue sign-in with Email Setup
If the next step is CONTINUE_SIGN_IN_WITH_EMAIL_SETUP, then the user must provide an email address to complete the sign in process. Once this value has been collected from the user, call the confirmSignIn API to continue.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONTINUE_SIGN_IN_WITH_EMAIL_SETUP': {
			// Prompt the user to enter an email address they would like to use for MFA
			break;
		}
	}
}

// Then, pass the email address to `confirmSignIn`
async function confirmEmail(email: string) {
	const result = await confirmSignIn({ challengeResponse: email });

	return handleSignInResult(result);
}
Continue sign-in with TOTP Setup
The CONTINUE_SIGN_IN_WITH_TOTP_SETUP step signifies that the user must set up TOTP before they can sign in. The step returns an associated value of type TOTPSetupDetails which must be used to configure an authenticator app like Microsoft Authenticator or Google Authenticator. TOTPSetupDetails provides a helper method called getSetupURI which generates a URI that can be used, for example, in a button to open the user's installed authenticator app. For more advanced use cases, TOTPSetupDetails also contains a sharedSecret which can be used to either generate a QR code or be manually entered into an authenticator app.

Once the authenticator app is set up, the user can generate a TOTP code and provide it to the library to complete the sign in process.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONTINUE_SIGN_IN_WITH_TOTP_SETUP': {
			const { totpSetupDetails } = result.nextStep;
			const appName = 'my_app_name';
			const setupUri = totpSetupDetails.getSetupUri(appName);
			// Open setupUri with an authenticator app
			// Prompt user to enter OTP code to complete setup
			break;
		}
	}
}

// Then, pass the collected OTP code to `confirmSignIn`
async function confirmTotpCode(totpCode: string) {
	const result = await confirmSignIn({ challengeResponse: totpCode });

	return handleSignInResult(result);
}
Continue sign-in with MFA Setup Selection
If the next step is CONTINUE_SIGN_IN_WITH_MFA_SETUP_SELECTION, then the user must indicate which of the available MFA methods they would like to setup. After the user selects an MFA method to setup, your implementation must pass the selected MFA method to the confirmSignIn API.

The MFA types which are currently supported by Amplify Auth for setup are:

TOTP
EMAIL
Once Amplify receives the users selection, you can expect to handle a follow up nextStep corresponding with the selected MFA type for setup:

If EMAIL is selected, CONTINUE_SIGN_IN_WITH_EMAIL_SETUP will be the next step.
If TOTP is selected, CONTINUE_SIGN_IN_WITH_TOTP_SETUP will be the next step.
import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONTINUE_SIGN_IN_WITH_MFA_SETUP_SELECTION': {
			const { allowedMFATypes } = result.nextStep;
			// Present available MFA options to user
			// Prompt for selection
			console.log(`There are multiple MFA options available for setup.`);
			console.log(`Select an MFA type from the allowedMFATypes list.`);
			break;
		}
	}
}

type MfaType = 'SMS' | 'TOTP' | 'EMAIL';

async function handleMfaSelection(mfaType: MfaType) {
	const result = await confirmSignIn({ challengeResponse: mfaType });

	return handleSignInResult(result);
}
Confirm sign-in with Password
If the next step is CONFIRM_SIGN_IN_WITH_PASSWORD, the user must provide their password as the first factor authentication method. To handle this step, your implementation should prompt the user to enter their password. After the user enters the password, pass the value to the confirmSignIn API.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
    switch (result.nextStep.signInStep) {
        case 'CONFIRM_SIGN_IN_WITH_PASSWORD': {
            // Prompt user to enter their password
            console.log(`Please enter your password.`);
            break;
        }
    }
}

async function confirmWithPassword(password: string) {
    const result = await confirmSignIn({ challengeResponse: password });

    return handleSignInResult(result);
}
Continue sign-in with First Factor Selection
If the next step is CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION, the user must select a first factor method for authentication. After the user selects an option, your implementation should pass the selected method to the confirmSignIn API.

The first factor types which are currently supported by Amplify Auth are:

SMS_OTP
EMAIL_OTP
WEB_AUTHN
PASSWORD
PASSWORD_SRP
Depending on your configuration and what factors the user has previously setup, not all options may be available. Only the available options will be presented in availableChallenges for selection.

Once Amplify receives the user's selection via the confirmSignIn API, you can expect to handle a follow up nextStep corresponding with the first factor type selected:

If SMS_OTP is selected, CONFIRM_SIGN_IN_WITH_SMS_CODE will be the next step.
If EMAIL_OTP is selected, CONFIRM_SIGN_IN_WITH_EMAIL_CODE will be the next step.
If PASSWORD or PASSWORD_SRP is selected, CONFIRM_SIGN_IN_WITH_PASSWORD will be the next step.
If WEB_AUTHN is selected, Amplify Auth will initiate the authentication ceremony on the user's device. If successful, the next step will be DONE.
import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONTINUE_SIGN_IN_WITH_FIRST_FACTOR_SELECTION': {
			const { availableChallenges } = result.nextStep;
			// Present available first factor options to user
			// Prompt for selection
			console.log(
				`There are multiple first factor options available for sign in.`,
			);
			console.log(
				`Select a first factor type from the availableChallenges list.`,
			);
			break;
		}
	}
}

async function handleFirstFactorSelection(firstFactorType: string) {
	const result = await confirmSignIn({ challengeResponse: firstFactorType });

	return handleSignInResult(result);
}
Confirm sign-in with custom challenge
If the next step is CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE, Amplify Auth is awaiting completion of a custom authentication challenge. The challenge is based on the AWS Lambda trigger you configured as part of a custom sign in flow.

For example, your custom challenge Lambda may pass a prompt to the frontend which requires the user to enter a secret code.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONFIRM_SIGN_IN_WITH_CUSTOM_CHALLENGE': {
			const params = result.nextStep.additionalInfo;
			const hint = params.hint!;
			// Prompt user to enter custom challenge response
			console.log(hint); // `Enter the secret code`
			break;
		}
	}
}
To complete this step, you should prompt the user for the custom challenge answer, and pass the answer to the confirmSignIn API.

async function confirmCustomChallenge(answer: string) {
	const result = await confirmSignIn({ challengeResponse: answer });

	return handleSignInResult(result);
}
Special Handling on confirmSignIn

If failAuthentication=true is returned by the Lambda, Cognito will invalidate the session of the request. This is represented by a NotAuthorizedException and requires restarting the sign-in flow by calling signIn again.

Confirm sign-in with new password
If the next step is CONFIRM_SIGN_IN_WITH_NEW_PASSWORD_REQUIRED, Amplify Auth requires the user choose a new password they proceeding with the sign in.

Prompt the user for a new password and pass it to the confirmSignIn API.

See the sign-in and manage-password docs for more information.

import { type SignInOutput, confirmSignIn } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONFIRM_SIGN_IN_WITH_NEW_PASSWORD_REQUIRED': {
			// Prompt user to enter a new password
			console.log(`Please enter a new password.`);
			break;
		}
	}
}

async function confirmNewPassword(newPassword: string) {
	const result = await confirmSignIn({ challengeResponse: newPassword });

	return handleSignInResult(result);
}
Reset password
If the next step is RESET_PASSWORD, Amplify Auth requires that the user reset their password before proceeding. Use the resetPassword API to guide the user through resetting their password, then call signIn to restart the sign-in flow.

See the reset password docs for more information.

import {
	type ResetPasswordOutput,
	type SignInOutput,
	resetPassword,
} from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'RESET_PASSWORD': {
			const resetPasswordResult = await resetPassword({ username });
			// initiate reset password flow
			await handleResetPasswordResult(resetPasswordResult);
			break;
		}
	}
}

async function handleResetPasswordResult(
	resetPasswordResult: ResetPasswordOutput,
) {
	switch (resetPasswordResult.nextStep.resetPasswordStep) {
		case 'CONFIRM_RESET_PASSWORD_WITH_CODE': {
			const { codeDeliveryDetails } = resetPasswordResult.nextStep;
			console.log(
				`A confirmation code has been sent to ${codeDeliveryDetails.destination}.`,
			);
			console.log(
				`Please check your ${codeDeliveryDetails.destination} for the code.`,
			);
			break;
		}
		case 'DONE': {
			console.log(`Successfully reset password.`);
			break;
		}
	}
}
Confirm Signup
If the next step is CONFIRM_SIGN_UP, Amplify Auth requires that the user confirm their email or phone number before proceeding. Use the resendSignUpCode API to send a new sign up code to the registered email or phone number, followed by confirmSignUp to complete the sign up.

See the sign up docs for more information.

The result includes an AuthCodeDeliveryDetails member. It includes additional information about the code delivery, such as the partial phone number of the SMS recipient, which can be used to prompt the user on where to look for the code.

import {
	type SignInOutput,
	confirmSignUp,
	resendSignUpCode,
} from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'CONFIRM_SIGN_UP': {
			// Resend sign up code to the registered user
			const { destination, deliveryMedium } = await resendSignUpCode({
				username,
			});
			console.log(`A confirmation code has been sent to ${destination}.`);
			console.log(`Please check your ${deliveryMedium} for the code.`);
			break;
		}
	}
}

async function handleConfirmSignUp(username: string, confirmationCode: string) {
	await confirmSignUp({
		username,
		confirmationCode,
	});
}
Once the sign up is confirmed, call signIn again to restart the sign-in flow.

Done
The sign-in flow is complete when the next step is DONE, which means the user is successfully authenticated. As a convenience, the SignInResult also provides the isSignedIn property, which will be true if the next step is DONE.

import { type SignInOutput } from '@aws-amplify/auth';

async function handleSignInResult(result: SignInOutput) {
	switch (result.nextStep.signInStep) {
		case 'DONE': {
			// `result.isSignedIn` is `true`
			console.log(`Sign in is complete.`);
			break;
		}
	}
}

- With admin actions -
Amplify Auth can be managed with the AWS SDK's @aws-sdk/client-cognito-identity-provider package. This package is intended to use server-side, and can be used within a Function. This example focuses on the addUserToGroup action and will be defined as a custom mutation.

To get started, create an "ADMINS" group that will be used to authorize the mutation:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["ADMINS"]
})
Next, create the Function resource:

amplify/data/add-user-to-group/resource.ts
import { defineFunction } from "@aws-amplify/backend"

export const addUserToGroup = defineFunction({
  name: "add-user-to-group",
})
Then, in your auth resources, grant access for the function to perform the addUserToGroup action. Learn more about granting access to auth resources.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"
import { addUserToGroup } from "../data/add-user-to-group/resource"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["ADMINS"],
  access: (allow) => [
    allow.resource(addUserToGroup).to(["addUserToGroup"])
  ],
})
You're now ready to define the custom mutation. Here you will use the newly-created addUserToGroup function resource to handle the addUserToGroup mutation. This mutation can only be called by a user in the "ADMINS" group.

amplify/data/resource.ts
import type { ClientSchema } from "@aws-amplify/backend"
import { a, defineData } from "@aws-amplify/backend"
import { addUserToGroup } from "./resource"

const schema = a.schema({
  addUserToGroup: a
    .mutation()
    .arguments({
      userId: a.string().required(),
      groupName: a.string().required(),
    })
    .authorization((allow) => [allow.group("ADMINS")])
    .handler(a.handler.function(addUserToGroup))
    .returns(a.json())
})

export type Schema = ClientSchema<typeof schema>

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "iam",
  },
})
Lastly, create the function's handler using the exported client schema to type the handler function, and the generated env to specify the user pool ID you'd like to interact with:

amplify/data/add-user-to-group/handler.ts
import type { Schema } from "../resource"
import { env } from "$amplify/env/add-user-to-group"
import {
  AdminAddUserToGroupCommand,
  CognitoIdentityProviderClient,
} from "@aws-sdk/client-cognito-identity-provider"

type Handler = Schema["addUserToGroup"]["functionHandler"]
const client = new CognitoIdentityProviderClient()

export const handler: Handler = async (event) => {
  const { userId, groupName } = event.arguments
  const command = new AdminAddUserToGroupCommand({
    Username: userId,
    GroupName: groupName,
    UserPoolId: env.AMPLIFY_AUTH_USERPOOL_ID,
  })
  const response = await client.send(command)
  return response
}
In your frontend, use the generated client to call your mutation using the group name and the user's ID.

src/client.ts
import type { Schema } from "../amplify/data/resource"
import { generateClient } from "aws-amplify/data"

const client = generateClient<Schema>()

await client.mutations.addUserToGroup({
  groupName: "ADMINS",
  userId: "5468d468-4061-70ed-8870-45c766d26225",
})

- Manage passwords -
Amplify Auth provides a secure way for your users to change their password or recover a forgotten password.

Understand password default settings
By default, your users can retrieve access to their accounts if they forgot their password by using either their phone or email. The following are the default account recovery methods used when either phone or email are used as login options.

Login option	User account verification channel
phone	Phone Number
email	Email
email and phone	Email
Reset Password
To reset a user's password, use the resetPassword API which will send a reset code to the destination (e.g. email or SMS) based on the user's settings.

import { resetPassword } from 'aws-amplify/auth';

const output = await resetPassword({
  username: "hello@mycompany.com"
});

const { nextStep } = output;
switch (nextStep.resetPasswordStep) {
  case 'CONFIRM_RESET_PASSWORD_WITH_CODE':
    const codeDeliveryDetails = nextStep.codeDeliveryDetails;
    console.log(
      `Confirmation code was sent to ${codeDeliveryDetails.deliveryMedium}`
    );
    // Collect the confirmation code from the user and pass to confirmResetPassword.
    break;
  case 'DONE':
    console.log('Successfully reset password.');
    break;
}
To complete the password reset process, invoke the confirmResetPassword API with the code your user received and the new password they want to set.

import { confirmResetPassword } from 'aws-amplify/auth';

await confirmResetPassword({
  username: "hello@mycompany.com",
  confirmationCode: "123456",
  newPassword: "hunter3",
});
Update password
You can update a signed in user's password using the updatePassword API.

import { updatePassword } from 'aws-amplify/auth';

await updatePassword({
  oldPassword: "hunter2",
  newPassword: "hunter3",
});
Override default user account verification channel
You can always change the channel used by your authentication resources by overriding the following setting.

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';

export const auth = defineAuth({
  loginWith: {
    email: true
  },
  accountRecovery: 'EMAIL_ONLY'
});
Override default password policy
By default your password policy is set to the following:

MinLength: 8 characters
requireLowercase: true
requireUppercase: true
requireNumbers: true
requireSymbols: true
tempPasswordValidity: 3 days
You can customize the password format acceptable by your auth resource by modifying the underlying cfnUserPool resource:

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';

const backend = defineBackend({
  auth,
});
// extract L1 CfnUserPool resources
const { cfnUserPool } = backend.auth.resources.cfnResources;
// modify cfnUserPool policies directly
cfnUserPool.policies = {
  passwordPolicy: {
    minimumLength: 32,
    requireLowercase: true,
    requireNumbers: true,
    requireSymbols: true,
    requireUppercase: true,
    temporaryPasswordValidityDays: 20,
  },
}; 

- Manage WebAuthn credentials - 
WebAuthn registration and authentication are not currently supported on React Native, other passwordless features are fully supported.

Amplify Auth enables your users to associate, keep track of, and delete passkeys.

Associate WebAuthN credentials
Note that users must be authenticated to register a passkey. That also means users cannot create a passkey during sign up; consequently, they must have at least one other first factor authentication mechanism associated with their account to use WebAuthn.

You can associate a passkey using the following API:

import { associateWebAuthnCredential} from 'aws-amplify/auth';

await associateWebAuthnCredential();
The user will be prompted to register a passkey using their local authenticator. Amplify will then associate that passkey with Cognito.

List WebAuthN credentials
You can list registered passkeys using the following API:

import { listWebAuthnCredentials } from 'aws-amplify/auth';

const result = await listWebAuthnCredentials();

for (const credential of result.credentials) {
	console.log(`Credential ID: ${credential.credentialId}`);
	console.log(`Friendly Name: ${credential.friendlyCredentialName}`);
	console.log(`Relying Party ID: ${credential.relyingPartyId}`);
	console.log(`Created At: ${credential.createdAt}`);
}
Delete WebAuthN credentials
You can delete a passkey with the following API:

import { deleteWebAuthnCredential } from 'aws-amplify/auth';

const id = "credential-id-to-delete";

await deleteWebAuthnCredential({
  credentialId: id
});
Practical example
Here is a code example that uses the list and delete APIs together. In this example, the user has 3 passkeys registered. They want to list all passkeys while using a pageSize of 2 as well as delete the first passkey in the list.

import { 
  listWebAuthnCredentials,
  deleteWebAuthnCredential
} from 'aws-amplify/auth';

let passkeys = [];

const result = await listWebAuthnCredentials({ pageSize: 2 });

passkeys.push(...result.credentials);

const nextPage = await listWebAuthnCredentials({
  pageSize: 2,
  nextToken: result.nextToken,
});

passkeys.push(...nextPage.credentials);

const id = passkeys[0].credentialId;

await deleteWebAuthnCredential({
  credentialId: id
});

- Manage devices -
Amplify Auth enables you to track devices your users use for auditing, MFA, and more. Before you begin it is important to understand the terminology for device statuses:

Tracked: Every time the user signs in with a new device, the client is given the device key at the end of a successful authentication event. We use this device key to generate a salt and password verifier which is used to call the ConfirmDevice API. At this point, the device is considered to be tracked. Once the device is in a tracked state, you can use the Amazon Cognito console to see the time it started to be tracked, last authentication time, and other information about that device.
Remembered: Remembered devices are also tracked. During user authentication, the device key and secret pair assigned to a remembered device is used to authenticate the device to verify that it is the same device that the user previously used to sign in.
Not Remembered: A not-remembered device is a tracked device where Cognito has been configured to require users to "Opt-in" to remember a device, but the user has not opt-ed in to having the device remembered. This use case is used for users signing into their application from a device that they don't own.
Forgotten: a forgotten device is one removed from being remembered
Note: device tracking and remembering features are not available when using federating sign-in with external providers as devices are tracked on the upstream identity provider. These features are also not available when using Cognito's Hosted UI.

Remember devices
You can remember devices using the following:

import { rememberDevice } from 'aws-amplify/auth';

await rememberDevice();
Forget devices
You can also forget devices but note that forgotten devices are neither remembered nor tracked.

import { forgetDevice } from 'aws-amplify/auth';

await forgetDevice();
Fetch devices
You can fetch a list of remembered devices by using the following:

import { fetchDevices } from 'aws-amplify/auth';

const output = await fetchDevices();
You can now set up devices to be remembered, forgotten, and fetched.

- Manage users with Amplify console -
The User management page in the Amplify console provides a user-friendly interface for managing your application's users. You can create and manage users and groups, edit user attributes, and suspend users.

If you have not yet created an auth resource, visit the Auth setup guide.

Access User management
After you've deployed your auth resource, you can access the manager on Amplify Console.

Log in to the Amplify console and choose your app.
Select the branch you would like to access.
Select Authentication from the left navigation bar.
Then, select User management.
To create a user
On the User management page, select Users tab.
Select Create user.
In the Create user window, for Unique identifier enter a email address, username, or phone number. For Temporary password enter a password.
Choose Create user.
A user can be confirmed by using the pre-built UI components and Amplify libraries.

To create a group
On the User management page, choose the Groups tab and then choose Create group.
In the Create group window, for Title enter a name for the group.
Choose Create group.
To add a users to a group
On the User management page, choose the Groups tab.
Select the name of the group to add users to.
Choose Add users.
In the Add users to group window, choose how you want to search for users to add from the Search menu. You can choose Email, Phone number, or Username.
Add one user or multiple users to add to the group and then choose Add users.
To delete a group
On the User management page, choose the Groups tab.
In the Groups section, select the name of the group to delete.
Choose Delete.
A confirmation window is displayed. Enter Delete and choose, Confirm deletion.

- Email customization -
Customize the Verification Email
By default, Amplify Auth resources are scaffolded with email as the default method for your users to sign in. When you users sign up they receive a verification email to confirm their ownership of the email they specified during sign-up. Emails such as the verification email can be customized with your app's brand identity.

To get started, change the email attribute of loginWith from true to an object to begin customizing its default behavior:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
-   email: true, 
+   email: {
+     verificationEmailStyle: "CODE",
+     verificationEmailSubject: "Welcome to my app!",
+     verificationEmailBody: (createCode) => `Use this code to confirm your account: ${createCode()}`,
+   },
  },
})
Customize the Invitation Email
In some cases, you may set up a user account on behalf of a user in the Amplify console. In this case, Amplify Auth will send an invitation email to the user welcoming them to your application. This email includes a brief welcome message, along with the email address they can log in with and the temporary password you've set up for them.

If you'd like to customize that email, you can override the userInvitation attribute of the email object:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
-   email: true, 
+   email: {
+     // can be used in conjunction with a customized welcome email as well
+     verificationEmailStyle: "CODE",
+     verificationEmailSubject: "Welcome to my app!",
+     verificationEmailBody: (createCode) => `Use this code to confirm your account: ${createCode()}`,
+     userInvitation: {
+       emailSubject: "Welcome to my app!",
+       emailBody: (user, code) =>
+         `We're happy to have you! You can now login with username ${user()} and temporary password ${code()}`, 
+     },
+   },
  },
})
Note that when using the user and code arguments of the emailBody function, user and code are functions which must be called. Failure to call them will result in an error when your sandbox deploys.

- Triggers - 
Amplify Auth's behavior can be customized through the use of triggers. A trigger is defined as a Function, and is a mechanism to slot some logic to execute during the authentication flow. For example, you can use triggers to validate whether emails include an allowlisted domain, add a user to a group upon confirmation, or create a "UserProfile" model upon account confirmation.

Triggers translate to Cognito user pool Lambda triggers.

When you have a Lambda trigger assigned to your user pool, Amazon Cognito interrupts its default flow to request information from your function. Amazon Cognito generates a JSON event and passes it to your function. The event contains information about your user's request to create a user account, sign in, reset a password, or update an attribute. Your function then has an opportunity to take action, or to send the event back unmodified.

To get started, define a function and specify the triggers property on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {}
})
To learn more about use cases for triggers, visit the Functions examples. 

- Microsoft Entra ID (SAML) - 
Microsoft Entra ID can be configured as a SAML provider for use with Amazon Cognito. Integrating Entra ID enables you to sign in with your existing enterprise users, and maintain profiles unique to the Amplify Auth resource for use within your Amplify app. To learn more, visit the Azure documentation for SAML authentication with Microsoft Entra ID.

Note: the following guidance showcases configuration with your personal cloud sandbox. You will need to repeat the configuration steps for branch deployments after confirming functionality against your sandbox.

Start your personal cloud sandbox
To get started, define your auth resource with the appropriate redirect URIs:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      logoutUrls: ["http://localhost:3000/come-back-soon"],
      callbackUrls: ["http://localhost:3000/profile"],
    },
  },
})
Deploy to your personal cloud sandbox with npx ampx sandbox. This will generate a domain you can use to configure your new Entra ID App. After deploying your changes successfully, copy the generated domain value from amplify_outputs.json

amplify_outputs.json
{
  "auth": {
    "aws_region": "us-east-1",
    "user_pool_id": "<your-cognito-user-pool-id>",
    "user_pool_client_id": "<your-cognito-user-pool-client-id>",
    "identity_pool_id": "<your-cognito-identity-pool-id>",
    "mfa_methods": [],
    "standard_required_attributes": [
      "email"
    ],
    "username_attributes": [
      "email"
    ],
    "user_verification_types": [
      "email"
    ],
    "mfa_configuration": "OFF",
    "password_policy": {
      "min_length": 8,
      "require_numbers": true,
      "require_lowercase": true,
      "require_uppercase": true,
      "require_symbols": true
    },
    "oauth": {
      "identity_providers": [],
      "redirect_sign_in_uri": [
        "http://localhost:3000/profile"
      ],
      "redirect_sign_out_uri": [
        "http://localhost:3000/come-back-soon"
      ],
      "response_type": "code",
      "scopes": [
        "phone",
        "email",
        "openid",
        "profile",
        "aws.cognito.signin.user.admin"
      ],
      "domain": "<some-hash>.auth.us-east-1.amazoncognito.com"
    },
  },
  "version": "1"
}
Set up Microsoft Entra ID
Next, navigate to portal.azure.com, select Entra ID. In your default directory, or company's existing directory, under Manage, select Enterprise Applications

Entra ID default directory page highlighting Enterprise Applications

Afterwards, select New application, then select Create your own application. Specify a name for the application and choose Integrate any other application you don't find in the gallery (Non-gallery)

Azure portal creating a new enterprise application for Entra ID

Now that you have created the new enterprise application you can begin to configure Single Sign-on with SAML. Select Single sign-on

Entra ID enterprise application highlighting "single sign-on"

Then select SAML

Entra ID enterprise application single sign-on setup highlighting "SAML"

You will be directed to a page to set up single sign-on with SAML, which needs a few pieces of information from your Amplify Auth resource.

Entra ID set up single sign-on page with a form requiring an entity ID and reply URL

In the Basic SAML Configuration step, select Edit and populate with the appropriate values.

Label	Value
Identifier (Entity ID)	urn:amazon:cognito:sp:<your-cognito-user-pool-id>
Reply URL (Assertion Consumer Service URL)	https://<your-cognito-domain>/saml2/idpresponse
Logout Url (Optional)	https://<your-cognito-domain>/saml2/logout
Note: Amazon Cognito redirect URIs for SAML providers follow the convention:

https://<some-hash>.auth.<aws-region>.amazoncognito.com/saml2/<action>
If you are using a custom domain the route remains the same: /saml2/<action>. Learn more about configuring Amazon Cognito with SAML identity providers

Warning: there is a known limitation where upstream sign-out functionality successfully signs out of Entra ID, but fails to redirect back to the user app. This behavior is disabled by default with SAML integrations in Amplify Auth.

Save the configuration and proceed to Step 3's SAML Certificates section. Copy the App Federation Metadata Url

Entra ID set up single sign-on page highlighting the app federation metadata URL

Configure your backend with Entra ID
Now that you've configured your SAML provider with Microsoft Entra ID and copied the App Federation Metadata Url, configure your auth resource with the new SAML provider and paste the URL value into the metadataContent property:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      saml: {
        name: "MicrosoftEntraIDSAML",
        metadata: {
          metadataType: "URL",
          metadataContent: "<your-metadata-content-url>",
        },
        attributeMapping: {
          email: "http://schemas.xmlsoap.org/ws/2005/05/identity/claims/emailaddress",
        },
      },
      logoutUrls: ["http://localhost:3000/come-back-soon"],
      callbackUrls: ["http://localhost:3000/profile"],
    },
  },
})
User attributes can be found in Step 2's Attributes & Claims section, and are prefixed with a namespace by default. The example above shows mapping the default claim for the SAML user's email address, however additional attributes can be mapped.

Optionally upload the Cognito Signing Certificate
In the AWS Console, navigate to your Cognito User Pool. Select the identity provider, MicrosoftEntraIDSAML, created after configuring Amplify Auth with the Entra ID SAML provider. Select View signing certificate and download as .crt

Amazon Cognito console highlighting "view signing certificate" for SAML provider

Rename the file extension to .cer in order to upload to Azure. On the Single sign-on page, scroll down to Step 3 (SAML Certificates), and under Verification Certificates (optional), select Edit.

Entra ID single sign-on page highlighting "edit" for verification certificates

Select Require verification certificates and upload the certificate.

Entra ID verification certificate upload pane

Save your changes, and now requests to Entra ID from your Cognito User Pool will be verified.

Connect your frontend
Now your users are ready to sign in with Microsoft Entra ID. To sign in with this custom provider, specify the provider name as the name specified in your auth resource definition: MicrosoftEntraIDSAML

main.ts
import { signInWithRedirect } from "aws-amplify/auth"

signInWithRedirect({
  provider: { custom: "MicrosoftEntraIDSAML" }
})

- Grant access to auth resources -
Amplify Auth can be defined with an access property, which allows other resources to interact with auth by specifying actions.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"
import { addUserToGroup } from "../functions/add-user-to-group/resource"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  access: (allow) => [
    allow.resource(addUserToGroup).to(["addUserToGroup"])
  ],
})
When you grant a function access to another resource in your Amplify backend it will configure environment variables for that function to make SDK calls to the AWS services it has access to. Those environment variables are typed and available as part of the env object.

List of actions
Action Name	Description	Cognito IAM Actions
manageUsers	Grants CRUD access to users in the UserPool	
cognito-idp:AdminConfirmSignUp
cognito-idp:AdminCreateUser
cognito-idp:AdminDeleteUser
cognito-idp:AdminDeleteUserAttributes
cognito-idp:AdminDisableUser
cognito-idp:AdminEnableUser
cognito-idp:AdminGetUser
cognito-idp:AdminListGroupsForUser
cognito-idp:AdminRespondToAuthChallenge
cognito-idp:AdminSetUserMFAPreference
cognito-idp:AdminSetUserSettings
cognito-idp:AdminUpdateUserAttributes
cognito-idp:AdminUserGlobalSignOut
manageGroupMembership	Grants permission to add and remove users from groups	
cognito-idp:AdminAddUserToGroup
cognito-idp:AdminRemoveUserFromGroup
manageGroups	Grants CRUD access to groups in the UserPool	
cognito-idp:GetGroup
cognito-idp:ListGroups
cognito-idp:CreateGroup
cognito-idp:DeleteGroup
cognito-idp:UpdateGroup
manageUserDevices	Manages devices registered to users	
cognito-idp:AdminForgetDevice
cognito-idp:AdminGetDevice
cognito-idp:AdminListDevices
cognito-idp:AdminUpdateDeviceStatus
managePasswordRecovery	Grants permission to reset user passwords	
cognito-idp:AdminResetUserPassword
cognito-idp:AdminSetUserPassword
addUserToGroup	Grants permission to add any user to any group.	
cognito-idp:AdminAddUserToGroup
createUser	Grants permission to create new users and send welcome messages via email or SMS.	
cognito-idp:AdminCreateUser
deleteUser	Grants permission to delete any user	
cognito-idp:AdminDeleteUser
deleteUserAttributes	Grants permission to delete attributes from any user	
cognito-idp:AdminDeleteUserAttributes
disableUser	Grants permission to deactivate any user	
cognito-idp:AdminDisableUser
enableUser	Grants permission to activate any user	
cognito-idp:AdminEnableUser
forgetDevice	Grants permission to deregister any user's devices	
cognito-idp:AdminForgetDevice
getDevice	Grants permission to get information about any user's devices	
cognito-idp:AdminGetDevice
getUser	Grants permission to look up any user by user name	
cognito-idp:AdminGetUser
listUsers	Grants permission to list users and their basic details in the UserPool	
cognito-idp:ListUsers
listDevices	Grants permission to list any user's remembered devices	
cognito-idp:AdminListDevices
listGroupsForUser	Grants permission to list the groups that any user belongs to	
cognito-idp:AdminListGroupsForUser
listUsersInGroup	Grants permission to list users in the specified group	
cognito-idp:ListUsersInGroup
removeUserFromGroup	Grants permission to remove any user from any group	
cognito-idp:AdminRemoveUserFromGroup
resetUserPassword	Grants permission to reset any user's password	
cognito-idp:AdminResetUserPassword
setUserMfaPreference	Grants permission to set any user's preferred MFA method	
cognito-idp:AdminSetUserMFAPreference
setUserPassword	Grants permission to set any user's password	
cognito-idp:AdminSetUserPassword
setUserSettings	Grants permission to set user settings for any user	
cognito-idp:AdminSetUserSettings
updateDeviceStatus	Grants permission to update the status of any user's remembered devices	
cognito-idp:AdminUpdateDeviceStatus
updateUserAttributes	Grants permission to updates any user's standard or custom attributes	
cognito-idp:AdminUpdateUserAttributes

- Modify Amplify-generated Cognito resources with CDK - 
Amplify Auth provides sensible defaults for the underlying Amazon Cognito resource definitions. You can customize your authentication resource to enable it to behave exactly as needed for your use cases by modifying it directly using AWS Cloud Development Kit (CDK)

Override Cognito UserPool password policies
You can override the password policy by using the L1 cfnUserPool construct and adding a addPropertyOverride.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';

const backend = defineBackend({
  auth,
});
// extract L1 CfnUserPool resources
const { cfnUserPool } = backend.auth.resources.cfnResources;
// modify cfnUserPool policies directly
cfnUserPool.policies = {
  passwordPolicy: {
    minimumLength: 10,
    requireLowercase: true,
    requireNumbers: true,
    requireSymbols: true,
    requireUppercase: true,
    temporaryPasswordValidityDays: 20,
  },
};
Override Cognito UserPool multi-factor authentication options
While Email MFA is not yet supported with defineAuth, this feature can be enabled by modifying the underlying CDK construct.

Start by ensuring your defineAuth resource configuration includes a compatible account recovery option and a custom SES sender.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
    phone: true,
  },
  multifactor: {
    mode: "OPTIONAL",
    sms: true,
    totp: false,
  },
  // Important! The logic to resolve this value cannot determine whether email mfa is enabled when overriding the resource. 
  // Be sure to pick a recovery option appropriate for your application.
  accountRecovery: "EMAIL_AND_PHONE_WITHOUT_MFA",
  senders: {
    email: {
      fromEmail: "registrations@example.com",
    },
  },
})
Next, extend the underlying CDK construct by activating Amazon Cognito's Advanced Security Features (ASF) and add EMAIL_OTP to the enabled MFA options.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"
import { auth } from "./auth/resource"

const backend = defineBackend({
  auth,
})

const { cfnUserPool } = backend.auth.resources.cfnResources

// enable ASF
cfnUserPool.userPoolAddOns = {
  advancedSecurityMode: "AUDIT",
}

// add email mfa
// https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-cognito-userpool.html#cfn-cognito-userpool-enabledmfas
cfnUserPool.enabledMfas = [...(cfnUserPool.enabledMfas || []), "EMAIL_OTP"]
Override Cognito UserPool to enable passwordless sign-in methods
You can modify the underlying Cognito user pool resource to enable sign in with passwordless methods. Learn more about passwordless sign-in methods.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"
import { auth } from "./auth/resource"

const backend = defineBackend({
  auth,
})

const { cfnResources } = backend.auth.resources;
const { cfnUserPool, cfnUserPoolClient } = cfnResources;

cfnUserPool.addPropertyOverride(
	'Policies.SignInPolicy.AllowedFirstAuthFactors',
	['PASSWORD', 'WEB_AUTHN', 'EMAIL_OTP', 'SMS_OTP']
);

cfnUserPoolClient.explicitAuthFlows = [
	'ALLOW_REFRESH_TOKEN_AUTH',
	'ALLOW_USER_AUTH'
];

/* Needed for WebAuthn */
cfnUserPool.addPropertyOverride('WebAuthnRelyingPartyID', '<RELYING_PARTY>');
cfnUserPool.addPropertyOverride('WebAuthnUserVerification', 'preferred');

- Moving to production - 
Amplify Auth provisions Amazon Cognito resources that are provisioned with limited capabilities for sending email and SMS messages. In its default state, it is not intended to handle production workloads, but is sufficient for developing your application and associated business logic.

Email
Cognito provides a default email functionality that limits how many emails can be sent in one day. When considering production workloads, Cognito can be configured to send emails using Amazon Simple Email Service (Amazon SES).

All new AWS accounts default to a "sandbox" status with Amazon SES. This comes with the primary caveat that you can only send mail to verified email addresses and domains

To get started with Amazon SES in production, you must first request production access. Once you submit your request the submission cannot be modified, however you will receive a response from AWS within 24 hours.

After you have configured your account for production access and have verified your sender email, you can configure your Cognito user pool to send emails using the verified sender:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/react/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  senders: {
    email: {
      // configure using the email registered and verified in Amazon SES
      fromEmail: "registrations@example.com",
    },
  },
})
Now when emails are sent on new user sign-ups, password resets, etc., the sending account will be your verified email! To customize further, you can change the display name of the sender, or optionally apply a custom address for your users to reply.

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/react/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  senders: {
    email: {
      fromEmail: "registrations@example.com",
      fromName: "MyApp",
      replyTo: "inquiries@example.com"
    },
  },
})
SMS
In order to send SMS authentication codes, you must request an origination number. Authentication codes will be sent from the origination number. If your AWS account is in the SMS sandbox, you must also add a destination phone number, which can be done by going to the Amazon Pinpoint Console, selecting SMS and voice in the navigation pane, and selecting Add phone number in the Destination phone numbers tab. To check if your AWS account is in the SMS sandbox, go to the SNS console, select the Text messaging (SMS) tab from the navigation pane, and check the status under the Account information section.

- Advanced workflows - 
Subscribing to Events
You can take specific actions when users sign-in or sign-out by subscribing to authentication events in your app. Please see our Hub Module Developer Guide for more information.

Identity Pool Federation
You can alternatively create your own custom credentials provider to get AWS credentials directly from Cognito Federated Identities and not use User Pool federation. You must supply the custom credentials provider to Amplify via the Amplify.configure method call. Below, you can see sample code of how such a custom provider can be built to achieve the use case.

import { Amplify } from 'aws-amplify';
import {
  fetchAuthSession,
  CredentialsAndIdentityIdProvider,
  CredentialsAndIdentityId,
  GetCredentialsOptions,
  AuthTokens,
} from 'aws-amplify/auth';

// Note: This example requires installing `@aws-sdk/client-cognito-identity` to obtain Cognito credentials
// npm add @aws-sdk/client-cognito-identity
import { CognitoIdentity } from '@aws-sdk/client-cognito-identity';

// You can make use of the sdk to get identityId and credentials
const cognitoidentity = new CognitoIdentity({
  region: '<region-from-config>',
});

// Note: The custom provider class must implement CredentialsAndIdentityIdProvider
class CustomCredentialsProvider implements CredentialsAndIdentityIdProvider {

  // Example class member that holds the login information
  federatedLogin?: {
    domain: string,
    token: string
  };

  // Custom method to load the federated login information
  loadFederatedLogin(login?: typeof this.federatedLogin) {
    // You may also persist this by caching if needed
    this.federatedLogin = login;
  }

  async getCredentialsAndIdentityId(
    getCredentialsOptions: GetCredentialsOptions
  ): Promise<CredentialsAndIdentityId | undefined> {
    try {

      // You can add in some validation to check if the token is available before proceeding
      // You can also refresh the token if it's expired before proceeding

      const getIdResult = await cognitoidentity.getId({
        // Get the identityPoolId from config
        IdentityPoolId: '<identity-pool-id-from-config>',
        Logins: { [this.federatedLogin.domain]: this.federatedLogin.token },
      });

      const cognitoCredentialsResult = await cognitoidentity.getCredentialsForIdentity({
        IdentityId: getIdResult.IdentityId,
        Logins: { [this.federatedLogin.domain]: this.federatedLogin.token },
      });

      const credentials: CredentialsAndIdentityId = {
        credentials: {
          accessKeyId: cognitoCredentialsResult.Credentials?.AccessKeyId,
          secretAccessKey: cognitoCredentialsResult.Credentials?.SecretKey,
          sessionToken: cognitoCredentialsResult.Credentials?.SessionToken,
          expiration: cognitoCredentialsResult.Credentials?.Expiration,
        },
        identityId: getIdResult.IdentityId,
      };
      return credentials;
    } catch (e) {
      console.log('Error getting credentials: ', e);
    }
  }
  // Implement this to clear any cached credentials and identityId. This can be called when signing out of the federation service.
  clearCredentialsAndIdentityId(): void {}
}

// Create an instance of your custom provider
const customCredentialsProvider = new CustomCredentialsProvider();
Amplify.configure(awsconfig, {
  Auth: {
    // Supply the custom credentials provider to Amplify
    credentialsProvider: customCredentialsProvider
  },
});
Now that the custom credentials provider is built and supplied to Amplify.configure, let's look at how you can use the custom credentials provider to finish federation into Cognito identity pool.

Facebook Sign-in (React Native - Expo)
import Expo from 'expo';
import React from 'react';
import { fetchAuthSession } from 'aws-amplify/auth';

const App = () => {
  const signIn = async () => {
    const { type, token, expires } =
      await Expo.Facebook.logInWithReadPermissionsAsync(
        'YOUR_FACEBOOK_APP_ID',
        {
          permissions: ['public_profile']
        }
      );
    if (type === 'success') {
      // sign in with federated identity
      try {
        customCredentialsProvider.loadFederatedLogin({
          domain: 'graph.facebook.com',
          token: token
        });
        const fetchSessionResult = await fetchAuthSession(); // will return the credentials
        console.log('fetchSessionResult: ', fetchSessionResult);
      } catch (err) {
        console.log(err);
      }
    }
  };

  // ...

  return (
    <View style={styles.container}>
      <Button title="FBSignIn" onPress={signIn} />
    </View>
  );
};
Lambda Triggers
With the triggers property of defineAuth and defineFunction from the new Functions implementation, you can define Lambda Triggers for your Cognito User Pool. These enable you to add custom functionality to your registration and authentication flows. Check out a preSignUp hook example here.

Pre Authentication and Pre Sign-up Lambda triggers
If you have a Pre Authentication Lambda trigger enabled, you can pass clientMetadata as an option for signIn. This metadata can be used to implement additional validations around authentication.

import { signIn } from 'aws-amplify/auth';

async function handleSignIn(username: string, password: string) {
  try {
    await signIn({
      username,
      password,
      options: {
        clientMetadata: {} // Optional, an object of key-value pairs which can contain any key and will be passed to your Lambda trigger as-is.
      }
    });
  } catch (err) {
    console.log(err);
  }
}
Passing metadata to other Lambda triggers
Many Cognito Lambda Triggers also accept unsanitized key/value pairs in the form of a clientMetadata attribute. This attribute can be specified for various Auth APIs which result in Cognito Lambda Trigger execution.

These APIs include:

signIn
signUp
confirmSignIn
confirmSignUp
resetPassword
confirmResetPassword
resendSignUpCode
updateUserAttributes
Please note that some of triggers which accept a validationData attribute will use clientMetadata as the value for validationData. Exercise caution with using clientMetadata when you are relying on validationData.

Working with AWS service objects
You can use AWS Service Interface Objects to work with AWS Services in authenticated State. You can call methods on any AWS Service interface object by passing your credentials from Amplify fetchAuthSession to the service call constructor:

import { fetchAuthSession } from 'aws-amplify/auth';
import Route53 from 'aws-sdk/clients/route53';

async function changeResourceRecordSets() {
  try {
    const { credentials } = await fetchAuthSession();

    const route53 = new Route53({
      apiVersion: '2013-04-01',
      credentials
    });

    // more code working with route53 object
    //route53.changeResourceRecordSets();
  } catch (err) {
    console.log(err);
  }
}
Note: To work with Service Interface Objects, your Amazon Cognito users' IAM role must have the appropriate permissions to call the requested services.

Custom Token providers
Create a custom Auth token provider for situations where you would like provide your own tokens for a service. For example, using OIDC Auth with AppSync. You must supply the token provider to Amplify via the Amplify.configure method call. Below, you can see sample code of how such a custom provider can be built to achieve the use case.

import { Amplify } from 'aws-amplify';
import { TokenProvider, decodeJWT } from 'aws-amplify/auth';

// ...

const myTokenProvider: TokenProvider = {
  async getTokens({ forceRefresh } = {}) {
    if (forceRefresh) {
      // try to obtain new tokens if possible
    }

    const accessTokenString = '<insert JWT from provider>';
    const idTokenString = '<insert JWT from provider>';
    
    return {
      accessToken: decodeJWT(accessTokenString),
      idToken: decodeJWT(idTokenString),
    };
  },
};

Amplify.configure(awsconfig, {
  Auth: {
    tokenProvider: myTokenProvider
  }
});


- Use existing Cognito resources - 
Amplify Auth can be configured to use an existing Amazon Cognito user pool and identity pool. If you are in a team setting or part of a company that has previously created auth resources, you can configure the client library directly, or maintain references with AWS Cloud Development Kit (AWS CDK) in your Amplify backend.

Note: when using existing auth resources, it may be necessary to add additional policies or permissions for your authenticated and unauthenticated IAM roles. These changes must be performed manually.

Use auth resources without an Amplify backend
You can use existing resources without an Amplify backend by configuring the client library directly.

src/main.ts
import { Amplify } from "aws-amplify"

Amplify.configure({
  Auth: {
    Cognito: {
      userPoolId: "<your-cognito-user-pool-id>",
      userPoolClientId: "<your-cognito-user-pool-client-id>",
      identityPoolId: "<your-cognito-identity-pool-id>",
      loginWith: {
        email: true,
      },
      signUpVerificationMethod: "code",
      userAttributes: {
        email: {
          required: true,
        },
      },
      allowGuestAccess: true,
      passwordFormat: {
        minLength: 8,
        requireLowercase: true,
        requireUppercase: true,
        requireNumbers: true,
        requireSpecialCharacters: true,
      },
    },
  },
})
Use auth resources with an Amplify backend
Amplify cannot modify the configuration of your referenced resources and only captures the resource configuration at the time of reference, any subsequent changes made to the referenced resources will not be automatically reflected in your Amplify backend.

If you have created Amazon Cognito resources outside of the context of your Amplify app such as creating resources through the AWS Console or consuming resources created by a separate team, you can use referenceAuth to reference the existing resources. It requires a user pool, a user pool client, identity pool, and an authenticated & unauthenticated IAM role configured on your identity pool.

amplify/auth/resource.ts
import { referenceAuth } from '@aws-amplify/backend';

export const auth = referenceAuth({
  userPoolId: 'us-east-1_xxxx',
  identityPoolId: 'us-east-1:b57b7c3b-9c95-43e4-9266-xxxx',
  authRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthauthenticatedU-xxxx',
  unauthRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthunauthenticate-xxxx',
  userPoolClientId: 'xxxx',
});
IAM policies specific to your Amplify application will be appended to your authenticated and unauthenticated roles, and applications using the referenced resource will be able to create users in the Cognito user pool and identities in the Cognito identity pool.

You can also use the access property to grant permissions to your auth resource from other Amplify backend resources. For example, if you have a function that needs to retrieve details about a user:

amplify/auth/resource.ts
import { referenceAuth } from '@aws-amplify/backend';
import { getUser } from "../functions/get-user/resource";

export const auth = referenceAuth({
  userPoolId: 'us-east-1_xxxx',
  identityPoolId: 'us-east-1:b57b7c3b-9c95-43e4-9266-xxxx',
  authRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthauthenticatedU-xxxx',
  unauthRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthunauthenticate-xxxx',
  userPoolClientId: 'xxxx',
  access: (allow) => [
    allow.resource(getUser).to(["getUser"]),
  ],
});
Additionally, you can also use the groups property to reference groups in your user pool. This is useful if you want to work with groups in your application and provide access to resources such as storage based on group membership.

amplify/auth/resource.ts
import { referenceAuth } from '@aws-amplify/backend';
import { getUser } from "../functions/get-user/resource";

export const auth = referenceAuth({
  userPoolId: 'us-east-1_xxxx',
  identityPoolId: 'us-east-1:b57b7c3b-9c95-43e4-9266-xxxx',
  authRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthauthenticatedU-xxxx',
  unauthRoleArn: 'arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthunauthenticate-xxxx',
  userPoolClientId: 'xxxx',
  groups: {
    admin: "arn:aws:iam::xxxx:role/amplify-xxxx-mai-amplifyAuthadminGroupRole-xxxx",
  },
});
In a team setting you may want to reference a different set of auth resources depending on the deployment context. For instance if you have a staging branch that should reuse resources from a separate "staging" environment compared to a production branch that should reuse resources from the separate "production" environment. In this case we recommend using environment variables.

amplify/auth/resource.ts
import { referenceAuth } from '@aws-amplify/backend';

export const auth = referenceAuth({
  userPoolId: process.env.MY_USER_POOL_ID,
  identityPoolId: process.env.MY_IDENTITY_POOL_ID,
  authRoleArn: process.env.MY_AUTH_ROLE_ARN,
  unauthRoleArn: process.env.MY_UNAUTH_ROLE_ARN,
  userPoolClientId: process.env.MY_USER_POOL_CLIENT_ID,
});
Environment variables must be configured separately on your machine for sandbox deployments and Amplify console for branch deployments.

- API Reference - 
associateWebAuthnCredential
Registers a new passkey for an authenticated user
Throws
PasskeyError:
Thrown when intermediate state is invalid
AuthError:
Thrown when user is unauthenticated
StartWebAuthnRegistrationException
Thrown due to a service error retrieving WebAuthn registration options
CompleteWebAuthnRegistrationException
Thrown due to a service error when verifying WebAuthn registration result
Returns
Promise<void>
autoSignIn
Signs a user in automatically after finishing the sign-up process.
This API will automatically sign a user in if the autoSignIn flow has been completed in the following cases:
User confirmed their account with a verification code sent to their phone or email (default option).
User confirmed their account with a verification link sent to their phone or email. In order to enable this option you need to go to the Amazon Cognito console, look for your userpool, then go to the Messaging tab and enable link mode inside the Verification message option. Finally you need to define the signUpVerificationMethod in your Auth config.
Throws
AutoSignInException- Thrown when the autoSignIn flow has not started, or has been cancelled/completed.
Returns
Promise<SignInOutput>
Output type for Cognito signIn API.
confirmResetPassword
Confirms the new password and verification code to reset the password.
Parameters
Option	Required	Type	Description
input	true	ConfirmResetPasswordInput	
The ConfirmResetPasswordInput object.
Throws
ConfirmForgotPasswordException Thrown due to an invalid confirmation code or password.
AuthValidationErrorCode Thrown due to an empty confirmation code, password or username.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
confirmSignIn
Continues or completes the sign in process when required by the initial call to signIn.
Parameters
Option	Required	Type	Description
input	true	ConfirmSignInInput	
The ConfirmSignInInput object
Throws
VerifySoftwareTokenException: Thrown due to an invalid MFA token.
RespondToAuthChallengeException: Thrown due to an invalid auth challenge response.
AssociateSoftwareTokenException: Thrown due to a service error during the MFA setup process.
AuthValidationErrorCode: Thrown when challengeResponse is not defined.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<ConfirmSignInOutput>
Output type for Cognito confirmSignIn API.
confirmSignUp
Confirms a new user account.
Parameters
Option	Required	Type	Description
input	true	ConfirmSignUpInput	
The ConfirmSignUpInput object.
Throws
ConfirmSignUpException Thrown due to an invalid confirmation code.
AuthValidationErrorCode Thrown due to an empty confirmation code
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<ConfirmSignUpOutput>
Output type for Cognito confirmSignUp API.
confirmUserAttribute
Confirms a user attribute with the confirmation code.
Parameters
Option	Required	Type	Description
input	true	ConfirmUserAttributeInput	
The ConfirmUserAttributeInput object
Throws
AuthValidationErrorCode - Thrown when confirmationCode is not defined.
VerifyUserAttributeException - Thrown due to an invalid confirmation code or attribute.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
decodeJWT
Decodes payload of JWT token
Parameters
Option	Required	Type	Description
token	true	string	
A string representing a token to be decoded
Throws
Error - Throws error when token is invalid or payload malformed.
Returns
JWT
deleteUser
Deletes a user from the user pool while authenticated.
Throws
DeleteUserException
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
deleteUserAttributes
Deletes user attributes.
Parameters
Option	Required	Type	Description
input	true	DeleteUserAttributesInput	
The DeleteUserAttributesInput object
Throws
DeleteUserAttributesException - Thrown due to invalid attribute.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
deleteWebAuthnCredential
Delete a registered credential for an authenticated user by credentialId
Parameters
Option	Required	Type	Description
input	true	DeleteWebAuthnCredentialInput	
The delete input parameters including the credentialId
Throws
AuthError:
Thrown when user is unauthenticated
DeleteWebAuthnCredentialException
Thrown due to a service error when deleting a WebAuthn credential
Returns
Promise<void>
fetchAuthSession
Fetch the auth session including the tokens and credentials if they are available. By default it does not refresh the auth tokens or credentials if they are loaded in storage already. You can force a refresh with { forceRefresh: true } input.
Parameters
Option	Required	Type	Description
options	false	FetchAuthSessionOptions	
Options configuring the fetch behavior.
Throws
AuthError - Throws error when session information cannot be refreshed.
Returns
Promise<AuthSession>
fetchDevices
Fetches devices that have been remembered using rememberDevice for the currently authenticated user.
Throws
ListDevicesException
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<FetchDevicesOutput>
Output type for Cognito fetchDevices API.
fetchMFAPreference
Fetches the preferred MFA setting and enabled MFA settings for the user.
Throws
GetUserException : error thrown when the service fails to fetch MFA preference and settings.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<FetchMFAPreferenceOutput>
fetchUserAttributes
Fetches the current user attributes while authenticated.
Throws
GetUserException - Cognito service errors thrown when the service is not able to get the user.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<Partial<Record<UserAttributeKey, string>>>
Make all properties in T optional
forgetDevice
Forget a remembered device while authenticated.
Parameters
Option	Required	Type	Description
input	false	AuthForgetDeviceInput	
The ForgetDeviceInput object.
Throws
ForgetDeviceException - Cognito service errors thrown when forgetting device with invalid device key
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
getCurrentUser
Gets the current user from the idToken.
Throws
InitiateAuthException - Thrown when the service fails to refresh the tokens.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<AuthUser>
Holds the user information along with the sign in details.
listWebAuthnCredentials
Lists registered credentials for an authenticated user
Parameters
Option	Required	Type	Description
input	false	ListWebAuthnCredentialsInput	
The list input parameters including page size and next token.
Throws
AuthError:
Thrown when user is unauthenticated
ListWebAuthnCredentialsException
Thrown due to a service error when listing WebAuthn credentials
Returns
Promise<ListWebAuthnCredentialsOutput>
Output type for Cognito listWebAuthnCredentials API.
rememberDevice
Marks device as remembered while authenticated.
Throws
UpdateDeviceStatusException - Cognito service errors thrown when setting device status to remembered using an invalid device key.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
resendSignUpCode
Resend the confirmation code while signing up
Parameters
Option	Required	Type	Description
input	true	ResendSignUpCodeInput	
The ResendSignUpCodeInput object
Throws
service:ResendConfirmationException - Cognito service errors thrown when resending the code.
validation:AuthValidationErrorCode - Validation errors thrown either username are not defined.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<ResendSignUpCodeOutput>
Output type for Cognito resendSignUpCode API.
resetPassword
Resets a user's password.
Parameters
Option	Required	Type	Description
input	true	ResetPasswordInput	
The ResetPasswordInput object.
Throws
ForgotPasswordException Thrown due to an invalid confirmation code or password.
AuthValidationErrorCode Thrown due to an empty username.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<ResetPasswordOutput>
Output type for Cognito resetPassword API.
sendUserAttributeVerificationCode
Resends user's confirmation code when updating attributes while authenticated.
Parameters
Option	Required	Type	Description
input	true	SendUserAttributeVerificationCodeInput	
The SendUserAttributeVerificationCodeInput object
Throws
GetUserAttributeVerificationException
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<SendUserAttributeVerificationCodeOutput>
Output type for Cognito sendUserAttributeVerificationCode API.
setUpTOTP
Sets up TOTP for the user.
Throws
AssociateSoftwareTokenException Thrown if a service occurs while setting up TOTP.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<SetUpTOTPOutput>
Output type for Cognito setUpTOTP API.
signIn
Signs a user in
Parameters
Option	Required	Type	Description
input	true	SignInInput	
The SignInInput object
Throws
service:InitiateAuthException, RespondToAuthChallengeException - Cognito service errors thrown during the sign-in process.
validation:AuthValidationErrorCode - Validation errors thrown when either username or password are not defined.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<SignInOutput>
Output type for Cognito signIn API.
signInWithRedirect
Signs in a user with OAuth. Redirects the application to an Identity Provider.
Parameters
Option	Required	Type	Description
input	false	AuthSignInWithRedirectInput	
The SignInWithRedirectInput object, if empty it will redirect to Cognito HostedUI
Throws
AuthTokenConfigException- Thrown when the user pool config is invalid.
OAuthNotConfigureException- Thrown when the oauth config is invalid.
Returns
Promise<void>
signOut
Signs a user out
Parameters
Option	Required	Type	Description
input	false	AuthSignOutInput	
The SignOutInput object
Throws
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
signUp
Creates a user
Parameters
Option	Required	Type	Description
input	true	SignUpInput	
The SignUpInput object
Throws
service:SignUpException - Cognito service errors thrown during the sign-up process.
validation:AuthValidationErrorCode - Validation errors thrown either username or password are not defined.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<SignUpOutput>
Output type for Cognito signUp API.
updateMFAPreference
Updates the MFA preference of the user.
Parameters
Option	Required	Type	Description
input	true	UpdateMFAPreferenceInput	
The UpdateMFAPreferenceInput object.
Throws
SetUserMFAPreferenceException - Service error thrown when the MFA preference cannot be updated.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
updatePassword
Updates user's password while authenticated.
Parameters
Option	Required	Type	Description
input	true	AuthUpdatePasswordInput	
The UpdatePasswordInput object.
Throws
ChangePasswordException - Cognito service errors thrown when updating a password.
AuthValidationErrorCode - Validation errors thrown when oldPassword or newPassword are empty.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
updateUserAttribute
Updates user's attribute while authenticated.
Parameters
Option	Required	Type	Description
input	true	UpdateUserAttributeInput	
The UpdateUserAttributeInput object
Throws
UpdateUserAttributesException
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<UpdateUserAttributeOutput>
Output type for Cognito updateUserAttribute API.
updateUserAttributes
Updates user's attributes while authenticated.
Parameters
Option	Required	Type	Description
input	true	UpdateUserAttributesInput	
The UpdateUserAttributesInput object
Throws
UpdateUserAttributesException
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<UpdateUserAttributesOutput>
Output type for Cognito updateUserAttributes API.
verifyTOTPSetup
Verifies an OTP code retrieved from an associated authentication app.
Parameters
Option	Required	Type	Description
input	true	VerifyTOTPSetupInput	
The VerifyTOTPSetupInput
Throws
VerifySoftwareTokenException: Thrown due to an invalid MFA token.
AuthValidationErrorCode: Thrown when code is not defined.
AuthTokenConfigException- Thrown when the token provider config is invalid.
Returns
Promise<void>
Link Color Legend
Interface
Reference
Other

- Set up Amplify Data - 
In this guide, you will learn how to set up Amplify Data. This includes building a real-time API and database using TypeScript to define your data model, and securing your API with authorization rules. We will also explore using AWS Lambda to scale to custom use cases.

Before you begin, you will need:

Node.js v18.16.0 or later
npm v6.14.4 or later
git v2.14.1 or later
With Amplify Data, you can build a secure, real-time API backed by a database in minutes. After you define your data model using TypeScript, Amplify will deploy a real-time API for you. This API is powered by AWS AppSync and connected to an Amazon DynamoDB database. You can secure your API with authorization rules and scale to custom use cases with AWS Lambda.

Building your data backend
If you've run npm create amplify@latest already, you should see an amplify/data/resource.ts file, which is the central location to configure your data backend. The most important element is the schema object, which defines your backend data models (a.model()) and custom queries (a.query()), mutations (a.mutation()), and subscriptions (a.subscription()).

amplify/data/resource.ts
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';

const schema = a.schema({
  Todo: a.model({
      content: a.string(),
      isDone: a.boolean()
    })
    .authorization(allow => [allow.publicApiKey()])
});

// Used for code completion / highlighting when making requests from frontend
export type Schema = ClientSchema<typeof schema>;

// defines the data resource to be deployed
export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: { expiresInDays: 30 }
  }
});
Every a.model() automatically creates the following resources in the cloud:

a DynamoDB database table to store records
query and mutation APIs to create, read (list/get), update, and delete records
createdAt and updatedAt fields that help you keep track of when each record was initially created or when it was last updated
real-time APIs to subscribe for create, update, and delete events of records
The allow.publicApiKey() rule designates that anyone authenticated using an API key can create, read, update, and delete todos.

To deploy these resources to your cloud sandbox, run the following CLI command in your terminal:

Terminal
npx ampx sandbox
Connect your application code to the data backend
Once the cloud sandbox is up and running, it will also create an amplify_outputs.json file, which includes the relevant connection information to your data backend, like your API endpoint URL and API key.

To connect your frontend code to your backend, you need to:

Configure the Amplify library with the Amplify client configuration file (amplify_outputs.json)
Generate a new API client from the Amplify library
Make an API request with end-to-end type-safety
First, install the Amplify client library to your project:

Terminal
npm add aws-amplify
In your app's entry point, typically main.tsx for React apps created using Vite, make the following edits:

src/main.tsx
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
Write data to your backend
Let's first add a button to create a new todo item. To make a "create Todo" API request, generate the data client using generateClient() in your frontend code, and then call .create() operation for the Todo model. The Data client is a fully typed client that gives you in-IDE code completion. To enable this in-IDE code completion capability, pass in the Schema type to the generateClient function.

src/TodoList.tsx
import type { Schema } from '../amplify/data/resource'
import { generateClient } from 'aws-amplify/data'

const client = generateClient<Schema>()

export default function TodoList() {
  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false
    })
  }

  return <div>
    <button onClick={createTodo}>Add new todo</button>
  </div>
}
Run the application in local development mode with npm run dev and check your network tab after creating a todo. You should see a successful request to a /graphql endpoint.

Try playing around with the code completion of .update(...) and .delete(...) to get a sense of other mutation operations.

Read data from your backend
Next, list all your todos and then refetch the todos after a todo has been added:

src/TodoList.tsx
import { useState, useEffect } from "react";
import type { Schema } from "../amplify/data/resource";
import { generateClient } from "aws-amplify/data";

const client = generateClient<Schema>();

export default function TodoList() {
  const [todos, setTodos] = useState<Schema["Todo"]["type"][]>([]);

  const fetchTodos = async () => {
    const { data: items, errors } = await client.models.Todo.list();
    setTodos(items);
  };

  useEffect(() => {
    fetchTodos();
  }, []);

  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false,
    });

    fetchTodos();
  }

  return (
    <div>
      <button onClick={createTodo}>Add new todo</button>
      <ul>
        {todos.map(({ id, content }) => (
          <li key={id}>{content}</li>
        ))}
      </ul>
    </div>
  );
}
Subscribe to real-time updates
You can also use observeQuery to subscribe to a live feed of your backend data. Let's refactor the code to use a real-time observeQuery instead.

src/App.tsx
import type { Schema } from "../amplify/data/resource";
import { useState, useEffect } from "react";
import { generateClient } from "aws-amplify/data";

const client = generateClient<Schema>();

export default function TodoList() {
  const [todos, setTodos] = useState<Schema["Todo"]["type"][]>([]);

  useEffect(() => {
    const sub = client.models.Todo.observeQuery().subscribe({
      next: ({ items }) => {
        setTodos([...items]);
      },
    });

    return () => sub.unsubscribe();
  }, []);

  const createTodo = async () => {
    await client.models.Todo.create({
      content: window.prompt("Todo content?"),
      isDone: false,
    });
    // no more manual refetchTodos required!
    // - fetchTodos()
  };

  return (
    <div>
      <button onClick={createTodo}>Add new todo</button>
      <ul>
        {todos.map(({ id, content }) => (
          <li key={id}>{content}</li>
        ))}
      </ul>
    </div>
  );
}
Conclusion
Success! You've learned how to create your first real-time API and database with Amplify Data.

- Connect your app code to API -
In this guide, you will connect your application code to the backend API using the Amplify Libraries. Before you begin, you will need:

Your cloud sandbox with an Amplify Data resource up and running (npx ampx sandbox)
A frontend application set up with the Amplify library installed
npm installed
Configure the Amplify Library
When you deploy you're iterating on your backend (npx ampx sandbox), an amplify_outputs.json file is generated for you. This file contains your API's endpoint information and auth configurations. Add the following code to your app's entrypoint to initialize and configure the Amplify client library:

import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
Generate the Amplify Data client
Once the Amplify library is configured, you can generate a "Data client" for your frontend code to make fully-typed API requests to your backend.

If you're using Amplify with a JavaScript-only frontend (i.e. not TypeScript), then you can still get a fully-typed data fetching experience by annotating the generated client with a JSDoc comment. Select the JavaScript in the code block below to see how.

To generate a new Data client, use the following code:

TypeScript
JavaScript
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

// Now you should be able to make CRUDL operations with the
// Data client
const fetchTodos = async () => {
  const { data: todos, errors } = await client.models.Todo.list();
};
Configure authorization mode
The Authorization Mode determines how a request should be authorized with the backend. By default, Amplify Data uses the "userPool" authorization which uses the signed-in user credentials to sign an API request. If you use a allow.publicApiKey() authorization rules for your data models, you need to use "apiKey" as an authorization mode. Review Customize your auth rules to learn more about which authorization modes to choose for which type of request. A Default Authorization Mode is provided as part of the amplify_outputs.json that is generated upon a successful deployment.

You can generate different Data clients with different authorization modes or pass in the authorization mode at the request time.

Set authorization mode on a per-client basis
To apply the same authorization mode on all requests from a Data client, specify the authMode parameter on the generateClient function.

API Key
Amazon Cognito user pool
AWS IAM (including Amazon Cognito identity pool roles)
OpenID Connect (OIDC)
Lambda Authorizer
Use "API Key" as your authorization mode when if defined the allow.publicApiKey() authorization rule.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>({
  authMode: 'apiKey',
});
Set authorization mode on the request-level
You can also specify the authorization mode on each individual API request. This is useful if your application typically only uses one authorization mode with a small number of exceptions.

API Key
Amazon Cognito user pool
AWS IAM (including Amazon Cognito identity pool roles)
OpenID Connect (OIDC)
Lambda Authorizer
const { data: todos, errors } = await client.models.Todo.list({
  authMode: 'apiKey',
});
Set custom request headers
When working with the Amplify Data endpoint, you may need to set request headers for authorization purposes or to pass additional metadata from your frontend to the backend API.

This is done by specifying a headers parameter into the configuration. You can define headers either on a per Data client-level or on a per-request level:

Custom headers per Data client
Custom headers per request
import type { Schema } from '../amplify/data/resource';
import { generateClient } from 'aws-amplify/data';

const client = generateClient<Schema>({
  headers: {
    'My-Custom-Header': 'my value',
  },
});
The examples above show you how to set static headers but you can also programmatically set headers by specifying an async function for headers:

Custom headers per Data client
Custom headers per request
import type { Schema } from '../amplify/data/resource';
import { generateClient } from 'aws-amplify/data';

const client = generateClient<Schema>({
  headers: async (requestOptions) => {
    console.log(requestOptions);
    /* The request options allow you to customize your headers based on the request options such
       as http method, headers, request URI, and query string. These options are typically used
       to create a request signature.
    {
      method: '...',
      headers: { },
      uri: '/',
      queryString: ""
    }
    */
    return {
      'My-Custom-Header': 'my value',
    };
  },
});
Use an additional Data endpoint
If you have an additional Data endpoint that you're managing with a different Amplify project or through other means, this section will show you how to utilize that endpoint in your frontend code.

This is done by specifying the endpoint parameter on the generateClient function.

import { generateClient } from 'aws-amplify/data';

const client = generateClient({
  endpoint: 'https://my-other-endpoint.com/graphql',
});
If this Data endpoint shares its authorization configuration (for example, both endpoints share the same user pool and/or identity pool as the one in your amplify_outputs.json file), you can specify the authMode parameter on generateClient.

const client = generateClient({
  endpoint: 'https://my-other-endpoint.com/graphql',
  authMode: 'userPool',
});
If the endpoint uses API Key authorization, you can pass in the apiKey parameter on generateClient.

const client = generateClient({
  endpoint: 'https://my-other-endpoint.com/graphql',
  authMode: 'apiKey',
  apiKey: 'my-api-key',
});
If the endpoint uses a different authorization configuration, you can manually pass in the authorization header using the instructions in the Set custom request headers section.

- Create, update, and delete application data - 
In this guide, you will learn how to create, update, and delete your data using Amplify Libraries' Data client.

Before you begin, you will need:

An application connected to the API
Create an item
You can create an item by first generating the Data client with your backend Data schema. Then you can add an item:

import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource'

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create({
  content: "My new todo",
  isDone: true,
})
Note: You do not need to specify createdAt or updatedAt fields because Amplify automatically populates these fields for you.

Update an item
To update the item, use the update function:

import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource';

const client = generateClient<Schema>();

const todo = {
  id: 'some_id',
  content: 'Updated content',
};

const { data: updatedTodo, errors } = await client.models.Todo.update(todo);
Notes:

You do not need to specify the updatedAt field. Amplify will automatically populate this field for you.
If you specify extra input fields not expected by the API, this query will fail. You can see this in the errors field returned by the query. With Amplify Data, errors are not thrown like exceptions. Instead, any errors are captured and returned as part of the query result in the errors field.
Delete an item
You can then delete the Todo by using the delete mutation. To specify which item to delete, you only need to provide the id of that item:

import { generateClient } from 'aws-amplify/data';
import { type Schema } from '../amplify/data/resource'

const client = generateClient<Schema>();

const toBeDeletedTodo = {
  id: '123123213'
}

const { data: deletedTodo, errors } = await client.models.Todo.delete(toBeDeletedTodo)
Note: When deleting items in many-to-many relationships, the join table records must be deleted before deleting the associated records. For example, for a many-to-many relationship between Posts and Tags, delete the PostTags join record before deleting a Post or Tag. Review Many-to-many relationships for more details.

Troubleshooting
Troubleshoot unauthorized errors
Cancel create, update, and delete requests
You can cancel any mutation API request by calling .cancel on the mutation request promise that's returned by .create(...), .update(...), or .delete(...).

const promise = client.models.Todo.create({ content: 'New Todo' });
//  ^ Note: we're not awaiting the request, we're returning the promise

try {
  await promise;
} catch (error) {
  console.log(error);
  // If the error is because the request was cancelled you can confirm here.
  if (client.isCancelError(error)) {
    console.log(error.message); // "my message for cancellation"
    // handle user cancellation logic
  }
}

//...

// To cancel the above request
client.cancel(promise, 'my message for cancellation');
You need to ensure that the promise returned from .create(), .update(), and .delete() has not been modified. Typically, async functions wrap the promise being returned into another promise. For example, the following will not work:

async function makeAPICall() {
  return client.models.Todo.create({ content: 'New Todo' });
}
const promise = makeAPICall();

// The following will NOT cancel the request.
client.cancel(promise, 'my error message');
Conclusion
Congratulations! You have finished the Create, update, and delete application data guide. In this guide, you created, updated, and deleted your app data.

Next steps
Our recommended next steps include using the API to query data and subscribe to real-time events to look for mutations in your data. Some resources that will help with this work include:

- Read application data - 
You can read application data using the Amplify Data client. In this guide, we will review the difference between reading data and getting data, how to filter query results to get just the data you need, and how to paginate results to make your data more manageable. We will also show you how to cancel these requests when needed.

Before you begin, you will need:

An application connected to the API
Data already created to view
List and get your data
Queries are used to read data through the API and include the list and get operations. Amplify Data automatically creates list and get queries for any a.model() type in your schema. The list query retrieves multiple items, such as Todo items, without needing to specific an identifier for a particular record. This is best suited for getting an overview or summary of items, or for enhancing the list operation to filter the items by specific criteria. When you want to query a single entry by an identifier, you would use get to retrieve a specific Todo item.

Note: The cost structure of your underlying data source can impact the cost to run some queries. For example, the list operation uses Amazon DynamoDB "scan operations," which can use more read request units than the get operation. You will want to review the associated costs for these operations for your data source. In our example, we are using DynamoDB. You can learn more about how DynamoDB costs are calculated by visiting Amazon DynamoDB pricing.

You can list items by first generating the Data client with your backend Data schema. Then you can list items of your desired model:

import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';

const client = generateClient<Schema>();

// list all items
const { data: todos, errors } = await client.models.Todo.list();

// get a specific item
const { data: todo, errors } = await client.models.Todo.get({
  id: '...',
});
Troubleshooting
Troubleshoot unauthorized errors
Filter list queries
As your data grows, you will need to paginate your list queries. Fortunately, this is already built in to Amplify Data.

import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';

const client = generateClient<Schema>();

const { data: todos, errors } = await client.models.Todo.list({
  filter: {
    content: {
      beginsWith: 'hello'
    }
  }
});
Compound filters
You can combine filters with and, or, and not Boolean logic. Observe that filter is recursive in respect to those fields. So if, for example, you wanted to filter for priority values of 1 or 2, you would do this:

import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';

const client = generateClient<Schema>();

const { data: todos, errors } = await client.models.Todo.list({
  filter: {
    or: [
      {
        priority: { eq: '1' }
      },
      {
        priority: { eq: '2' }
      }
    ]
  }
});
Note that querying for priority of 1 and 2 would return no results, because this is Boolean logic instead of natural language.

Paginate list queries
To paginate your list query results, make a subsequent list query request with the nextToken and limit input variable set. The limit variable limits how many results are returned. The response will include a nextToken you can use to request the next page of data. A nextToken is a very long string that represents the cursor to the starting item of the next query made with these filters.

import { generateClient } from 'aws-amplify/data';
import { type Schema } from '@/amplify/data/resource';

const client = generateClient<Schema>();

const {
  data: todos,
  nextToken, // Repeat this API call with the nextToken until the returned nextToken is `null`
  errors
} = await client.models.Todo.list({
  limit: 100, // default value is 100
  nextToken: 'eyJ2ZXJzaW9uejE1a2...' // previous nextToken
});
If you're building a React application, you can use the usePagination hook in Amplify UI to help with managing the pagination user experience.

import * as React from 'react';
import { Pagination } from '@aws-amplify/ui-react';

export const PaginationHasMorePagesExample = () => {
  const [pageTokens, setPageTokens] = React.useState([null]);
  const [currentPageIndex, setCurrentPageIndex] = React.useState(1);
  const [hasMorePages, setHasMorePages] = React.useState(true);

  const handleNextPage = async () => {
    if (hasMorePages && currentPageIndex === pageTokens.length) {
      const { data: todos, nextToken } = await client.models.Todo.list({
        nextToken: pageTokens[pageTokens.length - 1]
      });

      if (!nextToken) {
        setHasMorePages(false);
      }

      setPageTokens([...pageTokens, nextToken]);
    }

    setCurrentPageIndex(currentPageIndex + 1);
  };

  return (
    <Pagination
      currentPage={currentPageIndex}
      totalPages={pageTokens.length}
      hasMorePages={hasMorePages}
      onNext={handleNextPage}
      onPrevious={() => setCurrentPageIndex(currentPageIndex - 1)}
      onChange={(pageIndex) => setCurrentPageIndex(pageIndex)}
    />
  );
};
Limitations:

There is no API to get a total page count at this time. Note that scanning all items is a potentially expensive operation.
You cannot query by page number; you have to query by nextToken.
Fetch only the data you need with custom selection set
A business domain model may contain many models with numerous fields. However, apps typically only need subsets of the data or fields to meet the requirements of different components or screens. It is necessary to have a mechanism to retrieve subsets of models and their relationships. This mechanism would help optimize data usage for screens and components by only transferring needed data. Having this capability would improve the app's data efficiency, latency, and the end user's perceived performance.

A custom selection set allows consumers to specify, on a per-call basis, the fields the consumer wants to retrieve; this is possible for all operations that return data (CRUDL + observeQuery). The desired fields are specified in a strongly typed way (discoverable through IntelliSense) with a "dot notation".

// same way for all CRUDL: .create, .get, .update, .delete, .list, .observeQuery
const { data: blogWithSubsetOfData, errors } = await client.models.Blog.get(
  { id: blog.id },
  {
    selectionSet: ['author.email', 'posts.*'],
  }
);
TypeScript type helpers for Amplify Data
When using TypeScript, you frequently need to specify data model types for type generics.

For instance, with React's useState, you provide a type in TypeScript to ensure type-safety in your component code using the state. Use the Schema["MODEL_NAME"]["type"] pattern to get TypeScript types for the shapes of data models returned from the backend API.

import { type Schema } from '@/amplify/data/resource';

type Post = Schema['Post']['type'];

const [posts, setPosts] = useState<Post[]>([]);
You can combine the Schema["MODEL_NAME"]["type"] type with the SelectionSet helper type to describe the return type of API requests using the selectionSet parameter:

import type { SelectionSet } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';


const selectionSet = ['content', 'blog.author.*', 'comments.*'] as const;
type PostWithComments = SelectionSet<Schema['Post']['type'], typeof selectionSet>;

// ...
const [posts, setPosts] = useState<PostWithComments[]>([]);

const fetchPosts = async () => {
  const { data: postsWithComments } = await client.models.Post.list({
    selectionSet,
  });
  setPosts(postsWithComments);
}
Cancel read requests
You can cancel any query API request by calling .cancel on the query request promise that's returned by .list(...) or .get(...).

const promise = client.models.Todo.list();
//  ^ Note: we're not awaiting the request, we're returning the promise

try {
  await promise;
} catch (error) {
  console.log(error);
  // If the error is because the request was cancelled you can confirm here.
  if (client.isCancelError(error)) {
    console.log(error.message); // "my message for cancellation"
    // handle user cancellation logic
  }
}
...

// To cancel the above request
client.cancel(promise, "my message for cancellation");
You need to ensure that the promise returned from .list() or .get() has not been modified. Typically, async functions wrap the promise being returned into another promise. For example, the following will not work:

async function makeAPICall() {
  return client.models.Todo.list();
}
const promise = makeAPICall();

// The following will NOT cancel the request.
client.cancel(promise, 'my error message');
Conclusion
Congratulations! You have finished the Read application data guide. In this guide, you learned how to read your data through get and list queries.

Next steps
Our recommended next steps include subscribing to real-time events to look for mutations in your data and continuing to build out and customize your information architecture for your data. Some resources that will help with this work include:

- Subscribe to real-time events - 
In this guide, we will outline the benefits of enabling real-time data integrations and how to set up and filter these subscriptions. We will also cover how to unsubscribe from subscriptions.

Before you begin, you will need:

An application connected to the API
Data already created to modify
With Amplify Data Construct @aws-amplify/data-construct@1.8.4, an improvement was made to how relational field data is handled in subscriptions when different authorization rules apply to related models in a schema. The improvement redacts the values for the relational fields, displaying them as null or empty, to prevent unauthorized access to relational data.

This redaction occurs whenever it cannot be determined that the child model will be protected by the same permissions as the parent model.

Because subscriptions are tied to mutations and the selection set provided in the result of a mutation is then passed through to the subscription, relational fields in the result of mutations must be redacted.

If an authorized end-user needs access to the redacted relational fields, they should perform a query to read the relational data.

Additionally, subscriptions will inherit related authorization when relational fields are set as required. To better protect relational data, consider modifying the schema to use optional relational fields.

Set up a real-time list query
The recommended way to fetch a list of data is to use observeQuery to get a real-time list of your app data at all times. You can integrate observeQuery with React's useState and useEffect hooks in the following way:

import { useState, useEffect } from 'react';
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';

type Todo = Schema['Todo']['type'];

const client = generateClient<Schema>();

export default function MyComponent() {
  const [todos, setTodos] = useState<Todo[]>([]);

  useEffect(() => {
    const sub = client.models.Todo.observeQuery().subscribe({
      next: ({ items, isSynced }) => {
        setTodos([...items]);
      },
    });
    return () => sub.unsubscribe();
  }, []);

  return (
    <ul>
      {todos.map((todo) => (
        <li key={todo.id}>{todo.content}</li>
      ))}
    </ul>
  );
}
observeQuery fetches and paginates through all of your available data in the cloud. While data is syncing from the cloud, snapshots will contain all of the items synced so far and an isSynced status of false. When the sync process is complete, a snapshot will be emitted with all the records in the local store and an isSynced status of true.

Troubleshooting
Missing real-time events and model fields
Set up a real-time event subscription
Subscriptions is a feature that allows the server to send data to its clients when a specific event happens. For example, you can subscribe to an event when a new record is created, updated, or deleted through the API. Subscriptions are automatically available for any a.model() in your Amplify Data schema.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';

const client = generateClient<Schema>();

// Subscribe to creation of Todo
const createSub = client.models.Todo.onCreate().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});

// Subscribe to update of Todo
const updateSub = client.models.Todo.onUpdate().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});

// Subscribe to deletion of Todo
const deleteSub = client.models.Todo.onDelete().subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});

// Stop receiving data updates from the subscription
createSub.unsubscribe();
updateSub.unsubscribe();
deleteSub.unsubscribe();
Set up server-side subscription filters
Subscriptions take an optional filter argument to define service-side subscription filters:

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource';

const client = generateClient<Schema>();

const sub = client.models.Todo.onCreate({
  filter: {
    content: {
      contains: 'groceries',
    },
  },
}).subscribe({
  next: (data) => console.log(data),
  error: (error) => console.warn(error),
});
If you want to get all subscription events, don't specify any filter parameters.

Limitations:

Specifying an empty object {} as a filter is not recommended. Using {} as a filter might cause inconsistent behavior based on your data model's authorization rules.
If you're using dynamic group authorization and you authorize based on a single group per record, subscriptions are only supported if the user is part of five or fewer user groups.
Additionally, if you authorize by using an array of groups (groups: [String]),
subscriptions are only supported if the user is part of 20 or fewer groups
you can only authorize 20 or fewer user groups per record
Subscription connection status updates
Now that your application is set up and using subscriptions, you may want to know when the subscription is finally established, or reflect to your users when the subscription isn't healthy. You can monitor the connection state for changes through the Hub local eventing system.

import { CONNECTION_STATE_CHANGE, ConnectionState } from 'aws-amplify/data';
import { Hub } from 'aws-amplify/utils';

Hub.listen('api', (data: any) => {
  const { payload } = data;
  if (payload.event === CONNECTION_STATE_CHANGE) {
    const connectionState = payload.data.connectionState as ConnectionState;
    console.log(connectionState);
  }
});
Subscription connection states
Connected - Connected and working with no issues.
ConnectedPendingDisconnect - The connection has no active subscriptions and is disconnecting.
ConnectedPendingKeepAlive - The connection is open, but has missed expected keep-alive messages.
ConnectedPendingNetwork - The connection is open, but the network connection has been disrupted. When the network recovers, the connection will continue serving traffic.
Connecting - Attempting to connect.
ConnectionDisrupted - The connection is disrupted and the network is available.
ConnectionDisruptedPendingNetwork - The connection is disrupted and the network connection is unavailable.
Disconnected - Connection has no active subscriptions and is disconnecting.
Troubleshooting
Troubleshoot connection issues and automated reconnection
Unsubscribe from a subscription
You can also unsubscribe from events by using subscriptions by implementing the following:

// Stop receiving data updates from the subscription
sub.unsubscribe();
Conclusion
Congratulations! You have finished the Subscribe to real-time events guide. In this guide, you set up subscriptions for real-time events and learned how to filter and cancel these subscriptions when needed.

- Customize your data model - 
Data modeling capabilities
Every data model is defined as part of a data schema (a.schema()). You can enhance your data model with various fields, customize their identifiers, apply authorization rules, or model relationships. Every data model (a.model()) automatically provides create, read, update, and delete API operations as well as real-time subscription events. Below is a quick tour of the many functionalities you can add to your data model:

import { type ClientSchema, a, defineData } from '@aws-amplify/backend';

const schema = a
  .schema({
    Customer: a
      .model({
        customerId: a.id().required(),
        // fields can be of various scalar types,
        // such as string, boolean, float, integers etc.
        name: a.string(),
        // fields can be of custom types
        location: a.customType({
          // fields can be required or optional
          lat: a.float().required(),
          long: a.float().required(),
        }),
        // fields can be enums
        engagementStage: a.enum(["PROSPECT", "INTERESTED", "PURCHASED"]),
        collectionId: a.id(),
        collection: a.belongsTo("Collection", "collectionId")
        // Use custom identifiers. By default, it uses an `id: a.id()` field
      })
      .identifier(["customerId"]),
    Collection: a
      .model({
        customers: a.hasMany("Customer", "collectionId"), // setup relationships between types
        tags: a.string().array(), // fields can be arrays
        representativeId: a.id().required(),
        // customize secondary indexes to optimize your query performance
      })
      .secondaryIndexes((index) => [index("representativeId")]),
  })
  .authorization((allow) => [allow.publicApiKey()]);

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Add fields to data model
Configure built-in and custom field types.
Modeling relationships
Learn about the types of model relationships and modeling relationships.
Customize data model identifiers
Define the primary key for a model using single-field or composite identifiers.
Customize secondary indexes
Define the secondary indexes for your data model to optimize query performance
Disable Operations
Disable Operations for your data model
Gen 1 schema support
If you are coming from Gen 1, you can continue to use the GraphQL Schema Definition Language (SDL) for defining your schema. However, we strongly recommend you use the TypeScript-first schema builder experience in your project as it provides type safety and is the recommended way of working with Amplify going forward.

Note: Some features available in Gen 1 GraphQL SDL are not available in Gen 2. See the feature matrix for features supported in Gen 2.

amplify/data/resource.ts
import { defineData } from '@aws-amplify/backend';

const schema = /* GraphQL */`
  type Todo @model @auth(rules: [{ allow: owner }]) {
    content: String
    isDone: Boolean
  }
`;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});

- Add fields to data model - 
Amplify Data supports all AWS AppSync scalar types as field types. The following scalar types are available:

Field type	Description	TypeScript validation	GraphQL Scalar Type
a.id()	A unique identifier for an object. This scalar is serialized like a String but isn't meant to be human-readable. If not specified on create operations, a UUID will be generated.	string	ID
a.string()	A UTF-8 character sequence.	string	String
a.integer()	An integer value between -(2^31) and 2^31-1.	number but rounded to closest integer value upon query/mutation	Int
a.float()	An IEEE 754 floating point value.	number	Float
a.boolean()	A Boolean value, either true or false.	boolean	Boolean
a.date()	An extended ISO 8601 date string in the format YYYY-MM-DD.	string	AWSDate
a.time()	An extended ISO 8601 time string in the format hh:mm:ss.sss.	string	AWSTime
a.datetime()	An extended ISO 8601 date and time string in the format YYYY-MM-DDThh:mm:ss.sssZ.	string	AWSDateTime
a.timestamp()	An integer value representing the number of seconds before or after 1970-01-01-T00:00Z.	number	AWSTimestamp
a.email()	An email address in the format local-part@domain-part as defined by RFC 822.	string with local-part and domain-part type enforcement	AWSEmail
a.json()	A JSON string. Any valid JSON construct is automatically parsed and loaded in the resolver code as maps, lists, or scalar values, rather than as the literal input strings. Unquoted strings or otherwise invalid JSON result in a validation error.	any	AWSJSON
a.phone()	A phone number. This value is stored as a string. Phone numbers can contain either spaces or hyphens to separate digit groups. Phone numbers without a country code are assumed to be US/North American numbers adhering to the North American Numbering Plan.	string validation only happening service-side	AWSPhone
a.url()	A URL as defined by RFC 1738. For example, https://www.amazon.com/dp/B000NZW3KC/ or mailto:example@example.com. URLs must contain a schema (http, mailto) and can't contain two forward slashes (//) in the path part.	string but with type enforcement on the schema part	AWSURL
a.ipAddress()	A valid IPv4 or IPv6 address. IPv4 addresses are expected in quad-dotted notation (123.12.34.56). IPv6 addresses are expected in non-bracketed, colon-separated format (1a2b:3c4b:1234:4567). You can include an optional CIDR suffix (123.45.67.89/16) to indicate subnet mask.	string with type enforcement for IPv4 and IPv6 pattern	AWSIPAddress
Specify a custom field type
Sometimes, the built-in types do not meet the needs of your application. In those cases, you can specify custom types. You can either define the custom types inline or explicitly define the custom type in the schema.

Inline definition: The "location" field will become a new non-model type that uses PascalCase, a naming convention in which the first letter of each word in a compound word is capitalized. If there are conflicts with another schema-level definition (model, custom type, enum), you will receive a Type error with a warning that you need to sift the value out as a separate item and use a "ref".

a.schema({
  Post: a.model({
    location: a.customType({
      lat: a.float(),
      long: a.float(),
    }),
    content: a.string(),
  }),
}).authorization((allow) => allow.publicApiKey());
Explicit definition: Specify the "Location" as a.customType() in your schema. To use the custom type, reference it through a.ref() in the respective field definitions.

a.schema({
  Location: a.customType({
      lat: a.float(),
      long: a.float(),
  }),

  Post: a.model({
    location: a.ref('Location'),
    content: a.string(),
  }),

  User: a.model({
    lastKnownLocation: a.ref('Location'),
  }),
}).authorization((allow) => allow.publicApiKey());
To set or read the location field on the client side, you can expand a nested object and the type system will auto-infer the allowed values.

const { data: newPost, errors } = await client.models.Post.create({
  location: {
    lat: 48.837006,
    long: 8.28245,
  },
});

console.log(newPost?.location?.lat, newPost?.location?.long);
Specify an enum field type
Enum has a similar developer experience as custom types: short-hand and long-form approaches.

Short-hand approach

a.schema({
  Post: a.model({
    privacySetting: a.enum(['PRIVATE', 'FRIENDS_ONLY', 'PUBLIC']),
    content: a.string(),
  }),
}).authorization((allow) => allow.publicApiKey());
Long-form approach

a.schema({
  PrivacySetting: a.enum([
    'PRIVATE',
    'FRIENDS_ONLY',
    'PUBLIC'
  ]),

  Post: a.model({
    content: a.string(),
    privacySetting: a.ref('PrivacySetting'),
  }),

  Video: a.model({
    privacySetting: a.ref('PrivacySetting'),
  }),
}).authorization((allow) => allow.publicApiKey());
When creating a new item client-side, the enums are also type-enforced:

client.models.Post.create({
  content: 'hello',
  // WORKS - value auto-completed
  privacySetting: 'PRIVATE',

  // DOES NOT WORK - TYPE ERROR
  privacySetting: 'NOT_PUBLIC',
});
List enum values client-side
You can list available enum values client-side using the client.enums.<ENUM_NAME>.values() API. For example, this allows you to display the available enum values within a dropdown UI.

const availableSettings = client.enums.PrivacySetting.values()
// availableSettings returns ["PRIVATE", "FRIENDS_ONLY", "PUBLIC"]
Mark fields as required
By default, fields are optional. To mark a field as required, use the .required() modifier.

const schema = a.schema({
  Todo: a.model({
    content: a.string().required(),
  }),
}).authorization((allow) => allow.publicApiKey());
Mark fields as arrays
Any field can be modified to be an array using the .array() modifier.

const schema = a.schema({
  Todo: a.model({
    content: a.string().required(),
    notes: a.string().array(),
  }),
}).authorization((allow) => allow.publicApiKey());
Assign default values for fields
You can use the .default(...) modifier to specify a default value for optional scalar type fields and enums. The .default(...) modifier is not available for custom types, arrays, or relationships.

const schema = a.schema({
  Todo: a.model({
    content: a.string().default('My new Todo'),
  }),
}).authorization((allow) => allow.publicApiKey());
Note: The .default(...) modifier can't be applied to required fields.

- Modeling relationships - 
When modeling application data, you often need to establish relationships between different data models. In Amplify Data, you can create one-to-many, one-to-one, and many-to-many relationships in your Data schema. On the client-side, Amplify Data allows you to lazy or eager load of related data.

With Amplify Data Construct @aws-amplify/data-construct@1.8.4, an improvement was made to how relational field data is handled in subscriptions when different authorization rules apply to related models in a schema. The improvement redacts the values for the relational fields, displaying them as null or empty, to prevent unauthorized access to relational data.

This redaction occurs whenever it cannot be determined that the child model will be protected by the same permissions as the parent model.

Because subscriptions are tied to mutations and the selection set provided in the result of a mutation is then passed through to the subscription, relational fields in the result of mutations must be redacted.

If an authorized end-user needs access to the redacted relational fields, they should perform a query to read the relational data.

Additionally, subscriptions will inherit related authorization when relational fields are set as required. To better protect relational data, consider modifying the schema to use optional relational fields.

Types of relationships
Relationship	Code	Description	Example
one to many	a.hasMany(...) & a.belongsTo(...)	Creates a one-to-many relationship between two models.	A Team has many Members. A Member belongs to a Team.
one to one	a.hasOne(...) & a.belongsTo(...)	Creates a one-to-one relationship between two models.	A Customer has one Cart. A Cart belongs to one Customer.
many to many	Two a.hasMany(...) & a.belongsTo(...) on join tables	Create two one-to-many relationships between the related models in a join table.	A Post has many Tags. A Tag has many Posts.
Model one-to-many relationships
Create a one-to-many relationship between two models using the hasMany() and belongsTo() method. In the example below, a Team has many Members and a Member belongs to exactly one Team.

Create a reference field called teamId on the Member model. This reference field's type MUST match the type of Team's identifier. In this case, it's an auto-generated id: a.id().required() field.
Add a relationship field called team that references the teamId field. This allows you to query for the team information from the Member model.
Add a relationship field called members that references the teamId field on the Member model.
const schema = a.schema({
  Member: a.model({
    name: a.string().required(),
    // 1. Create a reference field
    teamId: a.id(),
    // 2. Create a belongsTo relationship with the reference field
    team: a.belongsTo('Team', 'teamId'),
  }),

  Team: a.model({
    mantra: a.string().required(),
    // 3. Create a hasMany relationship with the reference field
    //    from the `Member`s model.
    members: a.hasMany('Member', 'teamId'),
  }),
}).authorization((allow) => allow.publicApiKey());
Create a "Has Many" relationship between records
const { data: team } = await client.models.Team.create({
  mantra: 'Go Frontend!',
});

const { data: member } = await client.models.Member.create({
  name: "Tim",
  teamId: team.id,
});
Update a "Has Many" relationship between records
const { data: newTeam } = await client.models.Team.create({
  mantra: 'Go Fullstack',
});

await client.models.Member.update({
  id: "MY_MEMBER_ID",
  teamId: newTeam.id,
});
Delete a "Has Many" relationship between records
If your reference field is not required, then you can "delete" a one-to-many relationship by setting the relationship value to null.

await client.models.Member.update({
  id: "MY_MEMBER_ID",
  teamId: null,
});
Lazy load a "Has Many" relationship
const { data: team } = await client.models.Team.get({ id: "MY_TEAM_ID"});

const { data: members } = await team.members();

members.forEach(member => console.log(member.id));
Eagerly load a "Has Many" relationship
const { data: teamWithMembers } = await client.models.Team.get(
  { id: "MY_TEAM_ID" },
  { selectionSet: ["id", "members.*"] },
);

teamWithMembers.members.forEach(member => console.log(member.id));
Handling orphaned foreign keys on parent record deletion in "Has Many" relationship
// Get the IDs of the related members.
const { data: teamWithMembers } = await client.models.Team.get(
  { id: teamId },
  { selectionSet: ["id", "members.*"] },
);

// Delete Team
await client.models.Team.delete({ id: teamWithMembers.id });

// Delete all members in parallel
await Promise.all(
  teamWithMembers.members.map(member => 
  client.models.Member.delete({ id: member.id }) 
));
Model a "one-to-one" relationship
Create a one-to-one relationship between two models using the hasOne() and belongsTo() methods. In the example below, a Customer has a Cart and a Cart belongs to a Customer.

Create a reference field called customerId on the Cart model. This reference field's type MUST match the type of Customer's identifier. In this case, it's an auto-generated id: a.id().required() field.
Add a relationship field called customer that references the customerId field. This allows you to query for the customer information from the Cart model.
Add a relationship field called activeCart that references the customerId field on the Cart model.
const schema = a.schema({
  Cart: a.model({
    items: a.string().required().array(),
    // 1. Create reference field
    customerId: a.id(),
    // 2. Create relationship field with the reference field
    customer: a.belongsTo('Customer', 'customerId'),
  }),
  Customer: a.model({
    name: a.string(),
    // 3. Create relationship field with the reference field
    //    from the Cart model
    activeCart: a.hasOne('Cart', 'customerId')
  }),
}).authorization((allow) => allow.publicApiKey());
Create a "Has One" relationship between records
To create a "has one" relationship between records, first create the parent item and then create the child item and assign the parent.

const { data: customer, errors } = await client.models.Customer.create({
  name: "Rene",
});


const { data: cart } = await client.models.Cart.create({
  items: ["Tomato", "Ice", "Mint"],
  customerId: customer?.id,
});
Update a "Has One" relationship between records
To update a "Has One" relationship between records, you first retrieve the child item and then update the reference to the parent to another parent. For example, to reassign a Cart to another Customer:

const { data: newCustomer } = await client.models.Customer.create({
  name: 'Ian',
});

await client.models.Cart.update({
  id: cart.id,
  customerId: newCustomer?.id,
});
Delete a "Has One" relationship between records
You can set the relationship field to null to delete a "Has One" relationship between records.

await client.models.Cart.update({
  id: project.id,
  customerId: null,
});
Lazy load a "Has One" relationship
const { data: cart } = await client.models.Cart.get({ id: "MY_CART_ID"});
const { data: customer } = await cart.customer();
Eagerly load a "Has One" relationship
const { data: cart } = await client.models.Cart.get(
  { id: "MY_CART_ID" },
  { selectionSet: ['id', 'customer.*'] },
);

console.log(cart.customer.id)
Handling orphaned foreign keys on parent record deletion in "Has One" relationship
// Get the customer with their associated cart
const { data: customerWithCart } = await client.models.Customer.get(
  { id: customerId },
  { selectionSet: ["id", "activeCart.*"] },
);

// Delete Cart if exists
await client.models.Cart.delete({ id: customerWithCart.activeCart.id });

// Delete the customer
await client.models.Customer.delete({ id: customerWithCart.id });
Model a "many-to-many" relationship
In order to create a many-to-many relationship between two models, you have to create a model that serves as a "join table". This "join table" should contain two one-to-many relationships between the two related entities. For example, to model a Post that has many Tags and a Tag has many Posts, you'll need to create a new PostTag model that represents the relationship between these two entities.

const schema = a.schema({
  PostTag: a.model({
    // 1. Create reference fields to both ends of
    //    the many-to-many relationship
    postId: a.id().required(),
    tagId: a.id().required(),
    // 2. Create relationship fields to both ends of
    //    the many-to-many relationship using their
    //    respective reference fields
    post: a.belongsTo('Post', 'postId'),
    tag: a.belongsTo('Tag', 'tagId'),
  }),
  Post: a.model({
    title: a.string(),
    content: a.string(),
    // 3. Add relationship field to the join model
    //    with the reference of `postId`
    tags: a.hasMany('PostTag', 'postId'),
  }),
  Tag: a.model({
    name: a.string(),
    // 4. Add relationship field to the join model
    //    with the reference of `tagId`
    posts: a.hasMany('PostTag', 'tagId'),
  }),
}).authorization((allow) => allow.publicApiKey());
Model multiple relationships between two models
Relationships are defined uniquely by their reference fields. For example, a Post can have separate relationships with a Person model for author and editor.

const schema = a.schema({
  Post: a.model({
    title: a.string().required(),
    content: a.string().required(),
    authorId: a.id(),
    author: a.belongsTo('Person', 'authorId'),
    editorId: a.id(),
    editor: a.belongsTo('Person', 'editorId'),
  }),
  Person: a.model({
    name: a.string(),
    editedPosts: a.hasMany('Post', 'editorId'),
    authoredPosts: a.hasMany('Post', 'authorId'),
  }),
}).authorization((allow) => allow.publicApiKey());
On the client-side, you can fetch the related data with the following code:

const client = generateClient<Schema>();

const { data: post } = await client.models.Post.get({ id: "SOME_POST_ID" });

const { data: author } = await post?.author();
const { data: editor } = await post?.editor();
Model relationships for models with sort keys in their identifier
In cases where your data model uses sort keys in the identifier, you need to also add reference fields and store the sort key fields in the related data model:

const schema = a.schema({
  Post: a.model({
    title: a.string().required(),
    content: a.string().required(),
    // Reference fields must correspond to identifier fields.
    authorName: a.string(),
    authorDoB: a.date(),
    // Must pass references in the same order as identifiers.
    author: a.belongsTo('Person', ['authorName', 'authorDoB']),
  }),
  Person: a.model({
    name: a.string().required(),
    dateOfBirth: a.date().required(),
    // Must reference all reference fields corresponding to the
    // identifier of this model.
    authoredPosts: a.hasMany('Post', ['authorName', 'authorDoB']),
  }).identifier(['name', 'dateOfBirth']),
}).authorization((allow) => allow.publicApiKey());
Make relationships required or optional
Amplify Data's relationships use reference fields to determine if a relationship is required or not. If you mark a reference field as required, then you can't "delete" a relationship between two models. You'd have to delete the related record as a whole.

const schema = a.schema({
  Post: a.model({
    title: a.string().required(),
    content: a.string().required(),
    // You must supply an author when creating the post
    // Author can't be set to `null`.
    authorId: a.id().required(),
    author: a.belongsTo('Person', 'authorId'),
    // You can optionally supply an editor when creating the post.
    // Editor can also be set to `null`.
    editorId: a.id(),
    editor: a.belongsTo('Person', 'editorId'),
  }),
  Person: a.model({
    name: a.string(),
    editedPosts: a.hasMany('Post', 'editorId'),
    authoredPosts: a.hasMany('Post', 'authorId'),
  }),
}).authorization((allow) => allow.publicApiKey());

- Customize data model identifiers - 
Identifiers are defined using the .identifier() method on a model definition. Usage of the .identifier() method is optional; when it's not present, the model will automatically have a field called id of type ID that is automatically generated unless manually specified.

const schema = a.schema({
  Todo: a.model({
    content: a.string(),
    completed: a.boolean(),
  })
  .authorization(allow => [allow.publicApiKey()]),
});
const client = generateClient<Schema>();

const todo = await client.models.Todo.create({ content: 'Buy Milk', completed: false });
console.log(`New Todo created: ${todo.id}`); // New Todo created: 5DB6B4CC-CD41-49F5-9844-57C0AB506B69
If you want, you can use Amplify Data to define single-field and composite identifiers:

Single-field identifier with a consumer-provided value (type: id or string, and must be marked required)
Composite identifier with a set of consumer-provided values (type: id or string, and must be marked required)
Single-field identifier
If the default id identifier field needs to be customized, you can do so by passing the name of another field.

const schema = a.schema({
  Todo: a.model({
    todoId: a.id().required(),
    content: a.string(),
    completed: a.boolean(),
  })
  .identifier(['todoId'])
  .authorization(allow => [allow.publicApiKey()]),
});
const client = generateClient<Schema>();

const { data: todo, errors } = await client.models.Todo.create({ todoId: 'MyUniqueTodoId', content: 'Buy Milk', completed: false });
console.log(`New Todo created: ${todo.todoId}`); // New Todo created: MyUniqueTodoId
Composite identifier
For cases where items are uniquely identified by more than a single field, you can pass an array of the field names to the identifier() function:

const schema = a.schema({
  StoreBranch: a.model({
    geoId: a.id().required(),
    name: a.string().required(),
    country: a.string(),
    state: a.string(),
    city: a.string(),
    zipCode: a.string(),
    streetAddress: a.string(),
  }).identifier(['geoId', 'name'])
  .authorization(allow => [allow.publicApiKey()]),
});
const client = generateClient<Schema>();

const branch = await client.models.StoreBranch.get({ geoId: '123', name: 'Downtown' }); // All identifier fields are required when retrieving an item

- Customize secondary indexes - 
You can optimize your list queries based on "secondary indexes". For example, if you have a Customer model, you can query based on the customer's id identifier field by default but you can add a secondary index based on the accountRepresentativeId to get list customers for a given account representative.

A secondary index consists of a "hash key" and, optionally, a "sort key". Use the "hash key" to perform strict equality and the "sort key" for greater than (gt), greater than or equal to (ge), less than (lt), less than or equal to (le), equals (eq), begins with, and between operations.

amplify/data/resource.ts
export const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .secondaryIndexes((index) => [index("accountRepresentativeId")])
    .authorization(allow => [allow.publicApiKey()]),
});
The example client query below allows you to query for "Customer" records based on their accountRepresentativeId:

src/App.tsx
import { type Schema } from '../amplify/data/resource';
import { generateClient } from 'aws-amplify/data';

const client = generateClient<Schema>();

const { data, errors } =
  await client.models.Customer.listCustomerByAccountRepresentativeId({
    accountRepresentativeId: "YOUR_REP_ID",
  });
Review how this works under the hood with Amazon DynamoDB
Add sort keys to secondary indexes
You can define "sort keys" to add a set of flexible filters to your query, such as "greater than" (gt), "greater than or equal to" (ge), "less than" (lt), "less than or equal to" (le), "equals" (eq), "begins with" (beginsWith), and "between" operations.

amplify/data/resource.ts
export const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .secondaryIndexes((index) => [
      index("accountRepresentativeId")
        .sortKeys(["name"]),
    ])
    .authorization(allow => [allow.owner()]),
});
On the client side, you should find a new listBy... query that's named after hash key and sort keys. For example, in this case: listByAccountRepresentativeIdAndName. You can supply the filter as part of this new list query:

src/App.tsx
const { data, errors } =
  await client.models.Customer.listCustomerByAccountRepresentativeIdAndName({
    accountRepresentativeId: "YOUR_REP_ID",
    name: {
      beginsWith: "Rene",
    },
  });
Customize the query field for secondary indexes
You can also customize the auto-generated query name under client.models.<MODEL_NAME>.listBy... by setting the queryField() modifier.

amplify/data/resource.ts
const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .secondaryIndexes((index) => [
      index("accountRepresentativeId")
        .queryField("listByRep"),
    ])
    .authorization(allow => [allow.owner()]),
});
In your client app code, you'll see query updated under the Data client:

src/App.tsx
const {
  data,
  errors
} = await client.models.Customer.listByRep({
  accountRepresentativeId: 'YOUR_REP_ID',
})
Customize the name of secondary indexes
To customize the underlying DynamoDB's index name, you can optionally provide the name() modifier.

amplify/data/resource.ts
const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .secondaryIndexes((index) => [
      index("accountRepresentativeId")
        .name("MyCustomIndexName"),
    ])
    .authorization(allow => [allow.owner()]),
});

- Disable Operations - 
The disableOperations method allows you to selectively disable specific GraphQL operations for a model in your Amplify application. This can be useful for implementing specialized API designs and reduce the number of resources being deployed.

You can disable operations by adding the disableOperations method to your model definition:

amplify/data/resource.ts
export const schema = a.schema({
  Customer: a
    .model({
      name: a.string(),
      phoneNumber: a.phone(),
      accountRepresentativeId: a.id().required(),
    })
    .disableOperations(["mutations", "subscriptions", "queries"])
    .authorization(allow => [allow.publicApiKey()]),
});
Available Operation Types
The disableOperations method accepts an array of operation types that you want to disable:

General Operation Categories
mutations: Disables all mutation operations (create, update, delete)
subscriptions: Disables all real-time subscription operations (onCreate, onUpdate, onDelete)
queries: Disables all query operations (get, list)
Specific Operations
You can also disable more granular operations: Query Operations

get: Disables the ability to fetch a single item by ID
list: Disables the ability to fetch multiple items
Mutation Operations
create: Disables the ability to create new items
update: Disables the ability to update existing items
delete: Disables the ability to delete items
Subscription Operations
onCreate: Disables real-time notifications when items are created
onUpdate: Disables real-time notifications when items are updated
onDelete: Disables real-time notifications when items are deleted
You can specify one or more operation types in the array to disable them:

// Disable all mutations
disableOperations: ["mutations"]

// Disable both subscriptions and queries
disableOperations: ["subscriptions", "queries"]

// Disable specific operations
disableOperations: ["create", "update", "list"]

// Disable specific subscription types
disableOperations: ["onCreate", "onUpdate"]

// Mix general categories with specific operations
disableOperations: ["queries", "create", "onDelete"]

- Customize your auth rules - 
Use the .authorization() modifier to configure authorization rules for public, signed-in user, per user, and per user group data access. Authorization rules operate on the deny-by-default principle. Meaning that if an authorization rule is not specifically configured, it is denied.

const schema = a.schema({
  Post: a.model({
    content: a.string()
  }).authorization(allow => [
    // Allow anyone auth'd with an API key to read everyone's posts.
    allow.publicApiKey().to(['read']),
    // Allow signed-in user to create, read, update,
    // and delete their __OWN__ posts.
    allow.owner(),
  ])
})
In the example above, everyone (public) can read every Post but authenticated users (owner) can create, read, update, and delete their own posts. Amplify also allows you to restrict the allowed operations, combine multiple authorization rules, and apply fine-grained field-level authorization.

Available authorization strategies
Use the guide below to select the correct authorization strategy for your use case:

Recommended use case	Strategy	authMode
Public data access where users or devices are anonymous. Anyone with the AppSync API key is granted access.	publicApiKey	apiKey
Recommended for production environment's public data access. Public data access where unauthenticated users or devices are granted permissions using Amazon Cognito identity pool's role for unauthenticated identities.	guest	identityPool
Per user data access. Access is restricted to the "owner" of a record. Leverages amplify/auth/resource.ts Cognito user pool by default.	owner/ownerDefinedIn/ownersDefinedIn	userPool / oidc
Any signed-in data access. Unlike owner-based access, any signed-in user has access.	authenticated	userPool / oidc / identityPool
Per user group data access. A specific or dynamically configured group of users has access.	group/groupDefinedIn/groups/groupsDefinedIn	userPool / oidc
Define your own custom authorization rule within a serverless function.	custom	lambda
Understand how authorization rules are applied
Authorization rules can be applied globally across all data models in a schema, onto specific data models, and onto specific fields.

Amplify will always use the most specific authorization rule that is available. For example, if there is an authorization rule for a field and an authorization rule for the model that the field belongs to, Amplify will evaluate against the field-level authorization rule. Review Field-level authorization rules to learn more.

If there are multiple authorization rules present, they will be logically OR'ed. Review Configure multiple authorization rules to learn more. For userPools and oidc authorization modes, the rules are evaluated in the sequence authenticated > group(s) > owner(s)DefinedIn > group(s)DefinedIn.

Global authorization rule (only for getting started)
To help you get started, you can define an authorization rule on the data schema that will be applied to all data models that do not have a model-level authorization rule. Instead of having a global authorization rule for all production environments, we recommend creating specific authorization rules for each model or field.

The global authorization rule below uses allow.publicApiKey(). This example allows anyone to create, read, update, and delete and is applied to every data model.

const schema = a.schema({
  // Because no model-level authorization rule is present
  // this model will use the global authorization rule.
  Todo: a.model({
    content: a.string()
  }),

  // Will use model-level authorization rule
  Notes: a.model({
    content: a.string()
    // [Model-level authorization rule]
  }).authorization(allow => [allow.publicApiKey().to(['read'])])

// [Global authorization rule]
}).authorization(allow => [
  allow.publicApiKey()
])
Model-level authorization rules
Add an authorization rule to a model to apply the authorization rule to all fields of that model.

const schema = a.schema({
  Post: a.model({
    content: a.string(),
    createdBy: a.string()
    // [Model-level authorization rule]
    // All fields (content, createdBy) will be protected by
    // this authorization rule
  }).authorization(allow => [
    allow.publicApiKey().to(['read']),
    allow.owner(),
  ])
})
Field-level authorization rules
When an authorization rule is added to a field, it will strictly define the authorization rules applied on the field. Field-level authorization rules do not inherit model-level authorization rules. Meaning, only the specified field-level authorization rule is applied.

In the example below:

Owners are allowed to create, read, update, and delete Employee records they own
Any signed in user has read access and can read data with the exception of the ssn field
Only the ssn field has owner auth applied and this field-level auth rule means that model-level auth rules are not applied
const schema = a.schema({
  Employee: a.model({
    name: a.string(),
    email: a.string(),
    // [Field-level authorization rule]
    // This auth rule will be used for the "ssn" field
    // All other fields will use the model-level auth rule
    ssn: a.string().authorization(allow => [allow.owner()]),
  })

  // [Model-level authorization rule]
  .authorization(allow => [
    allow.authenticated().to(["read"]),
    allow.owner()
  ]),
});
Non-model authorization rules
Non-model types are any types added to the schema without using a.model(). These consist of modifiers such as a.customType(), a.enum(),a.query(), a.mutation(), or a.subscription().

Dynamic authorization rules such as allow.owner(), allow.ownerDefinedIn(), allow.groupDefinedIn() are not supported for non-model types.

const schema = a.schema({
  // ...
  listCustomType: a
    .query()
    .returns(a.ref("CustomType").array())
    .handler(
      a.handler.custom({
        entry: "./handler.js",
      })
    )
    .authorization((allow) => [
      // Static auth rules - Supported
      allow.guest(),
      allow.publicApiKey(),
      allow.authenticated(),
      allow.group("Admin"),
      allow.groups(["Teacher", "Student"]),

      // Dynamic auth rules - Not supported
      allow.owner(),
      allow.ownerDefinedIn("owner"),
      allow.ownersDefinedIn("otherOwners"),
      allow.groupDefinedIn("group"),
      allow.groupsDefinedIn("otherGroups"),
    ]),
});
There are TS warnings and validation checks in place that will cause a sandbox deployment to fail if unsupported auth rules are defined on custom queries and mutations.

Configure multiple authorization rules
When combining multiple authorization rules, they are "logically OR"-ed. In the following example:

Any user (using Amazon Cognito identity pool's unauthenticated roles) is allowed to read all posts
Owners are allowed to create, read, update, and delete their own posts
const schema = a.schema({
  Post: a.model({
    title: a.string(),
    content: a.string()
  }).authorization(allow => [
    allow.guest().to(["read"]),
    allow.owner()
  ])
})
On the client side, make sure to always authenticate with the corresponding authorization mode.

import { generateClient } from 'aws-amplify/data'
import type { Schema } from '@/amplify/data/resource' // Path to your backend resource definition

const client = generateClient<Schema>()

// Creating a post is restricted to Cognito User Pools
const { data: newPostResult , errors } = await client.models.Post.create({
	query: queries.createPost,
	variables: { input: { title: 'Hello World' } },
	authMode: 'userPool',
});

// Listing posts is available to unauthenticated users (verified by Amazon Cognito identity pool's unauthenticated role)
const { data: listPostsResult , errors } = await client.models.Post.list({
	query: queries.listPosts,
	authMode: 'identityPool',
});
IAM authorization
All Amplify Gen 2 projects enable IAM authorization for data access. This ensures that the Amplify console's data manager will be able to access your API. It also allows you to authorize other administrative or machine-to-machine access using your own IAM policies. See the AWS AppSync Developer Guide for details on how AWS AppSync works with IAM.

Authorization on custom types
Authorization rules are only supported on data models (model-level and field-level) and custom operations (queries, mutations and subscriptions). They are not fully supported on custom types, including custom types returned by custom operations. For example, consider a custom query that returns a custom type:

const schema = a.schema({
  Counter: a.customType({
    value: a.integer(),
  })
  .authorization(...), // <-- not supported
  getCounter: a
    .mutation()
    .arguments({
      id: a.string().required(),
    })
    .returns(a.ref("Counter"))
    .handler(
      a.handler.custom({
        entry: "./getCounter.js",
      })
    )
    .authorization((allow) => [allow.authenticated()]),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema: schema,
  authorizationModes: {
    defaultAuthorizationMode: "userPool",
  },
});
As you can see, the custom Counter type does not support the .authorization() modifier. Instead, behind the scenes, Amplify will add appropriate authorization rules to Counter to allow authenticated users to access it. That means that any signed-in user will be able to access the custom operation and all fields of the custom type.

Note: IAM authorization is not currently supported for custom operations that return custom types if defaultAuthorizationMode is not iam. See GitHub issue #2929 for details and suggested workarounds.

- Public data access - 
The public authorization strategy grants everyone access to the API, which is protected behind the scenes with an API key. You can also override the authorization provider to use an unauthenticated IAM role from Cognito instead of an API key for public access.

Add public authorization rule using API key-based authentication
To grant everyone access, use the .public() authorization strategy. Behind the scenes, the API will be protected with an API key.

amplify/data/resource.ts
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.publicApiKey()]),
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> by specifying the apiKey auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'apiKey',
  }
);
Extend API Key Expiration
If the API key has not expired, you can extend the expiration date by deploying your app again. The API key expiration date will be set to expiresInDays days from the date when the app is deployed. In the example below, the API key will expire 7 days from the latest deployment.

amplify/data/resource.ts
export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 7,
    },
  },
});
Rotate an API Key
You can rotate an API key if it was expired, compromised, or deleted. To rotate an API key, you can override the logical ID of the API key resource in the amplify/backend.ts file. This will create a new API key with a new logical ID.

amplify/backend.ts
const backend = defineBackend({
  auth,
  data,
});

backend.data.resources.cfnResources.cfnApiKey?.overrideLogicalId(
  `recoverApiKey${new Date().getTime()}`
);
Deploy your app. After the deploy has finished, remove the override to the logical ID and deploy your app again to use the default logical ID.

amplify/backend.ts
const backend = defineBackend({
  auth,
  data,
});

// backend.data.resources.cfnResources.cfnApiKey?.overrideLogicalId(
//   `recoverApiKey${new Date().getTime()}`
// );
A new API key will be created for your app.

Add public authorization rule using Amazon Cognito identity pool's unauthenticated role
You can also override the authorization provider. In the example below, identityPool is specified as the provider which allows you to use an "Unauthenticated Role" from the Cognito identity pool for public access instead of an API key. Your Auth resources defined in amplify/auth/resource.ts generates scoped down IAM policies for the "Unauthenticated role" in the Cognito identity pool automatically.

amplify/data/resource.ts
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.guest()]),
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the identityPool auth mode.

If you're not using the auto-generated amplify_outputs.json file, then you must set the Amplify Library resource configuration's allowGuestAccess flag to true. This lets the Amplify Library use the unauthenticated role from your Cognito identity pool when your user isn't logged in.

Amplify configuration
src/App.tsx
import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'identityPool',
  }
);

- Per-user/per-owner data access - 
The owner authorization strategy restricts operations on a record to only the record's owner. When configured, the owner field will automatically be added and populated with the identity of the created user. The API will authorize against the owner field to allow or deny operations.

Add per-user/per-owner authorization rule
You can use the owner authorization strategy to restrict a record's access to a specific user. When owner authorization is configured, only the record's owner is allowed the specified operations.

amplify/data/resource.ts
// The "owner" of a Todo is allowed to create, read, update, and delete their own todos
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.owner()]),
});
amplify/data/resource.ts
// The "owner" of a Todo record is only allowed to create, read, and update it.
// The "owner" of a Todo record is denied to delete it.
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.owner().to(['create', 'read', 'update'])]),
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'userPool',
  }
);
Behind the scenes, Amplify will automatically add a owner: a.string() field to each record which contains the record owner's identity information upon record creation.

By default, the Cognito user pool's user information is populated into the owner field. The value saved includes sub and username in the format <sub>::<username>. The API will authorize against the full value of <sub>::<username> or sub / username separately and return username. You can alternatively configure OpenID Connect as an authorization provider.

By default, owners can reassign the owner of their existing record to another user.

To prevent an owner from reassigning their record to another user, protect the owner field (by default owner: String) with a field-level authorization rule. For example, in a social media app, you would want to prevent Alice from being able to reassign Alice's Post to Bob.

const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      owner: a.string().authorization(allow => [allow.owner().to(['read', 'delete'])]),
    })
    .authorization(allow => [allow.owner()]),
});
Customize the owner field
You can override the owner field to your own preferred field, by specifying a custom ownerField in the authorization rule.

const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      author: a.string(), // record owner information now stored in "author" field
    })
    .authorization(allow => [allow.ownerDefinedIn('author')]),
});

- Multi-user data access -

The ownersDefinedIn rule grants a set of users access to a record by automatically creating an owners field to store the allowed record owners. You can override the default owners field name by specifying inField with the desired field name to store the owner information. You can dynamically manage which users can access a record by updating the owner field.

Add multi-user authorization rule
If you want to grant a set of users access to a record, you use the ownersDefinedIn rule. This automatically creates a owners: a.string().array() field to store the allowed owners.

amplify/data/resource.ts
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      owners: a.string().array(),
    })
    .authorization(allow => [allow.ownersDefinedIn('owners')]),
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

// Create a record with current user as first owner
const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'userPool',
  }
);
Add another user as an owner

await client.models.Todo.update(
  {
    id: newTodo.id,
    owners: [...(newTodo.owners as string[]), otherUserId],
  },
  {
    authMode: "userPool"
  }
);
Override to a list of owners
You can override the inField to a list of owners. Use this if you want a dynamic set of users to have access to a record. In the example below, the authors list is populated with the creator of the record upon record creation. The creator can then update the authors field with additional users. Any user listed in the authors field can access the record.

const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
      authors: a.string().array(), // record owner information now stored in "authors" field
    })
    .authorization(allow => [allow.ownersDefinedIn('authors')]),
});

- Signed-in user data access - 
The authenticated authorization strategy restricts record access to only signed-in users authenticated through IAM, Cognito, or OpenID Connect, applying the authorization rule to all users. It provides a simple way to make data private to all authenticated users.

Add signed-in user authorization rule
You can use the authenticated authorization strategy to restrict a record's access to every signed-in user.

Note: If you want to restrict a record's access to a specific user, see Per-user/per-owner data access. The authenticated authorization strategy detailed on this page applies the authorization rule for data access to every signed-in user.

In the example below, anyone with a valid JWT token from the Cognito user pool is allowed access to all Todos.

amplify/data/resource.ts
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.authenticated()]),
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'userPool',
  }
);
Use identity pool for signed-in user authentication
You can also override the authorization provider. In the example below, identityPool is specified as the provider which allows you to use an "Unauthenticated Role" from the Cognito identity pool for public access instead of an API key. Your Auth resources defined in amplify/auth/resource.ts generates scoped down IAM policies for the "Unauthenticated role" in the Cognito identity pool automatically.

amplify/data/resource.ts
const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.authenticated('identityPool')]),
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the iam auth mode.

The user must be logged in for the Amplify Library to use the authenticated role from your Cognito identity pool.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'identityPool',
  }
);
In addition, you can also use OpenID Connect with authenticated authorization. See OpenID Connect as an authorization provider.

- User group-based data access - 
You can use the group authorization strategy to restrict access based on user groups. The user group authorization strategy allows restricting data access to specific user groups or groups defined dynamically on each data record.

Add authorization rules for specific user groups
When you want to restrict access to a specific set of user groups, provide the group names in the groups parameter. In the example below, only users that are part of the "Admin" user group are granted access to the Salary model.

amplify/data/resource.ts
// allow one specific group
const schema = a.schema({
  Salary: a
    .model({
      wage: a.float(),
      currency: a.string(),
    })
    .authorization(allow => [allow.group('Admin')]),
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

// As a signed-in user that belongs to the 'Admin' User Pool Group
const { errors, data: newSalary } = await client.models.Salary.create(
  {
    wage: 50.25,
    currency: 'USD'
  },
  {
    authMode: 'userPool',
  }
);
This can then be updated to allow access to multiple defined groups; in this example below we added access for "Leadership".

// allow multiple specific groups
const schema = a.schema({
  Salary: a
    .model({
      wage: a.float(),
      currency: a.string(),
    })
    .authorization(allow => [allow.groups(['Admin', 'Leadership'])]),
});
Add authorization rules for dynamically set user groups
With dynamic group authorization, each record contains an attribute specifying what Cognito groups should be able to access it. Use the first argument to specify which attribute in the underlying data store holds this group information. To specify that a single group should have access, use a field of type a.string(). To specify that multiple groups should have access, use a field of type a.string().array().

// Dynamic group authorization with multiple groups
const schema = a.schema({
  Post: a
    .model({
      title: a.string(),
      groups: a.string().array(),
    })
    .authorization(allow => [allow.groupsDefinedIn('groups')]),
});
// Dynamic group authorization with a single group
const schema = a.schema({
  Post: a
    .model({
      title: a.string(),
      group: a.string(),
    })
    .authorization(allow => [allow.groupDefinedIn('group')]),
});
By default, group authorization leverages Amazon Cognito user pool groups but you can also use OpenID Connect with group authorization. See OpenID Connect as an authorization provider.

Known limitations for real-time subscriptions when using dynamic group authorization:

If you authorize based on a single group per record, then subscriptions are only supported if the user is part of 5 or fewer user groups
If you authorize via an array of groups (groups: a.string().array() used in the example above),
subscriptions are only supported if the user is part of 20 or fewer groups
you can only authorize 20 or fewer user groups per record
Access user groups from the session
You can access a user's groups from their session using the Auth category:

import { fetchAuthSession } from 'aws-amplify/auth';

const session = await fetchAuthSession();
const groups = session.tokens.accessToken.payload['cognito:groups'] || [];

console.log('User groups:', groups);

- Custom data access using Lambda functions - 
You can define your own custom authorization rule with a Lambda function.

amplify/data/resource.ts
import {
  type ClientSchema,
  a,
  defineData,
  defineFunction,
} from '@aws-amplify/backend';

const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    // STEP 1
    // Indicate which models / fields should use a custom authorization rule
    .authorization(allow => [allow.custom()]),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'lambda',
    // STEP 2
    // Pass in the function to be used for a custom authorization rule
    lambdaAuthorizationMode: {
      function: defineFunction({
        entry: './custom-authorizer.ts',
      }),
      // (Optional) STEP 3
      // Configure the token's time to live
      timeToLiveInSeconds: 300,
    },
  },
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the lambda auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    content: 'My new todo',
  },
  {
    authMode: 'lambda',
  }
);
The Lambda function of choice will receive an authorization token from the client and execute the desired authorization logic. The AppSync GraphQL API will receive a payload from Lambda after invocation to allow or deny the API call accordingly.

To configure a Lambda function as the authorization mode, create a new file amplify/data/custom-authorizer.ts. You can use this Lambda function code template as a starting point for your authorization handler code:

// amplify/data/custom-authorizer.ts

// This is sample code. Update this to suite your needs
import type { AppSyncAuthorizerHandler } from 'aws-lambda'; // types imported from @types/aws-lambda

type ResolverContext = {
  userid: string;
  info: string;
  more_info: string;
};

export const handler: AppSyncAuthorizerHandler<ResolverContext> = async (
  event
) => {
  console.log(`EVENT: ${JSON.stringify(event)}`);
  const {
    authorizationToken,
    requestContext: { apiId, accountId }
  } = event;
  const response = {
    isAuthorized: authorizationToken === 'custom-authorized',
    resolverContext: {
      // eslint-disable-next-line spellcheck/spell-checker
      userid: 'user-id',
      info: 'contextual information A',
      more_info: 'contextual information B'
    },
    deniedFields: [
      `arn:aws:appsync:${process.env.AWS_REGION}:${accountId}:apis/${apiId}/types/Event/fields/comments`,
      `Mutation.createEvent`
    ],
    ttlOverride: 300
  };
  console.log(`RESPONSE: ${JSON.stringify(response, null, 2)}`);
  return response;
};
You can use the template above as a starting point for your custom authorization rule. The authorization Lambda function receives the following event:

{
    "authorizationToken": "ExampleAuthToken123123123", # Authorization token specified by client
    "requestContext": {
        "apiId": "aaaaaa123123123example123", # AppSync API ID
        "accountId": "111122223333", # AWS Account ID
        "requestId": "f4081827-1111-4444-5555-5cf4695f339f",
        "queryString": "mutation CreateEvent {...}\n\nquery MyQuery {...}\n", # GraphQL query
        "operationName": "MyQuery", # GraphQL operation name
        "variables": {} # any additional variables supplied to the operation
    }
}
Your Lambda authorization function needs to return the following JSON:

{
  // required
  "isAuthorized": true, // if "false" then an UnauthorizedException is raised, access is denied
  "resolverContext": { "banana": "very yellow" }, // JSON object visible as $ctx.identity.resolverContext in VTL resolver templates

  // optional
  "deniedFields": ["TypeName.FieldName"], // Forces the fields to "null" when returned to the client
  "ttlOverride": 10 // The number of seconds that the response should be cached for. Overrides default specified in "amplify update api"
}
Review the Amplify documentation to set the custom authorization token for the Data client.

- Use OpenID Connect as an authorization provider - 
Private, owner, and group authorization can be configured with an OpenID Connect (OIDC) authorization mode. Add "oidc" to the authorization rule as the provider. Use the oidcAuthorizationMode property to configure the OpenID Connect provider name, OpenID Connect provider domain, Client ID, Issued at TTL, and Auth Time TTL.

The example below highlights the supported authorization strategies with a oidc authorization provider. For owner and group-based authorization, you also will need to specify a custom identity and group claim.

amplify/data/resource.ts
// amplify/data/resource.ts
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';

const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [
      allow.owner('oidc').identityClaim('user_id'),
      allow.authenticated('oidc'),
      allow
        .groups(['testGroupName'], 'oidc')
        .withClaimIn('user_groups'),
    ]),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'oidc',
    oidcAuthorizationMode: {
      oidcProviderName: 'oidc-provider-name',
      oidcIssuerUrl: 'https://example.com',
      clientId: 'client-id',
      tokenExpiryFromAuthInSeconds: 300,
      tokenExpireFromIssueInSeconds: 600,
    },
  },
});
In your application, you can perform CRUD operations against the model using client.models.<model-name> by specifying the oidc auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: todos } = await client.models.Todo.list({
  authMode: "oidc",
});

- Configure custom identity and group claims - 
Amplify Data supports using custom identity and group claims if you do not wish to use the default Amazon Cognito-provided cognito:groups or the double-colon-delimited claims, sub::username, from your JWT token. This can be helpful if you are using tokens from a 3rd party OIDC system or if you wish to populate a claim with a list of groups from an external system, such as when using a Pre Token Generation Lambda Trigger which reads from a database.

To use custom claims specify identityClaim or groupClaim as appropriate. In the example below, the identityClaim is specified and the record owner will check against this user_id claim. Similarly, if the user_groups claim contains a "Moderator" string then access will be granted.

amplify/data/resource.ts
import { a, defineData, type ClientSchema } from '@aws-amplify/backend';

const schema = a.schema({
  Post: a
    .model({
      id: a.id(),
      owner: a.string(),
      postname: a.string(),
      content: a.string(),
    })
    .authorization(allow => [
      allow.owner().identityClaim('user_id'),
      allow.groups(['Moderator']).withClaimIn('user_groups'),
    ]),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({ schema });
In your application, you can perform CRUD operations against the model using client.models.<model-name> with the userPool auth mode.

import { generateClient } from 'aws-amplify/data';
import type { Schema } from '../amplify/data/resource'; // Path to your backend resource definition

const client = generateClient<Schema>();

const { errors, data: newTodo } = await client.models.Todo.create(
  {
    postname: 'My New Post'
    content: 'My post content',
  },
  {
    authMode: 'userPool',
  }
);

- Grant Lambda function access to API and Data - 
Function access to defineData can be configured using an authorization rule on the schema object.

amplify/data/resource.ts
import {
  a,
  defineData,
  type ClientSchema
} from '@aws-amplify/backend';
import { functionWithDataAccess } from '../function/data-access/resource';

const schema = a
  .schema({
    Todo: a.model({
      name: a.string(),
      description: a.string(),
      isDone: a.boolean()
    })
  })
  .authorization(allow => [allow.resource(functionWithDataAccess)]);

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema
});
Create a new directory and a resource file, amplify/functions/data-access/resource.ts. Then, define the Function with defineFunction:

amplify/functions/data-access/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const functionWithDataAccess = defineFunction({
  name: 'data-access',
});
The object returned from defineFunction can be passed directly to allow.resource() in the schema authorization rules. This will grant the function the ability to execute Query, Mutation, and Subscription operations against the GraphQL API. Use the .to() method to narrow down access to one or more operations.

amplify/data/resource.ts
const schema = a
  .schema({
    Todo: a.model({
      name: a.string(),
      description: a.string(),
      isDone: a.boolean()
    })
  })
  .authorization(allow => [
    allow.resource(functionWithDataAccess).to(['query', 'listen'])
  ]); // allow query and subscription operations but not mutations
Function access can only be configured on the schema object. It cannot be configured on individual models or fields.

Access the API using aws-amplify
In the handler file for your function, configure the Amplify data client

amplify/functions/data-access/handler.ts
import type { Handler } from 'aws-lambda';
import type { Schema } from '../../data/resource';
import { Amplify } from 'aws-amplify';
import { generateClient } from 'aws-amplify/data';
import { getAmplifyDataClientConfig } from '@aws-amplify/backend/function/runtime';
import { env } from '$amplify/env/<function-name>'; // replace with your function name

const { resourceConfig, libraryOptions } = await getAmplifyDataClientConfig(env);

Amplify.configure(resourceConfig, libraryOptions);

const client = generateClient<Schema>();

export const handler = async (event) => {
  // your function code goes here
}
When configuring Amplify with getAmplifyDataClientConfig, your function consumes schema information from an S3 bucket created during backend deployment with grants for the access your function need to use it. Any changes to this bucket outside of backend deployment may break your function.

Once you have generated the client code, update the function to access the data. The following code creates a todo and then lists all todos.

amplify/functions/data-access.ts
const client = generateClient<Schema>();

export const handler: Handler = async (event) => {
  const { errors: createErrors, data: newTodo } = await client.models.Todo.create({
    name: "My new todo",
    description: "Todo description",
    isDone: false,
  })


  const { errors: listErrors, data: todos } = await client.models.Todo.list();

  return event;
};

- Add custom queries and mutations - 
The a.model() data model provides a solid foundation for querying, mutating, and fetching data. However, you may need additional customizations to meet specific requirements around custom API requests, response formatting, and/or fetching from external data sources.

In the following sections, we walk through the three steps to create a custom query or mutation:

Define a custom query or mutation
Configure custom business logic handler code
Invoke the custom query or mutation
Step 1 - Define a custom query or mutation
Type	When to choose
Query	When the request only needs to read data and will not modify any backend data
Mutation	When the request will modify backend data
For every custom query or mutation, you need to set a return type and, optionally, arguments. Use a.query() or a.mutation() to define your custom query or mutation in your amplify/data/resource.ts file:

Custom query
Custom mutation
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';

const schema = a.schema({
  // 1. Define your return type as a custom type
  EchoResponse: a.customType({
    content: a.string(),
    executionDuration: a.float()
  }),

  // 2. Define your query with the return type and, optionally, arguments
  echo: a
    .query()
    // arguments that this query accepts
    .arguments({
      content: a.string()
    })
    // return type of the query
    .returns(a.ref('EchoResponse'))
    // only allow signed-in users to call this API
    .authorization(allow => [allow.authenticated()])
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema
});
Step 2 - Configure custom business logic handler code
After your query or mutation is defined, you need to author your custom business logic. You can either define it in a function or using a custom resolver powered by AppSync JavaScript resolver.

Function
Custom resolver powered by AppSync JavaScript resolvers
In your amplify/data/echo-handler/ folder, create a handler.ts file. You can import a utility type for your function handler via the Schema type from your backend resource. This gives you type-safe handler parameters and return values.

amplify/data/echo-handler/handler.ts
import type { Schema } from '../resource'

export const handler: Schema["echo"]["functionHandler"] = async (event, context) => {
  const start = performance.now();
  return {
    content: `Echoing content: ${event.arguments.content}`,
    executionDuration: performance.now() - start
  };
};
In your amplify/data/resource.ts file, define the function using defineFunction and then reference the function with your query or mutation using a.handler.function() as a handler.

amplify/data/resource.ts
import {
  type ClientSchema,
  a,
  defineData,
  defineFunction // 1.Import "defineFunction" to create new functions
} from '@aws-amplify/backend';

// 2. define a function
const echoHandler = defineFunction({
  entry: './echo-handler/handler.ts'
})

const schema = a.schema({
  EchoResponse: a.customType({
    content: a.string(),
    executionDuration: a.float()
  }),

  echo: a
    .query()
    .arguments({ content: a.string() })
    .returns(a.ref('EchoResponse'))
    .authorization(allow => [allow.publicApiKey()])
    // 3. set the function has the handler
    .handler(a.handler.function(echoHandler))
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30
    },
  },
});
If you want to use an existing Lambda function, you can reference it by its name: a.handler.function('name-of-existing-lambda-fn'). Note that Amplify will not update this external Lambda function or its dependencies.

All handlers must be of the same type. For example, you can't mix and match a.handler.function with a.handler.custom within a single .handler() modifier.

Step 3 - Invoke the custom query or mutation
From your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.

Custom query
Custom mutation
const { data, errors } = await client.queries.echo({
  content: 'hello world!!!'
});
Supported Argument Types in Custom Operations
Custom operations can accept different types of arguments. Understanding these options helps define flexible and well-structured APIs.

Defining Arguments in Custom Operations
When defining a custom operation, you can specify arguments using different types:

Scalar Fields: Basic types such as string, integer, float, etc
Custom Types: Define inline customType
Reference Types: Use a.ref() to reference enums and custom types
amplify/data/resource.ts
const schema = a.schema({
  Status: a.enum(['ACCEPTED', 'REJECTED']),
  
  getPost: a
    .query()
    .arguments({
      // scalar field
      content: a.string(),
      // inline custom type
      config: a.customType({
        filter: a.string(),
        // reference to enum
        status: a.ref('Status')
      }),
    })
    .returns(a.string())
    .authorization(allow => [allow.authenticated()])
});
Async function handlers
Async function handlers allow you to execute long-running operations asynchronously, improving the responsiveness of your API. This is particularly useful for tasks that don't require an immediate response, such as batch processing, putting messages in a queue, and initiating a generative AI model inference.

Usage
To define an async function handler, use the .async() method when defining your handler:

amplify/data/resource.ts
const signUpForNewsletter = defineFunction({
  entry: './sign-up-for-newsletter/handler.ts'
});

const schema = a.schema({
  someAsyncOperation: a.mutation()
    .arguments({
      email: a.email().required()
    })
    .handler(a.handler.function(signUpForNewsletter).async())
    .authorization((allow) => allow.guest()),
})
Key Characteristics
Single Return Type: Async handlers return a static type EventInvocationResponse and don't support specifying a return type. The .returns() method is not available for operations using async handlers.

Fire and Forget: The client is informed whether the invocation was successfully queued, but doesn't receive data from the Lambda function execution.

Pipeline Support: Async handlers can be used in function pipelines. If the final handler is an async function, the return type of the query or mutation is EventInvocationResponse.

- Working with files/attachments - 
The Storage and GraphQL API categories can be used together to associate a file, such as an image or video, with a particular record. For example, you might create a User model with a profile picture, or a Post model with an associated image. With Amplify's GraphQL API and Storage categories, you can reference the file within the model itself to create an association.

Set up the project
Set up your project by following the instructions in the Quickstart guide.

Define the model
Open amplify/data/resource.ts and add the following model as shown below:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";

const schema = a.schema({
  Song: a
    .model({
      id: a.id().required(),
      name: a.string().required(),
      coverArtPath: a.string(),
    })
    .authorization((allow) => [allow.publicApiKey()]),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",

    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Setup the Storage
Next, Let's configure Storage and allow access to all authenticated(signed in) users of your application. create a file amplify/storage/resource.ts and add the following code,This will restrict file access to only the signed-in user.

amplify/storage/resource.ts
import { defineStorage } from "@aws-amplify/backend";

export const storage = defineStorage({
  name: "amplify-gen2-files",
  access: (allow) => ({
    "images/*": [allow.authenticated.to(["read", "write", "delete"])],
  }),
});
Configure the storage in the amplify/backend.ts file as demonstrated below:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { storage } from "./storage/resource";

export const backend = defineBackend({
  auth,
  data,
  storage,
});
Configuring authorization
Your application needs authorization credentials for reading and writing to both Storage and the Data, except in the case where all data and files are intended to be publicly accessible.

The Storage and Data categories govern data access based on their own authorization patterns, meaning that it's necessary to configure appropriate auth roles for each individual category. Although both categories share the same access credentials set up through the Auth category, they work independently from one another. For instance, adding an allow.authenticated() to the Data does not guard against file access in the Storage category. Likewise, adding authorization rules to the Storage category does not guard against data access in the API.

When you configure Storage, Amplify will configure appropriate IAM policies on the bucket using a Cognito Identity Pool role. You will then have the option of adding CRUD (Create, Update, Read and Delete) based permissions as well, so that Authenticated and Guest users will be granted limited permissions within these levels. Even after adding this configuration, all Storage access is still guest by default. To guard against accidental public access, the Storage access levels must either be configured on the Storage object globally, or set within individual function calls. This guide uses the former approach, setting all Storage access to authenticated users.

The ability to independently configure authorization rules for each category allows for more granular control over data access, and adds greater flexibility. For scenarios where authorization patterns must be mixed and matched, configure the access level on individual Storage function calls. For example, you may want to use entity_id CRUD access on an individual Storage function call for files that should only be accessible by the owner (such as personal files), authenticated read access to allow all logged in users to view common files (such as images in a shared photo album), and guest read access to allow all users to view a file (such as a public profile picture).

For more details on how to configure Storage authorization levels, see the Storage documentation. For more on configuring Data authorization, see the API documentation.

Create a record with an associated file
You can create a record via the Amplify Data client, upload a file to Storage, and finally update the record to associate it with the uploaded file. Use the following example with the Amplify Data client and Amplify Storage library helpers, uploadData and getUrl, to create a record and associate it the file with the record.

The API record's id is prepended to the Storage file name to ensure uniqueness. If this is excluded, multiple API records could then be associated with the same file path unintentionally.

src/App.tsx
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

// Create the API record:
const response = await client.models.Song.create({
  name: `My first song`,
});

const song = response.data;

if (!song) return;

// Upload the Storage file:
const result = await uploadData({
  path: `images/${song.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;

// Add the file association to the record:
const updateResponse = await client.models.Song.update({
  id: song.id,
  coverArtPath: result?.path,
});

const updatedSong = updateResponse.data;

setCurrentSong(updatedSong);

// If the record has no associated file, we can return early.
if (!updatedSong.coverArtPath) return;

// Retrieve the file's signed URL:
const signedURL = await getUrl({ path: updatedSong.coverArtPath });
Add or update a file for an associated record
To associate a file with a record, update the record with the path returned by the Storage upload. The following example uploads the file using Storage, updates the record with the file's path, then retrieves the signed URL to download the image. If an image is already associated with the record, this will update the record with the new image.

src/App.tsx
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

// Upload the Storage file:
const result = await uploadData({
  path: `images/${currentSong.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;

// Add the file association to the record:
const response = await client.models.Song.update({
  id: currentSong.id,
  coverArtPath: result?.path,
});

const updatedSong = response.data;

setCurrentSong(updatedSong);

// If the record has no associated file, we can return early.
if (!updatedSong?.coverArtPath) return;

// Retrieve the file's signed URL:
const signedURL = await getUrl({ path: updatedSong.coverArtPath });
Query a record and retrieve the associated file
To retrieve the file associated with a record, first query the record, then use Storage to get the signed URL. The signed URL can then be used to download the file, display an image, etc:

src/App.tsx
import { generateClient } from "aws-amplify/api";
import { getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

const response = await client.models.Song.get({
  id: currentSong.id,
});

const song = response.data;

// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;

// Retrieve the signed URL:
const signedURL = await getUrl({ path: song.coverArtPath });
Delete and remove files associated with API records
There are three common deletion workflows when working with Storage files and the GraphQL API:

Remove the file association, continue to persist both file and record.
Remove the record association and delete the file.
Delete both file and record.
Remove the file association, continue to persist both file and record
The following example removes the file association from the record, but does not delete the file from S3, nor the record from the database.

src/App.tsx
import { generateClient } from "aws-amplify/api";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

const response = await client.models.Song.get({
  id: currentSong.id,
});

const song = response.data;

// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;

const updatedSong = await client.models.Song.update({
  id: song.id,
  coverArtPath: null,
});
Remove the record association and delete the file
The following example removes the file from the record, then deletes the file from S3:

src/App.tsx
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});
const response = await client.models.Song.get({
  id: currentSong.id,
});
const song = response?.data;

// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;

// Remove associated file from record
const updatedSong = await client.models.Song.update({
  id: song.id,
  coverArtPath: null,
});

// Delete the file from S3:
await remove({ path: song.coverArtPath });
Delete both file and record
src/App.tsx
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});
const response = await client.models.Song.get({
  id: currentSong.id,
});

const song = response.data;

// If the record has no associated file, we can return early.
if (!song?.coverArtPath) return;

await remove({ path: song.coverArtPath });

// Delete the record from the API:
await client.models.Song.delete({ id: song.id });
Working with multiple files
You may want to add multiple files to a single record, such as a user profile with multiple images. To do this, you can add a list of file keys to the record. The following example adds a list of file keys to a record:

GraphQL schema to associate a data model with multiple files
Add the following model in `amplify/data/resource.ts" file.

amplify/data/resource.ts
const schema = a.schema({
  PhotoAlbum: a
    .model({
      id: a.id().required(),
      name: a.string().required(),
      imagePaths: a.string().array(),
    })
    .authorization((allow) => [allow.publicApiKey()]),
});
CRUD operations when working with multiple files is the same as when working with a single file, with the exception that we are now working with a list of image keys, as opposed to a single image key.

Create a record with multiple associated files
First create a record via the GraphQL API, then upload the files to Storage, and finally add the associations between the record and files.

src/App.tsx
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

// Create the API record:
const response = await client.models.PhotoAlbum.create({
  name: `My first photoAlbum`,
});

const photoAlbum = response.data.createPhotoAlbum;

if (!photoAlbum) return;

// Upload all files to Storage:
const imagePaths = await Promise.all(
  Array.from(e.target.files).map(async (file) => {
    const result = await uploadData({
      path: `images/${photoAlbum.id}-${file.name}`,
      data: file,
      options: {
        contentType: "image/png", // contentType is optional
      },
    }).result;

    return result.path;
  })
);

const updatePhotoAlbumDetails = {
  id: photoAlbum.id,
  imagePaths: imagePaths,
};

// Add the file association to the record:
const updateResponse = await client.graphql({
  query: mutations.updatePhotoAlbum,
  variables: { input: updatePhotoAlbumDetails },
});

const updatedPhotoAlbum = updateResponse.data.updatePhotoAlbum;

// If the record has no associated file, we can return early.
if (!updatedPhotoAlbum.imageKeys?.length) return;

// Retrieve signed urls for all files:
const signedUrls = await Promise.all(
  updatedPhotoAlbum?.imagePaths.map(
    async (path) => await getUrl({ path: path! })
  )
);
Add new files to an associated record
To associate additional files with a record, update the record with the paths returned by the Storage uploads.

src/App.tsx
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

// Upload all files to Storage:
const newimagePaths = await Promise.all(
  Array.from(e.target.files).map(async (file) => {
    const result = await uploadData({
      path: `images/${currentPhotoAlbum.id}-${file.name}`,
      data: file,
      options: {
        contentType: "image/png", // contentType is optional
      },
    }).result;

    return result.path;
  })
);

// Query existing record to retrieve currently associated files:
const queriedResponse = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});

const photoAlbum = queriedResponse.data;

if (!photoAlbum?.imagePaths) return;

// Merge existing and new file paths:
const updatedimagePaths = [...newimagePaths, ...photoAlbum.imagePaths];

// Update record with merged file associations:
const response = await client.models.PhotoAlbum.update({
  id: currentPhotoAlbum.id,
  imagePaths: updatedimagePaths,
});

const updatedPhotoAlbum = response.data;

// If the record has no associated file, we can return early.
if (!updatedPhotoAlbum?.imageKeys) return;

// Retrieve signed urls for merged image paths:
const signedUrls = await Promise.all(
  updatedPhotoAlbum?.imagePaths.map(
    async (path) => await getUrl({ path: path! })
  )
);
Update the file for an associated record
Updating a file for an associated record is the same as updating a file for a single file record, with the exception that you will need to update the list of file keys.

src/App.tsx
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

// Upload new file to Storage:
const result = await uploadData({
  path: `images/${currentPhotoAlbum.id}-${file.name}`,
  data: file,
  options: {
    contentType: "image/png", // contentType is optional
  },
}).result;

const newFilePath = result.path;

// Query existing record to retrieve currently associated files:
const queriedResponse = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});

const photoAlbum = queriedResponse.data;

if (!photoAlbum?.imagePaths?.length) return;

// Retrieve last image path:
const [lastImagePath] = photoAlbum.imagePaths.slice(-1);

// Remove last file association by path
const updatedimagePaths = [
  ...photoAlbum.imagePaths.filter((path) => path !== lastImagePath),
  newFilePath,
];

// Update record with updated file associations:
const response = await client.models.PhotoAlbum.update({
  id: currentPhotoAlbum.id,
  imagePaths: updatedimagePaths,
});

const updatedPhotoAlbum = response.data;

// If the record has no associated file, we can return early.
if (!updatedPhotoAlbum?.imagePaths) return;

// Retrieve signed urls for merged image paths:
const signedUrls = await Promise.all(
  updatedPhotoAlbum?.imagePaths.map(
    async (path) => await getUrl({ path: path! })
  )
);
Query a record and retrieve the associated files
To retrieve the files associated with a record, first query the record, then use Storage to retrieve all of the signed URLs.

src/App.tsx
async function getImagesForPhotoAlbum() {
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

// Query the record to get the file paths:
const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});

const photoAlbum = response.data;

// If the record has no associated files, we can return early.
if (!photoAlbum?.imagePaths) return;

// Retrieve the signed URLs for the associated images:
const signedUrls = await Promise.all(
  photoAlbum.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    return await getUrl({ path: imagePath });
  })
);
}
Delete and remove files associated with API records
The workflow for deleting and removing files associated with API records is the same as when working with a single file, except that when performing a delete you will need to iterate over the list of file paths and call Storage.remove() for each file.

Remove the file association, continue to persist both files and record
src/App.tsx
import { generateClient } from "aws-amplify/api";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});

const photoAlbum = response.data;

// If the record has no associated file, we can return early.
if (!photoAlbum?.imagePaths) return;

const updatedPhotoAlbum = await client.models.PhotoAlbum.update({
  id: photoAlbum.id,
  imagePaths: null,
});
Remove the record association and delete the files
src/App.tsx
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});

const photoAlbum = response.data;

// If the record has no associated files, we can return early.
if (!photoAlbum?.imagePaths) return;

// Remove associated files from record
const updateResponse = await client.models.PhotoAlbum.update({
  id: photoAlbum.id,
  imagePaths: null, // Set the file association to `null`
});

const updatedPhotoAlbum = updateResponse.data;

// Delete the files from S3:
await Promise.all(
  photoAlbum?.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    await remove({ path: imagePath });
  })
);
Delete record and all associated files
src/App.tsx
import { generateClient } from "aws-amplify/api";
import { remove } from "aws-amplify/storage";
import type { Schema } from "../amplify/data/resource";

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

const response = await client.models.PhotoAlbum.get({
  id: currentPhotoAlbum.id,
});

const photoAlbum = response.data;

if (!photoAlbum) return;

await client.models.PhotoAlbum.delete({
  id: photoAlbum.id,
});

setCurrentPhotoAlbum(null);

// If the record has no associated file, we can return early.
if (!photoAlbum?.imagePaths) return;

await Promise.all(
  photoAlbum?.imagePaths.map(async (imagePath) => {
    if (!imagePath) return;
    await remove({ path: imagePath });
  })
);
Data consistency when working with records and files
The recommended access patterns in these docs attempt to remove deleted files, but favor leaving orphans over leaving records that point to non-existent files. This optimizes for read latency by ensuring clients rarely attempt to fetch a non-existent file from Storage. However, any app that deletes files can inherently cause records on-device to point to non-existent files.

One example is when we create an API record, associate the Storage file with that record, and then retrieve the file's signed URL. "Device A" calls the GraphQL API to create API_Record_1, and then associates that record with First_Photo. Before "Device A" is about to retrieve the signed URL, "Device B" might query API_Record_1, delete First_Photo, and update the record accordingly. However, "Device A" is still using the old API_Record_1, which is now out-of-date. Even though the shared global state is correctly in sync at every stage, the individual device ("Device A") has an out-of-date record that points to a non-existent file. Similar issues can conceivably occur for updates. Depending on your app, some of these mismatches can be minimized even more with real-time data / GraphQL subscriptions.

It is important to understand when these mismatches can occur and to add meaningful error handling around these cases. This guide does not include exhaustive error handling, real-time subscriptions, re-querying of outdated records, or attempts to retry failed operations. However, these are all important considerations for a production-level application.

Complete examples
Single File (TS)
Multi-File (TS)
src/App.tsx
import "./App.css";
import { generateClient } from "aws-amplify/api";
import { uploadData, getUrl, remove } from "aws-amplify/storage";
import React, { useState } from "react";
import type { Schema } from "../amplify/data/resource";
import "@aws-amplify/ui-react/styles.css";
import {
  type WithAuthenticatorProps,
  withAuthenticator,
} from "@aws-amplify/ui-react";
import { Amplify } from "aws-amplify";
import outputs from "../amplify_outputs.json";

Amplify.configure(outputs);

// Generating the client
const client = generateClient<Schema>({
  authMode: "apiKey",
});

type Song = Schema["Song"]["type"];

function App({ signOut, user }: WithAuthenticatorProps) {

  const [currentSong, setCurrentSong] = useState<Song | null>(null);

  // Used to display image for current song:
  const [currentImageUrl, setCurrentImageUrl] = useState<
    string | null | undefined
    >("");

  async function createSongWithImage(e: React.ChangeEvent<HTMLInputElement>) {
    if (!e.target.files) return;
    const file = e.target.files[0];
    try {

      // Create the API record:
      const response = await client.models.Song.create({
        name: `My first song`,
      });

      const song = response.data;

      if (!song) return;

      // Upload the Storage file:
      const result = await uploadData({
        path: `images/${song.id}-${file.name}`,
        data: file,
        options: {
          contentType: "image/png", // contentType is optional
        },
      }).result;

      // Add the file association to the record:
      const updateResponse = await client.models.Song.update({
        id: song.id,
        coverArtPath: result?.path,
      });

      const updatedSong = updateResponse.data;
      setCurrentSong(updatedSong);

      // If the record has no associated file, we can return early.
      if (!updatedSong?.coverArtPath) return;

      // Retrieve the file's signed URL:
      const signedURL = await getUrl({ path: updatedSong.coverArtPath });

      setCurrentImageUrl(signedURL.url.toString());
    } catch (error) {
      console.error("Error create song / file:", error);
    }
  }

  // Upload image, add to song, retrieve signed URL and retrieve the image.
  // Also updates image if one already exists.
  async function addNewImageToSong(e: React.ChangeEvent<HTMLInputElement>) {

    if (!currentSong) return;

    if (!e.target.files) return;

    const file = e.target.files[0];

    try {
      // Upload the Storage file:
      const result = await uploadData({
        path: `images/${currentSong.id}-${file.name}`,
        data: file,
        options: {
          contentType: "image/png", // contentType is optional
        },
      }).result;

      // Add the file association to the record:
      const response = await client.models.Song.update({
        id: currentSong.id,
        coverArtPath: result?.path,
      });

      const updatedSong = response.data;

      setCurrentSong(updatedSong);

      // If the record has no associated file, we can return early.
      if (!updatedSong?.coverArtPath) return;

      // Retrieve the file's signed URL:
      const signedURL = await getUrl({ path: updatedSong.coverArtPath });
      setCurrentImageUrl(signedURL.url.toString());

    } catch (error) {
      console.error("Error uploading image / adding image to song: ", error);
    }
  }

  async function getImageForCurrentSong() {
    if (!currentSong) return;

    try {
      // Query the record to get the file path:
      const response = await client.models.Song.get({
        id: currentSong.id,
      });

      const song = response.data;

      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;

      // Retrieve the signed URL:
      const signedURL = await getUrl({ path: song.coverArtPath });
      setCurrentImageUrl(signedURL.url.toString());
    } catch (error) {
      console.error("Error getting song / image:", error);
    }
  }

  // Remove the file association, continue to persist both file and record
  async function removeImageFromSong() {

    if (!currentSong) return;

    try {
      const response = await client.models.Song.get({
        id: currentSong.id,
      });

      const song = response.data;

      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;

      const updatedSong = await client.models.Song.update({
        id: song.id,
        coverArtPath: null,
      });

      // If successful, the response here will be `null`:
      setCurrentSong(updatedSong.data);

      setCurrentImageUrl(updatedSong.data?.coverArtPath);

    } catch (error) {
      console.error("Error removing image from song: ", error);
    }
  }

  // Remove the record association and delete the file
  async function deleteImageForCurrentSong() {

    if (!currentSong) return;

    try {
      const response = await client.models.Song.get({
        id: currentSong.id,
      });

      const song = response?.data;

      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;

      // Remove associated file from record
      const updatedSong = await client.models.Song.update({
        id: song.id,
        coverArtPath: null,
      });

      // Delete the file from S3:
      await remove({ path: song.coverArtPath });

      // If successful, the response here will be `null`:
      setCurrentSong(updatedSong.data);

      setCurrentImageUrl(updatedSong.data?.coverArtPath);

    } catch (error) {
      console.error("Error deleting image: ", error);
    }
  }

  // Delete both file and record
  async function deleteCurrentSongAndImage() {

    if (!currentSong) return;
    try {
      const response = await client.models.Song.get({
        id: currentSong.id,
      });
      const song = response.data;

      // If the record has no associated file, we can return early.
      if (!song?.coverArtPath) return;

      await remove({ path: song.coverArtPath });

      // Delete the record from the API:
      await client.models.Song.delete({ id: song.id });

      clearLocalState();

    } catch (error) {
      console.error("Error deleting song: ", error);
    }
  }

  function clearLocalState() {
    setCurrentSong(null);
    setCurrentImageUrl("");
  }

  return (
    <>
      <h1>Hello {user?.username}</h1>
      <button onClick={signOut}>Sign out</button>
      <div>
        <label>
          <h2>{`Current Song: ${currentSong?.id}`}</h2>
          Create song with file:
          <input id="name" type="file" onChange={createSongWithImage} />
        </label>
        <label>
          Add / update song image:
          <input
            id="name"
            type="file"
            onChange={addNewImageToSong}
            disabled={!currentSong}
          />
        </label>
        <button
          onClick={getImageForCurrentSong}
          disabled={!currentSong || !currentImageUrl}
        >
          Get image for current song
        </button>
        <button
          onClick={removeImageFromSong}
          disabled={!currentSong || !currentImageUrl}
        >
          Remove image from current song (does not delete image)
        </button>
        <button
          onClick={deleteImageForCurrentSong}
          disabled={!currentSong || !currentImageUrl}
        >
          Remove image from current song, then delete image
        </button>
        <button onClick={deleteCurrentSongAndImage} disabled={!currentSong}>
          Delete current song (and image, if it exists)
        </button>
        <button onClick={signOut} className="app-button">
          Sign out
        </button>
      </div>
    </>
  );
}

export default withAuthenticator(App);

- Add custom real-time subscriptions - 
Create a custom real-time subscription for any mutation to enable PubSub use cases.

Define a custom subscription
For every custom subscription, you need to set:

the mutation(s) that should trigger a subscription event,
a return type that matches the subscribed mutations' return type,
authorization rules.
Optionally, you can set filter arguments to customize the server-side subscription filter rules.

Use a.subscription() to define your custom subscription in your amplify/data/resource.ts file:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';

const schema = a.schema({
  // Message type that's used for this PubSub sample
  Message: a.customType({
    content: a.string().required(),
    channelName: a.string().required()
  }),

  // Message publish mutation
  publish: a.mutation()
    .arguments({
      channelName: a.string().required(),
      content: a.string().required()
    })
    .returns(a.ref('Message'))
    .handler(a.handler.custom({ entry: './publish.js' }))
    .authorization(allow => [allow.publicApiKey()]),

  // Subscribe to incoming messages
  receive: a.subscription()
    // subscribes to the 'publish' mutation
    .for(a.ref('publish')) 
    // subscription handler to set custom filters
    .handler(a.handler.custom({entry: './receive.js'})) 
    // authorization rules as to who can subscribe to the data
    .authorization(allow => [allow.publicApiKey()]),

  // A data model to manage channels
  Channel: a.model({
    name: a.string(),
  }).authorization(allow => [allow.publicApiKey()]),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema
});
For this example, we're building a generic PubSub capability. This requires us to convert the arguments for publish into the Channel's format. Create a new publish.js file in your amplify/data/ folder with the following contents:

amplify/data/publish.js
// This handler simply passes through the arguments of the mutation through as the result
export function request() {
  return {}
}

/**
 * @param {import('@aws-appsync/utils').Context} ctx
 */
export function response(ctx) {
  return ctx.args
}
Next, create a new receive.js file in your amplify/data/ folder to define handlers for your subscription. In this case, it'll just be a simple passthrough. In the next section, we'll explore how to use this handler to construct more advanced subscription filters.

Note: We're planning a developer experience enhancement in the near future that'll create this passthrough under the hood.

amplify/data/receive.js
export function request() {
  return {};
}

export const response = (ctx) => {
  return ctx.result;
};
Subscribe to custom subscriptions client-side
From your generated Data client, you can find all your custom subscriptions under client.subscriptions. Subscribe using the .subscribe() function and then use the next function to handle incoming events.

import { generateClient } from 'aws-amplify/data'
import type { Schema } from '../amplify/data/resource'

const client = generateClient<Schema>()

const sub = client.subscriptions.receive()
  .subscribe({
    next: event => {
      console.log(event)
    }
  }
)
You can try publishing an event using the custom mutation to test the real-time subscription.

client.mutations.publish({
  channelName: "world",
  content: "My first message!"
})
Your subscription event should be received and logs the payload into your app's developer console. Unsubscribe your subscription to disconnect using the unsubscribe() function.

sub.unsubscribe()
(Optionally) Add server-side subscription filters
You can add subscription filters by adding arguments to the custom subscriptions.

If you want to customize the filters, modify the subscription handler. For this example, we'll allow a customer to pass in a namePrefix parameter that allows the end users to only receive channel events in channels that start with the namePrefix.

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from '@aws-amplify/backend';

const schema = a.schema({
  Channel: a.model({
    name: a.string(),
  }).authorization(allow => [allow.publicApiKey()]),

  Message: a.customType({
    content: a.string().required(),
    channelName: a.string().required()
  }),

  publish: a.mutation()
    .arguments({
      channelName: a.string().required(),
      content: a.string().required()
    })
    .returns(a.ref('Message'))
    .handler(a.handler.custom({ entry: './publish.js' }))
    .authorization(allow => [allow.publicApiKey()]),

  receive: a.subscription()
    .for(a.ref('publish'))
    .arguments({ namePrefix: a.string() })
    .handler(a.handler.custom({entry: './receive.js'}))
    .authorization(allow => [allow.publicApiKey()])
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema
});
In your handler, you can set custom subscription filters based on arguments passed into the custom subscription. For this example, create a new receive.js file alongside the amplify/data/resource.ts file:

import { util, extensions } from "@aws-appsync/utils"

// Subscription handlers must return a `null` payload on the request
export function request() { return { payload: null } }

/**
 * @param {import('@aws-appsync/utils').Context} ctx
 */
export function response(ctx) {
  const filter = {
    channelName: {
      beginsWith: ctx.args.namePrefix
    }
  }

  extensions.setSubscriptionFilter(util.transform.toSubscriptionFilter(filter))

  return null
}

- Connect your app to existing MySQL and PostgreSQL database - 
Amplify's native integration supports any MySQL or Postgres database, no matter if they're hosted on AWS within a VPC or outside of AWS with a 3rd party hosted database provider.

You must create a connection string using the following database information to get started:

Database hostname
Database port
Database username
Database user password
Database name
Step 1 - Set secrets for database connection
First, provide all the database connection information as secrets, you can use the Amplify sandbox's secret functionality to set them or go to the Amplify console to set secrets in a shared environment:

npx ampx sandbox secret set SQL_CONNECTION_STRING
MySQL
PostgreSQL
Connection string format for MySQL

mysql://user:password@hostname:port/db-name
Step 2 - Generate TypeScript representation of your database schema
Run the following command to generate the Data schema with your database connection information. It'll infer an a.model() representation for all database tables that have primary key specified.

npx ampx generate schema-from-database --connection-uri-secret SQL_CONNECTION_STRING --out amplify/data/schema.sql.ts
Info
Connecting to a database behind the VPC
Info
Handling of implicit fields (id, createdAt, updatedAt)
Learn more
RDS Proxy for improved connectivity
Connecting to a database with a custom SSL certificate
This creates a new schema.sql.ts with a schema reflecting the types of your database. Do not edit the schema.sql.ts file directly. Import the schema to your amplify/data/resource.ts file and apply any additive changes there. This ensures that you can continuously regenerate the TypeScript schema representation of your SQL database without losing any additive changes that you apply out-of-band.

import { type ClientSchema, a, defineData } from '@aws-amplify/backend';
import { schema as generatedSqlSchema } from './schema.sql';

// Add a global authorization rule
const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())

// Relational database sources can coexist with DynamoDB tables managed by Amplify.
const schema = a.schema({
  Todo: a.model({
    content: a.string(),
  }).authorization(allow => [allow.guest()])
});

// Use the a.combine() operator to stitch together the models backed by DynamoDB
// and the models backed by Postgres or MySQL databases.
const combinedSchema = a.combine([schema, sqlSchema]);

// Don't forget to update your client types to take into account the types from
// both schemas.
export type Schema = ClientSchema<typeof combinedSchema>;

export const data = defineData({
  // Update the data definition to use the combined schema, instead of just
  // your DynamoDB-backed schema
  schema: combinedSchema
});
Step 3 - Fine-grained authorization rules
Use the .setAuthorization() modifier to set model-level and field-level authorization rules for the SQL-backed data models. Review Customize your auth rules for detailed authorization rule options.

// Add an authorization rule to the schema
const sqlSchema = generatedSqlSchema.setAuthorization((models) => [
  // Model-level authorization rules
  models.event.authorization((allow) => [allow.publicApiKey()]),
  // Field-level authorization rules
  models.event.fields.id.authorization(allow => [allow.publicApiKey(), allow.guest()]),
  models.event.fields.created_at.authorization(allow => [allow.publicApiKey(), allow.guest()])
]);
Step 4 - Deploy your Data resources using the cloud sandbox
Finally, you can now validate your Data resources with your cloud sandbox:

npx ampx sandbox
On the client side, you can now make create, read, update, delete, and subscribe to your SQL-backed data models:

const { data: events } = await client.models.event.list()
Step 5 - Configuring database connection for production
When deploying your app to production, you need to add the database connection string as a secret. Make sure to add the appropriate database connection string with the same secret name you used in the sandbox environment. For example, we used SQL_CONNECTION_STRING above.

Rename generated models and fields
To improve the ergonomics of your API, you might want to rename the generate fields or types to better accommodate your use case. Use the renameModels() modifier to rename the auto-inferred data models.

// Rename models or fields to be more idiomatic for frontend code
const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())
  .renameModels(() => [
    // existing model name based on table name
    ['event', 'Event']
    //        ^^^^^^ renamed data model name
  ])
Add relationships between tables
const sqlSchema = generatedSqlSchema
  .authorization(allow => allow.guest())
  .setRelationships((models) => [
    models.Note.relationships({
      comments: a.hasMany("Comment", "note_id"),
    }),
    models.Comment.relationships({
      note: a.belongsTo("Note", "note_id")
    })
  ]);
Add custom queries, mutations, subscriptions auto-generated SQL data schema
Use the .addToSchema(...) to add in additional queries, mutations, and subscriptions to your auto-generated SQL data schema.

Note: you can't add additional data models via a.model(). They should be exclusively generated via npx ampx generate schema-from-database.

Use an inline SQL statement as a query or mutation handler
// Add custom mutations or queries that execute SQL statements
const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())
  .addToSchema({
    listEventsWithDecodedLatLong: a.query()
      // reference custom types added to the schema
      .returns(a.ref("EventWithDecodedCoord").array())
      .handler(a.handler.inlineSql(
          `SELECT
            id,
            name,
            address,
            ST_X(geom) AS longitude,
            ST_Y(geom) AS latitude
          FROM locations;`
      ))
      .authorization(allow => [allow.guest()]),

      // Define custom types to provide end-to-end typed results
      // for custom queries / mutations
      EventWithDecodedCoord: a.customType({
        id: a.integer(),
        name: a.string(),
        address: a.string(),
        longitude: a.float(),
        latitude: a.float(),
      })
  })
Reference an existing SQL file as a query or mutation handler
You can define the different SQL handlers in separate .sql files and reference them in your custom queries / mutations.

First, configure the custom query or mutation in your amplify/data/resource.ts file:

const sqlSchema = generatedSqlSchema.authorization(allow => allow.guest())
  .addToSchema({
    createNewLocationWithLongLat: a.mutation()
      .arguments({
        lat: a.float().required(),
        long: a.float().required(),
        name: a.string().required(),
        address: a.string().required()
      })
      .returns(a.json().array())
      .authorization(allow => allow.authenticated())
      .handler(a.handler.sqlReference('./createNewLocationWithLongLat.sql'))
  })
Next, add a corresponding sql file to handle the request:

MySQL
PostgreSQL
createNewLocationWithLongLat.sql
INSERT INTO locations (name, address, geom)
VALUES (:name, :address, ST_GEOMFROMTEXT(CONCAT('POINT (', :long, ' ', :lat, ')'), 4326));
The return type for custom queries and mutations expecting to return row data from SQL statements must be an array of the corresponding model. This is true even for custom get queries, where a single row is expected.

Example

getPostBySlug: a
  .query()
  .arguments({
    slug: a.string().required(),
  })
  .returns(a.ref("Post").array())
  .handler(
    a.handler.inlineSql(`
    SELECT id, title, slug, content, created_at, updated_at
    FROM posts
    WHERE slug = :slug;
    `)
  )
How does it work?
The Amplify uses AWS Lambda functions to enable features like querying data from your database. To work properly, these Lambda functions need access to common logic and dependencies.

Amplify provides this shared code in the form of Lambda Layers. You can think of Lambda Layers as a package of reusable runtime code that Lambda functions can reference.

When you deploy an Amplify API, it will create two Lambda functions:

SQL Lambda
This allows you to query and write data to your database from your API.

NOTE: If the database is in a VPC, this Lambda function will be deployed in the same VPC as the database. The usage of Amazon Virtual Private Cloud (VPC) or VPC peering, with AWS Lambda functions will incur additional charges as explained, this comes with an additional cost as explained on the Amazon Elastic Compute Cloud (EC2) on-demand pricing page.

Updater Lambda
This automatically keeps the SQL Lambda up-to-date by managing its Lambda Layers.

A Lambda layer that includes all the core SQL connection logic lives within the AWS Amplify service account but is executed within your AWS account, when invoked by the SQL Lambda. This allows the Amplify service team to own the ongoing maintenance and security enhancements of the SQL connection logic.

This allows the Amplify team to maintain and enhance the SQL Layer without needing direct access to your Lambdas. If updates to the Layer are needed, the Updater Lambda will receive a signal from Amplify and automatically update the SQL Lambda with the latest Layer.

Mapping of SQL data types to field types for auto-generated schema
Note: MySQL does not support time zone offsets in date time or timestamp fields. Instead, we will convert these values to datetime, without the offset. Unlike MySQL, PostgreSQL does support date time or timestamp values with an offset.

SQL	Mapped field types
String	
char	a.string()
varchar	a.string()
tinytext	a.string()
text	a.string()
mediumtext	a.string()
longtext	a.string()
Geometry	
geometry	a.string()
point	a.string()
linestring	a.string()
geometryCollection	a.string()
Numeric	
smallint	a.integer()
mediumint	a.integer()
int	a.integer()
integer	a.integer()
bigint	a.integer()
tinyint	a.integer()
float	a.float()
double	a.float()
decimal	a.float()
dec	a.float()
numeric	a.float()
Date and Time	
date	a.date()
datetime	a.datetime()
timestamp	a.datetime()
time	a.time()
year	a.integer()
Binary	
binary	a.string()
varbinary	a.string()
tinyblob	a.string()
blob	a.string()
mediumblob	a.string()
longblob	a.string()
Others	
bool	a.boolean()
boolean	a.boolean()
bit	a.integer()
json	a.json()
enum	a.enum()
Troubleshooting
Debug Mode
To return the actual SQL error instead of a generic error from underlying API responses, an environment variable DEBUG_MODE can be set to true on the Amplify-generated SQL Lambda function. You can find this Lambda function in the AWS Lambda console with the naming convention of: <stack-name>-<api-name>-SQLLambdaFunction<hash>.

My SQL table doesn't get generated when running npx ampx generate schema-from-database
This is likely because the table doesn't have a designated primary key. A primary key is required for npx ampx generate schema-from-database to infer the table structure and create a create, read, update, and delete API.

- Connect to external Amazon DynamoDB data sources - 
The a.model() data model allows you to define a GraphQL schema for an AWS AppSync API where models are backed by DynamoDB Tables managed by Amplify. The generated schema also provides queries and mutations to the Amplify Data client. However, you may want to connect to an external DynamoDB table and execute custom business logic against it instead.

Using an external DynamoDB table as a data source may be useful if you need to leverage patterns such as single table design.

In the following sections, we walk through the steps to add and use an external DynamoDB table as a data source for your API:

Set up your Amazon DynamoDB table
Add your Amazon DynamoDB table as a data source
Define custom queries and mutations
Configure custom business logic handler code
Invoke custom queries or mutations
Step 1 - Set up your Amazon DynamoDB table
For the purpose of this guide we will define a Post type and create an external DynamoDB table that will store records for it. In Amplify Gen 2, customType adds a type to the schema that is not backed by an Amplify-generated DynamoDB table.

With the Post type defined, it can then be referenced as the return type when defining your custom queries and mutations.

First, add the Post custom type to your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";

const schema = a.schema({
  Todo: a
    .model({
      content: a.string(),
    })
    .authorization(allow => [allow.publicApiKey()]),
  Post: a.customType({
    id: a.id().required(),
    author: a.string().required(),
    title: a.string(),
    content: a.string(),
    url: a.string(),
    ups: a.integer(),
    downs: a.integer(),
    version: a.integer(),
  }),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
NOTE: To comply with the GraphQL spec, at least one query is required for a schema to be valid. Otherwise, deployments will fail with a schema error. The Amplify Data schema is auto-generated with a Todo model and corresponding queries under the hood. You can leave the Todo model in the schema until you add the first custom query to the schema in the next steps.

Once the deployment successfully completes, navigate to the AppSync console and select your Amplify-generated API. Follow these steps to create a new DynamoDB table:

On the Schema page, choose Create Resources.
AWS AppSync console showing navigation pane with "AWS AppSync" expanded and "APIs" > "TestAPI" selected. Main content displays "Schema Info" section with a "Create Resources" button.

Choose Use existing type, then choose the Post type.
AWS AppSync console, "Create Resources" page. A prominent heading reads "Create Resources". Radio buttons are presented for either defining a new type or selecting an existing type for the table creation.

Set the Primary key to id and the Sort key to None.

Disable Automatically generate GraphQL. In this example, we'll create the resolver ourselves.

AWS AppSync console, "Create a table to hold Post objects" page. A table structure is shown with columns and values of "Table name": "PostTable", "Primary Key": "id", and "Sort key": "None". Below the table, there is an option to "Automatically generate GraphQL" which is disabled.

Choose Create.
You now have a new DynamoDB table named PostTable, which you can see by visiting Data sources in the side tab. You will use this table as the data source for your custom queries and mutations to your Amazon DynamoDB table.

AWS AppSync console, 'Data sources' page. The page shows a list of existing data sources connected to an API. The data sources include an Amazon DynamoDB table named 'PostTable' and another table named 'Todo'.*

Step 2 - Add your Amazon DynamoDB table as a data source
In your amplify/backend.ts file, add your DynamoDB table as a data source for your API:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { aws_dynamodb } from "aws-cdk-lib";

export const backend = defineBackend({
  auth,
  data,
});

const externalDataSourcesStack = backend.createStack("MyExternalDataSources");

const externalTable = aws_dynamodb.Table.fromTableName(
  externalDataSourcesStack,
  "MyExternalPostTable",
  "PostTable"
);

backend.data.addDynamoDbDataSource(
  "ExternalPostTableDataSource",
  externalTable
);
Step 3 - Define custom queries and mutations
Now that your DynamoDB table has been added as a data source, you can reference it in custom queries and mutations using the a.handler.custom() modifier which accepts the name of the data source and an entry point for your resolvers.

Use the following code examples to add addPost, getPost, updatePost, and deletePost as custom queries and mutations to your schema:

addPost
getPost
updatePost
deletePost
amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";

const schema = a.schema({
  Post: a.customType({
    author: a.string().required(),
    title: a.string(),
    content: a.string(),
    url: a.string(),
    ups: a.integer(),
    downs: a.integer(),
    version: a.integer(),
  }),
  addPost: a
    .mutation()
    .arguments({
      id: a.id(),
      author: a.string().required(),
      title: a.string(),
      content: a.string(),
      url: a.string(),
    })
    .returns(a.ref("Post"))
    .authorization(allow => [allow.publicApiKey()])
    .handler(
      a.handler.custom({
        dataSource: "ExternalPostTableDataSource",
        entry: "./addPost.js",
      })
    ),
});

export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: 'apiKey',
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Step 4 - Configure custom business logic handler code
Next, create the following files in your amplify/data folder and use the code examples to define custom resolvers for the custom queries and mutations added to your schema from the previous step. These are AppSync JavaScript resolvers

addPost
getPost
updatePost
deletePost
amplify/data/addPost.js
import { util } from "@aws-appsync/utils";
import * as ddb from "@aws-appsync/utils/dynamodb";

export function request(ctx) {
  const item = { ...ctx.arguments, ups: 1, downs: 0, version: 1 };
  const key = { id: ctx.args.id ?? util.autoId() };
  return ddb.put({ key, item });
}

export function response(ctx) {
  return ctx.result;
}
Step 5 - Invoke custom queries or mutations
From your generated Data client, you can find all your custom queries and mutations under the client.queries. and client.mutations. APIs respectively.

addPost
getPost
updatePost
deletePost
App.tsx
const { data, errors } = await client.mutations.addPost({
  title: "My Post",
  content: "My Content",
  author: "Chris",
});
Conclusion
In this guide, youve added an external DynamoDB table as a data source to an Amplify GraphQL API and defined custom queries and mutations, handled by AppSync JS resolvers, to manipulate Post items in an external DynamoDB table using the Amplify Gen 2 Data client.

To clean up, you can delete your sandbox by accepting the prompt when terminating the sandbox process in your terminal. Alternatively, you can also use the AWS Amplify console to manage and delete sandbox environments.

To delete your external DynamoDB table, you can navigate to the AppSync console and click on the name of the table in the data sources list. This takes you to the DynamoDB console where you can delete the table.

All DynamoDB operations & example resolvers
GetItem
Reference - The GetItem request lets you tell the AWS AppSync DynamoDB function to make a GetItem request to DynamoDB, and enables you to specify:

The key of the item in DynamoDB
Whether to use a consistent read or not
Example:

export function request(ctx) {
  const { foo, bar } = ctx.args;
  return {
    operation: 'GetItem',
    key: util.dynamodb.toMapValues({ foo, bar }),
    consistentRead: true
  };
}
PutItem
PutItem - The PutItem request mapping document lets you tell the AWS AppSync DynamoDB function to make a PutItem request to DynamoDB, and enables you to specify the following:

The key of the item in DynamoDB
The full contents of the item (composed of key and attributeValues)
Conditions for the operation to succeed
Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { foo, bar, ...values } = ctx.args;
  return {
    operation: 'PutItem',
    key: util.dynamodb.toMapValues({ foo, bar }),
    attributeValues: util.dynamodb.toMapValues(values)
  };
}
UpdateItem
UpdateItem - The UpdateItem request enables you to tell the AWS AppSync DynamoDB function to make a UpdateItem request to DynamoDB and allows you to specify the following:

The key of the item in DynamoDB
An update expression describing how to update the item in DynamoDB
Conditions for the operation to succeed
Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { id } = ctx.args;
  return {
    operation: 'UpdateItem',
    key: util.dynamodb.toMapValues({ id }),
    update: {
      expression: 'ADD #voteField :plusOne, version :plusOne',
      expressionNames: { '#voteField': 'upvotes' },
      expressionValues: { ':plusOne': { N: 1 } }
    }
  };
}
DeleteItem
DeleteItem - The DeleteItem request lets you tell the AWS AppSync DynamoDB function to make a DeleteItem request to DynamoDB, and enables you to specify the following:

The key of the item in DynamoDB
Conditions for the operation to succeed
Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  return {
    operation: 'DeleteItem',
    key: util.dynamodb.toMapValues({ id: ctx.args.id })
  };
}
Query
Query - The Query request object lets you tell the AWS AppSync DynamoDB resolver to make a Query request to DynamoDB, and enables you to specify the following:

Key expression
Which index to use
Any additional filter
How many items to return
Whether to use consistent reads
query direction (forward or backward)
Pagination token
Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { owner } = ctx.args;
  return {
    operation: 'Query',
    query: {
      expression: 'ownerId = :ownerId',
      expressionValues: util.dynamodb.toMapValues({ ':ownerId': owner })
    },
    index: 'owner-index'
  };
}
Scan
Scan - The Scan request lets you tell the AWS AppSync DynamoDB function to make a Scan request to DynamoDB, and enables you to specify the following:

A filter to exclude results
Which index to use
How many items to return
Whether to use consistent reads
Pagination token
Parallel scans
Example:

export function request(ctx) {
  return { operation: 'Scan' };
}
Sync
Sync - The Sync request object lets you retrieve all the results from a DynamoDB table and then receive only the data altered since your last query (the delta updates). Sync requests can only be made to versioned DynamoDB data sources. You can specify the following:

A filter to exclude results

How many items to return

Pagination Token

When your last Sync operation was started

Example:

export function request(ctx) {
  const { nextToken, lastSync } = ctx.args;
  return { operation: 'Sync', limit: 100, nextToken, lastSync };
}
BatchGetItem
BatchGetItem - The BatchGetItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchGetItem request to DynamoDB to retrieve multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table names where to retrieve the items from

The keys of the items to retrieve from each table

The DynamoDB BatchGetItem limits apply and no condition expression can be provided.

Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { authorId, postId } = ctx.args;
  return {
    operation: 'BatchGetItem',
    tables: {
      authors: [util.dynamodb.toMapValues({ authorId })],
      posts: [util.dynamodb.toMapValues({ authorId, postId })],
    },
  };
}
BatchDeleteItem
BatchDeleteItem - The BatchDeleteItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchWriteItem request to DynamoDB to delete multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table names where to delete the items from

The keys of the items to delete from each table

The DynamoDB BatchWriteItem limits apply and no condition expression can be provided.

Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { authorId, postId } = ctx.args;
  return {
    operation: 'BatchDeleteItem',
    tables: {
      authors: [util.dynamodb.toMapValues({ authorId })],
      posts: [util.dynamodb.toMapValues({ authorId, postId })],
    },
  };
}
BatchPutItem
BatchPutItem - The BatchPutItem request object lets you tell the AWS AppSync DynamoDB function to make a BatchWriteItem request to DynamoDB to put multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table names where to put the items in

The full items to put in each table

The DynamoDB BatchWriteItem limits apply and no condition expression can be provided.

Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { authorId, postId, name, title } = ctx.args;
  return {
    operation: 'BatchPutItem',
    tables: {
      authors: [util.dynamodb.toMapValues({ authorId, name })],
      posts: [util.dynamodb.toMapValues({ authorId, postId, title })],
    },
  };
}
TransactGetItems
TransactGetItems - The TransactGetItems request object lets you to tell the AWS AppSync DynamoDB function to make a TransactGetItems request to DynamoDB to retrieve multiple items, potentially across multiple tables. For this request object, you must specify the following:

The table name of each request item where to retrieve the item from

The key of each request item to retrieve from each table

The DynamoDB TransactGetItems limits apply and no condition expression can be provided.

Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { authorId, postId } = ctx.args;
  return {
    operation: 'TransactGetItems',
    transactItems: [
      {
        table: 'posts',
        key: util.dynamodb.toMapValues({ postId }),
      },
      {
        table: 'authors',
        key: util.dynamodb.toMapValues({ authorId }),
      },
    ],
  };
}
TransactWriteItems
TransactWriteItems - The TransactWriteItems request object lets you tell the AWS AppSync DynamoDB function to make a TransactWriteItems request to DynamoDB to write multiple items, potentially to multiple tables. For this request object, you must specify the following:

The destination table name of each request item

The operation of each request item to perform. There are four types of operations that are supported: PutItem, UpdateItem, DeleteItem, and ConditionCheck

The key of each request item to write

The DynamoDB TransactWriteItems limits apply.

Example:

import { util } from '@aws-appsync/utils';

export function request(ctx) {
  const { authorId, postId, title, description, oldTitle, authorName } = ctx.args;
  return {
    operation: 'TransactWriteItems',
    transactItems: [
      {
        table: 'posts',
        operation: 'PutItem',
        key: util.dynamodb.toMapValues({ postId }),
        attributeValues: util.dynamodb.toMapValues({ title, description }),
        condition: util.transform.toDynamoDBConditionExpression({
          title: { eq: oldTitle },
        }),
      },
      {
        table: 'authors',
        operation: 'UpdateItem',
        key: util.dynamodb.toMapValues({ authorId }),
        update: {
          expression: 'SET authorName = :name',
          expressionValues: util.dynamodb.toMapValues({ ':name': authorName }),
        },
      },
    ],
  };
}

- Next.js server runtime - 
This guide walks through how you can connect to Amplify Data from Next.js Server-side Runtimes (SSR). For Next.js applications, Amplify provides first-class support for the App Router (React Server Components, Route Handlers, and Server Actions), the Pages Router (Components, API Routes), and Middleware.

Before you begin, you will need:

A Next.js application created
Installed and configured Amplify libraries for Next.js
Deployed Amplify Data resources, or directly using AWS AppSync
Connect to Amplify Data from a Next.js server runtime
Connecting to Amplify Data will include choosing the correct data client for Next.js server runtimes, generating the data client, and then calling the API.

Step 1 - Choose the correct Data client for Next.js server runtimes
Amplify offers two specialized data clients for Next.js server runtimes (from @aws-amplify/adapter-nextjs/data) that you should use depending whether you retrieve the user tokens using cookies or NextRequest and NextResponse:

generateServerClientUsingCookies()  generates a data client with the Next.js cookies function from next/headers. Each API request dynamically refetches the cookies at runtime.
generateServerClientUsingReqRes()  generates a data client requiring NextRequest and NextResponse provided to an runWithAmplifyServerContext function to prevent token contamination.
Choose the correct data client based on your Next.js Router (App or Pages) and then the use case:

App Router
Pages Router
Use case	Required Data client
React Server Component	generateServerClientUsingCookies() 
Server Actions	generateServerClientUsingCookies() 
Route Handler	generateServerClientUsingCookies() 
Middleware	generateServerClientUsingReqRes() 
Step 2 - Generate the Data client for Next.js server runtimes
generateServerClientUsingCookies() 
generateServerClientUsingReqRes() 
To generate a Data client for the Next.js server runtime using cookies, you need to provide both your Amplify configuration and the cookies function from Next.js.

import { type Schema } from '@/amplify/data/resource';
import { generateServerClientUsingCookies } from '@aws-amplify/adapter-nextjs/data';
import outputs from '@/amplify_outputs.json';
import { cookies } from 'next/headers';

export const cookieBasedClient = generateServerClientUsingCookies<Schema>({
  config: outputs,
  cookies,
});
We recommend you generate Amplify Data's server client in a utility file. Then, import the generated client in your Next.js React Server Components, Server Actions, or Route Handlers.

Step 3 - Call API using generated server Data clients
You can make any available query or mutation request with the generated server data clients; however, note that subscriptions are not available within server runtimes.

generateServerClientUsingCookies() 
generateServerClientUsingReqRes() 
Import the cookie-based server Data client in your Next.js React Server Component code and make your API requests.

import { type Schema } from '@/amplify/data/resource';
import { generateServerClientUsingCookies } from '@aws-amplify/adapter-nextjs/data';
import outputs from '@/amplify_outputs.json';
import { cookies } from 'next/headers';

export const cookieBasedClient = generateServerClientUsingCookies<Schema>({
  config: outputs,
  cookies,
});

const fetchTodos = async () => {
  const { data: todos, errors } = await cookieBasedClient.models.Todo.list();

  if (!errors) {
    return todos;
  }
}; 

- Nuxt.js server runtime - 
This guide walks through how you can connect to Amplify Data from Nuxt.js Server-side Runtime (SSR). For Nuxt.js applications, Amplify provides first-class support for Routing (Pages) , API Routes , and Middleware.

Before you begin, you will need:

A Nuxt.js application created
Deployed Amplify Data resources, or directly using AWS AppSync
Connect to Amplify Data from a Nuxt.js server runtime
Connecting to Amplify Data will include setting up the AmplifyAPIs Plugin with the runWithAmplifyServerContext adapter, using the useNuxtApp() composable, setting up the Amplify server context utility and then using the runAmplifyApi function to call the API in an isolated server context.

Step 1 - Set up the AmplifyAPIs Plugin
Nuxt 3 offers universal rendering by default, where your data fetching logic may be executed on both the client and server sides. Amplify offers APIs that are capable of running within a server context to support use cases such as server-side rendering (SSR) and static site generation (SSG), though Amplify's client-side APIs and server-side APIs of Amplify are slightly different. You can set up an AmplifyAPIs plugin to make your data fetching logic run smoothly across the client and server. To learn more about how to use Amplify categories APIs in server side rendering, refer to this documentation.

Create a plugins directory under the root of your Nuxt project.
Create two files 01.amplify-apis.client.ts and 01.amplify-apis.server.ts under the plugins directory.
In these files, you will register both client-specific and server-specific Amplify APIs that you will use in your Nuxt project as a plugin. You can then access these APIs via the useNuxtApp composable.

NOTE: The leading number in the files name indicate the plugin loading order, for more details see https://nuxt.com/docs/guide/directory-structure/plugins#registration-order. The .client and .server indicate the runtime that the logic contained in the file will run on, client or server. For details see: https://nuxt.com/docs/guide/directory-structure/plugins

Modify the 01.amplify-apis.client.ts file, with the following code:

Expand to view the code implementation
Next, modify the 01.amplify-apis.server.ts file, with the following code:

Expand to view the code implementation
Step 2 - Use the useNuxtApp() composable
Using the GraphQL API in ~/app.vue:

nuxt-amplify-gen2/app.vue
<script setup lang="ts">
import { Authenticator } from '@aws-amplify/ui-vue';
import '@aws-amplify/ui-vue/styles.css';
import { onMounted, ref } from 'vue';
import type { Schema } from '@/amplify/data/resource';

// create a reactive reference to the array of todos
const todos = ref<Schema['Todo']['type'][]>([]);

async function listTodos() {
 try {
    // `$Amplify` is generated by Nuxt according to the `provide` key in the plugins
    // fetch all todos
    const { data } = await useNuxtApp().$Amplify.GraphQL.client.models.Todo.list();
    todos.value = data;

  } catch (error) {
     console.error('Error fetching todos', error);
  }
}

// fetch todos when the component is mounted
onMounted(() => {
  listTodos();
});
</script>


<template>
  <Authenticator>
    <template v-slot="{ user, signOut }">
      <h1>Hello, Amplify </h1>
        <ul>
          <li v-for="todo in todos" :key="todo.id">{{ todo.content }}</li>
        </ul>
      <button @click="signOut">Sign Out</button>
    </template>
  </Authenticator>
</template>
The app.vue file can be rendered on both the client and server sides by default. The useNuxtApp().$Amplify composable will pick up the correct implementation of 01.amplify-apis.client.ts and 01.amplify-apis.server.ts to use, depending on the runtime.

Only a subset of Amplify APIs are usable on the server side, and as the libraries evolve, amplify-apis.client and amplify-apis.server may diverge further. You can guard your API calls to ensure an API is available in the context where you use it. E.g., you can use if (process.client) to ensure that a client-only API isn't executed on the server.

Step 3 - Set up Amplify for API Routes
Following the specification of Nuxt, your API route handlers will live under ~/server, which is a separate environment from other parts of your Nuxt app; hence, the plugins created in the previous step are not usable here, and extra work is required.

Setup Amplify Server Context Utility
Create a utils directory under the server directory of your Nuxt project.
Create an amplifyUtils.ts file under the utils directory.
In this file, you will create a helper function to call Amplify APIs that are capable of running on the server side with context isolation. Modify the amplifyUtils.ts file, with the following code:

Expand to view the code implementation
Now, you can use the runAmplifyApi function to call Amplify APIs in an isolated server context. Create a new API route /api/current-user in the server directory and modify the current-user.ts file, with the following code:

nuxt-amplify-gen2/server/api/current-user.ts
import { getCurrentUser } from "aws-amplify/auth/server";
import { runAmplifyApi } from "~/server/utils/amplifyUtils";

export default defineEventHandler(async (event) => {
  const user = await runAmplifyApi(event, (contextSpec) =>
    getCurrentUser(contextSpec)
  );

  return user;
});
You can then fetch data from this API route, for example: fetch('http://localhost:3000/api/current-user')

- Connect to AWS AppSync Events - 
This guide walks through how you can connect to AWS AppSync Events using the Amplify library.

AWS AppSync Events lets you create secure and performant serverless WebSocket APIs that can broadcast real-time event data to millions of subscribers, without you having to manage connections or resource scaling. With this feature, you can build multi-user features such as a collaborative document editors, chat apps, and live polling systems.

Learn more about AWS AppSync Events by visiting the Developer Guide.

Connect to an Event API without an existing Amplify backend
Before you begin, you will need:

An Event API created via the AWS Console
Take note of: HTTP endpoint, region, API Key
src/App.tsx
import type { EventsChannel } from 'aws-amplify/data';
import { useState, useEffect } from 'react';
import { Amplify } from 'aws-amplify';
import { events } from 'aws-amplify/data';

Amplify.configure({
  API: {
    Events: {
      endpoint:
        'https://abcdefghijklmnopqrstuvwxyz.appsync-api.us-east-1.amazonaws.com/event',
      region: 'us-east-1',
      defaultAuthMode: 'apiKey',
      apiKey: 'da2-abcdefghijklmnopqrstuvwxyz'
    }
  }
});

export default function App() {
  const [myEvents, setMyEvents] = useState<unknown[]>([]);

  useEffect(() => {
    let channel: EventsChannel;

    const connectAndSubscribe = async () => {
      channel = await events.connect('default/channel');

      channel.subscribe({
        next: (data) => {
          console.log('received', data);
          setMyEvents((prev) => [data, ...prev]);
        },
        error: (err) => console.error('error', err)
      });
    };

    connectAndSubscribe();

    return () => channel && channel.close();
  }, []);

  async function publishEvent() {
    // Publish via HTTP POST
    await events.post('default/channel', { some: 'data' });

    // Alternatively, publish events through the WebSocket channel
    const channel = await events.connect('default/channel');
    await channel.publish({ some: 'data' });
  }

  return (
    <>
      <button onClick={publishEvent}>Publish Event</button>
      <ul>
        {myEvents.map((data) => (
          <li key={data.id}>{JSON.stringify(data.event)}</li>
        ))}
      </ul>
    </>
  );
}
Add an Event API to an existing Amplify backend
This guide walks through how you can add an Event API to an existing Amplify backend. We'll be using Cognito User Pools for authenticating with Event API from our frontend application. Any signed in user will be able to subscribe to the Event API and publish events.

Before you begin, you will need:

An existing Amplify backend (see Quickstart)
Latest versions of @aws-amplify/backend and @aws-amplify/backend-cli (npm add @aws-amplify/backend@latest @aws-amplify/backend-cli@latest)
Update Backend Definition
First, we'll add a new Event API to our backend definition.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
// import CDK resources:
import {
  CfnApi,
  CfnChannelNamespace,
  AuthorizationType,
} from 'aws-cdk-lib/aws-appsync';
import { Policy, PolicyStatement } from 'aws-cdk-lib/aws-iam';

const backend = defineBackend({
	auth,
});

// create a new stack for our Event API resources:
const customResources = backend.createStack('custom-resources');

// add a new Event API to the stack:
const cfnEventAPI = new CfnApi(customResources, 'CfnEventAPI', {
  name: 'my-event-api',
  eventConfig: {
    authProviders: [
      {
        authType: AuthorizationType.USER_POOL,
        cognitoConfig: {
          awsRegion: customResources.region,
          // configure Event API to use the Cognito User Pool provisioned by Amplify:
          userPoolId: backend.auth.resources.userPool.userPoolId,
        },
      },
    ],
    // configure the User Pool as the auth provider for Connect, Publish, and Subscribe operations:
    connectionAuthModes: [{ authType: AuthorizationType.USER_POOL }],
    defaultPublishAuthModes: [{ authType: AuthorizationType.USER_POOL }],
    defaultSubscribeAuthModes: [{ authType: AuthorizationType.USER_POOL }],
  },
});

// create a default namespace for our Event API:
const namespace = new CfnChannelNamespace(
  customResources,
  'CfnEventAPINamespace',
  {
    apiId: cfnEventAPI.attrApiId,
    name: 'default',
  }
);

// attach a policy to the authenticated user role in our User Pool to grant access to the Event API:
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(
  new Policy(customResources, 'AppSyncEventPolicy', {
    statements: [
      new PolicyStatement({
        actions: [
          'appsync:EventConnect',
          'appsync:EventSubscribe',
          'appsync:EventPublish',
        ],
        resources: [`${cfnEventAPI.attrApiArn}/*`, `${cfnEventAPI.attrApiArn}`],
      }),
    ],
  })
);

// finally, add the Event API configuration to amplify_outputs:
backend.addOutput({
  custom: {
    events: {
      url: `https://${cfnEventAPI.getAtt('Dns.Http').toString()}/event`,
      aws_region: customResources.region,
      default_authorization_type: AuthorizationType.USER_POOL,
    },
  },
});
Deploy Backend
To test your changes, deploy your Amplify Sandbox.

Terminal
npx ampx sandbox
Connect your frontend application
After the sandbox deploys, connect your frontend application to the Event API. We'll be using the Amplify Authenticator component to sign in to our Cognito User Pool.

If you don't already have the Authenticator installed, you can install it by running npm add @aws-amplify/ui-react.

src/App.tsx
import { useEffect, useState } from 'react';
import { Amplify } from 'aws-amplify';
import { events, type EventsChannel } from 'aws-amplify/data';
import { Authenticator } from '@aws-amplify/ui-react';
import '@aws-amplify/ui-react/styles.css';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);

export default function App() {
  const [myEvents, setMyEvents] = useState<Record<string, any>[]>([]);

  useEffect(() => {
    let channel: EventsChannel;

    const connectAndSubscribe = async () => {
      channel = await events.connect('default/channel');

      channel.subscribe({
        next: (data) => {
          console.log('received', data);
          setMyEvents((prev) => [data, ...prev]);
        },
        error: (err) => console.error('error', err),
      });
    };

    connectAndSubscribe();

    return () => channel && channel.close();
  }, []);

  async function publishEvent() {
    // Publish via HTTP POST
    await events.post('default/channel', { some: 'data' });

    // Alternatively, publish events through the WebSocket channel
    const channel = await events.connect('default/channel');
    await channel.publish({ some: 'data' });
  }

  return (
    <Authenticator>
      {({ signOut, user }) => (
        <>
          <div>
            <h1>Welcome, {user.username}</h1>
            <button onClick={signOut}>Sign Out</button>
          </div>
          <div>
            <button onClick={publishEvent}>Publish Event</button>
            <ul>
            {myEvents.map((data) => (
              <li key={data.id}>{JSON.stringify(data.event)}</li>
              ))}
            </ul>
          </div>
        </>
      )}
    </Authenticator>
  );
}

- Modify Amplify-generated AWS resources - 
Amplify GraphQL API uses a variety of auto-generated, underlying AWS services and resources. You can customize these underlying resources to optimize the deployed stack for your specific use case.

In your Amplify app, you can access every underlying resource using CDK "L2" or "L1" constructs. Access the generated resources as L2 constructs via the .resources property on the returned stack or access the generated resources as L1 constructs using the .resources.cfnResources property.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';

const backend = defineBackend({
  data
});

const { cfnResources } = backend.data.resources;

for (const table of Object.values(cfnResources.amplifyDynamoDbTables)) {
  table.pointInTimeRecoveryEnabled = true;
}
Customize Amplify-generated AppSync GraphQL API resources
Apply all the customizations on backend.data.resources.graphqlApi or backend.data.resources.cfnResources.cfnGraphqlApi. For example, to enable X-Ray tracing for the AppSync GraphQL API:

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';

const backend = defineBackend({
  data
});

const { cfnResources } = backend.data.resources;

cfnResources.cfnGraphqlApi.xrayEnabled = true;
Customize Amplify-generated resources for data models
Pass in the model type name into backend.data.resources.amplifyDynamoDbTables["MODEL_NAME"] to modify the resources generated for that particular model type. For example, to enable time-to-live on the Todo @model type's DynamoDB table:

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';

const backend = defineBackend({
  data
});

const { cfnResources } = backend.data.resources;

cfnResources.amplifyDynamoDbTables["Todo"].timeToLiveAttribute = {
  attributeName: "ttl",
  enabled: true,
};
Example - Configure billing mode on a DynamoDB table
Set the DynamoDB billing mode for the DynamoDB table as either "PROVISIONED" or "PAY_PER_REQUEST".

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { BillingMode } from "aws-cdk-lib/aws-dynamodb";
import { data } from './data/resource';

const backend = defineBackend({
  data
});

const { cfnResources } = backend.data.resources;

cfnResources.amplifyDynamoDbTables['Todo'].billingMode = BillingMode.PAY_PER_REQUEST;
Example - Configure provisioned throughput for a DynamoDB table
Override the default ProvisionedThroughput provisioned for each model table and its Global Secondary Indexes (GSI). This override is only valid if the "DynamoDBBillingMode" is set to "PROVISIONED".

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';

const backend = defineBackend({
  data
});

const { cfnResources } = backend.data.resources;

cfnResources.amplifyDynamoDbTables["Todo"].provisionedThroughput = {
  readCapacityUnits: 5,
  writeCapacityUnits: 5,
};
Example - Enable point-in-time recovery for a DynamoDB table
Enable/disable DynamoDB point-in-time recovery for each model table.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { data } from './data/resource';

const backend = defineBackend({
  data
});

const { cfnResources } = backend.data.resources;

cfnResources.amplifyDynamoDbTables['Todo'].pointInTimeRecoveryEnabled = true;

- Manage Data with Amplify console - 
The Data manager page in the Amplify Console offers a user-friendly interface for managing the backend GraphQL API data of an application. It enables real-time creation and updates of application data, eliminating the need to build separate admin views.

If you have not yet created a data resource, visit the Data setup guide.

Access Data manager
After you've deployed your data resource, you can access the manager on Amplify console.

Log in to the Amplify console and choose your app.
Select the branch you would like to access.
Select Data from the left navigation bar.
Then, select Data manager.
To create a record
On the Data manager page, select a table from the Select table dropdown. For this example, we are using a Todo table.
Select Create Todo.
In the Add Todo pane, specify your custom values for the fields in the table. For example, enter my first todo for the Content field and toggle the Is done field.
Select Submit.
To update a record
On the Data manager page, select a table from the Select table dropdown.
From the list of records, select a record you want to update.
In the Edit Todo pane, make any changes to your record, and then select Submit.
To delete a record(s)
On the Data manager page, select a table from the Select table dropdown.
From the list of records, select the checkbox to the left of the record(s) you want to delete.
Select the Actions dropdown, and then select delete item(s) .
To Seed records
On the Data manager page, select a table from the Select table dropdown.
Select the Actions dropdown and then select Auto-generate data.
In the Auto-generate data pane, specify how many rows of data you want to generate and constraints for the generated data.
Then select Generate data
You can generate up to 100 records at a time.

Seed data cannot be generated for tables that have the following field types: AWSPhone, Enum, Custom Type, or Relationship

To download records
On the Data manager page, select a table from the Select table dropdown.
Select the Actions dropdown.
Here you have two options for downloading data.
Choose Download selected items (.csv) to download only the selected rows of data.
Choose Download all items (.csv) to download all rows of records on the currently selected table.
Once you have selected a download option, your data should immediately start downloading as a CSV file.

- Enable logging -
You can enable logging to debug your GraphQL API using Amazon CloudWatch logs. To learn more about logging and monitoring capabilities for your GraphQL API, visit the AWS AppSync documentation for logging and monitoring.

Enable default logging configuration
Default logging can be enabled by setting the logging property to true in the call to defineData. For example:

amplify/data/resource.ts
export const data = defineData({
  // ...
  logging: true
});
Using logging: true applies the default configuration:

excludeVerboseContent: true (see AppSync's Request-level logs)
fieldLogLevel: 'none' (see AppSync's Field-level logs)
retention: '1 week' (see Enum RetentionDays)
Customize logging configuration
You can customize individual configuration values by providing a DataLogConfig object. For example:

amplify/data/resource.ts
export const data = defineData({
  // ...
  logging: {
    excludeVerboseContent: false,
    fieldLogLevel: 'all',
    retention: '1 month'
  }
});
WARNING: Setting excludeVerboseContent to false logs full queries and user parameters, which can contain sensitive data. We recommend limiting CloudWatch log access to only those roles or users (e.g., DevOps or developers) who genuinely require it, by carefully scoping your IAM policies.

Configuration Properties
logging
true: Enables default logging.
DataLogConfig object: Overrides one or more default fields.
DataLogConfig Fields
excludeVerboseContent?: boolean

Defaults to true
When false, logs can contain request-level logs. See AppSync's Request-Level Logs.
fieldLogLevel?: DataLogLevel

Defaults to 'none'
Supported values of AppSync's Field Log Levels:
'none'
'error'
'info'
'debug'
'all'
retention?: LogRetention

Number of days to keep the logs
Defaults to '1 week'
Supported values of Enum RetentionDays:
'1 day'
'3 days'
'5 days'
'1 week'
'2 weeks'
'1 month'
'2 months'
'3 months'
'4 months'
'5 months'
'6 months'
'1 year'
'13 months'
'18 months'
'2 years'
'5 years'
'10 years'
'infinite'

- Field-level validation - 
You can enable field-level validation in your model schema by chaining a validate function to the field.

Examples
amplify/data/resource.ts
const schema = a.schema({
  Todo: a.model({
    content: a.string().validate(v => 
      v
        .minLength(1, 'Content must be at least 1 character long')
        .maxLength(100, 'Content must be less than 100 characters')
        .matches('^[a-zA-Z0-9\\\\s]+$', 'Content must contain only letters, numbers, and spaces')
    )
  })
  .authorization(allow => [allow.publicApiKey()])
});
Supported validators
String Validators
For string fields:

Validator	Description	Parameters	Example
minLength	Validates that a string field has at least the specified length	 length: The minimum length required
 errorMessage: Optional custom error message	a.string().validate(v => v.minLength(5, 'String must be at least 5 characters'))
maxLength	Validates that a string field does not exceed the specified length	 length: The maximum length allowed
 errorMessage: Optional custom error message	a.string().validate(v => v.maxLength(100, 'String must be at most 100 characters'))
startsWith	Validates that a string field starts with the specified prefix	 prefix: The prefix the string must start with
 errorMessage: Optional custom error message	a.string().validate(v => v.startsWith("prefix-", 'String must start with prefix-'))
endsWith	Validates that a string field ends with the specified suffix	 suffix: The suffix the string must end with
 errorMessage: Optional custom error message	a.string().validate(v => v.endsWith("-suffix", 'String must end with -suffix'))
matches	Validates that a string field matches the specified regex pattern using the Java regex engine. See notes below.	 pattern: The regex pattern the string must match
 errorMessage: Optional custom error message	a.string().validate(v => v.matches("^[a-zA-Z0-9]+$", 'String must match the pattern'))
Note: Our schema transformer uses the Java regex engine under the hood. Because of how TypeScript processes string literals, you must quadruple-escape special regex characters in your schema. In a TypeScript string literal, writing \\\\s produces the string \\s, which is the correct form for the Java regex engine. If you write \\s, it produces \s, which is invalid. Therefore, for the matches validator, ensure you use quadruple-escaping. For example: a.string().validate(v => v.matches("^[a-zA-Z0-9\\\\s]+$", 'Content must contain only letters, numbers, and spaces'))

Numeric Validators
For integer and float fields:

Validator	Description	Parameters	Example
gt	Validates that a numeric field is greater than the specified value	 value: The value the field must be greater than
 errorMessage: Optional custom error message	a.integer().validate(v => v.gt(10, 'Must be greater than 10'))
gte	Validates that a numeric field is greater than or equal to the specified value	 value: The value the field must be greater than or equal to
 errorMessage: Optional custom error message	a.integer().validate(v => v.gte(10, 'Must be at least 10'))
lt	Validates that a numeric field is less than the specified value	 value: The value the field must be less than
 errorMessage: Optional custom error message	a.integer().validate(v => v.lt(10, 'Must be less than 10'))
lte	Validates that a numeric field is less than or equal to the specified value	 value: The value the field must be less than or equal to
 errorMessage: Optional custom error message	a.integer().validate(v => v.lte(10, 'Must be at most 10'))
positive	Validates that a numeric field is positive	 errorMessage: Optional custom error message	a.integer().validate(v => v.positive('Must be positive'))
negative	Validates that a numeric field is negative	 errorMessage: Optional custom error message	a.integer().validate(v => v.negative('Must be negative'))
Note: Currently, we only support validation on non-array fields of type string, integer, and float.

- Set up Storage - 
In this guide, you will learn how to set up storage in your Amplify app. You will set up your backend resources, and enable listing, uploading, and downloading files.

If you have not yet created an Amplify app, visit the quickstart guide.

Amplify Storage seamlessly integrates file storage and management capabilities into frontend web and mobile apps, built on top of Amazon Simple Storage Service (Amazon S3). It provides intuitive APIs and UI components for core file operations, enabling developers to build scalable and secure file storage solutions without dealing with cloud service complexities.

Building your storage backend
First, create a file amplify/storage/resource.ts. This file will be the location where you configure your storage backend. Instantiate storage using the defineStorage function and providing a name for your storage bucket. This name is a friendly name to identify your bucket in your backend configuration. Amplify will generate a unique identifier for your app using a UUID, the name attribute is just for use in your app.

amplify/storage/resource.ts
import { defineStorage } from '@aws-amplify/backend';

export const storage = defineStorage({
  name: 'amplifyTeamDrive'
});
Import your storage definition in your amplify/backend.ts file that contains your backend definition. Add storage to defineBackend.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { storage } from './storage/resource';

defineBackend({
  auth,
  storage
});
Now when you run npx ampx sandbox or deploy your app on Amplify, it will configure an Amazon S3 bucket where your files will be stored. Before files can be accessed in your application, you must configure storage access rules.

To deploy these changes, commit them to git and push the changes upstream. Amplify's CI/CD system will automatically pick up the changes and build and deploy the updates.

Terminal
git commit -am "add storage backend"
git push
Define File Path Access
By default, no users or other project resources have access to any files in the storage bucket. Access must be explicitly granted within defineStorage using the access callback.

The access callback returns an object where each key in the object is a file path and each value in the object is an array of access rules that apply to that path.

The following example shows you how you can set up your file storage structure for a generic photo sharing app. Here,

Guests have access to see all profile pictures and only the users that uploaded the profile picture can replace or delete them. Users are identified by their Identity Pool ID in this case i.e. identityID.
There's also a general pool where all users can submit pictures.
Learn more about customizing access to file path.

amplify/storage/resource.ts
export const storage = defineStorage({
  name: 'amplifyTeamDrive',
  access: (allow) => ({
    'profile-pictures/{entity_id}/*': [
      allow.guest.to(['read']),
      allow.entity('identity').to(['read', 'write', 'delete'])
    ],
    'picture-submissions/*': [
      allow.authenticated.to(['read','write']),
      allow.guest.to(['read', 'write'])
    ],
  })
});
Configure additional storage buckets
Amplify Storage gives you the flexibility to configure your backend to automatically provision and manage multiple storage resources.

You can define additional storage buckets by using the same defineStorage function and providing a unique, descriptive name to identify the storage bucket. You can pass this name to the storage APIs to specify the bucket you want to perform the action to. Ensure that this name attribute is unique across the defined storage buckets in order to reliably identify the correct bucket and prevent conflicts.

It's important to note that if additional storage buckets are defined one of them must be marked as default with the isDefault flag.

amplify/storage/resource.ts
export const firstBucket = defineStorage({
  name: 'firstBucket',
  isDefault: true, // identify your default storage bucket (required)
});

export const secondBucket = defineStorage({
  name: 'secondBucket',
  access: (allow) => ({
    'private/{entity_id}/*': [
      allow.entity('identity').to(['read', 'write', 'delete'])
    ]
  })
})
Add additional storage resources to the backend definition.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { firstBucket, secondBucket } from './storage/resource';

defineBackend({
  auth,
  firstBucket,
  secondBucket
});
Storage bucket client usage
Additional storage buckets can be referenced from application code by passing the bucket option to Amplify Storage APIs. You can provide a target bucket's name assigned in Amplify Backend.

import { downloadData } from 'aws-amplify/storage';

try {
  const result = downloadData({
    path: "album/2024/1.jpg",
    options: {
      // Specify a target bucket using name assigned in Amplify Backend
      bucket: "secondBucket"
    }
  }).result;
} catch (error) {
  console.log(`Error: ${error}`)
}
Alternatively, you can also pass in an object by specifying the bucket name and region from the console. See each Amplify Storage API page for additional usage examples.

import { downloadData } from 'aws-amplify/storage';

try {
  const result = downloadData({
    path: 'album/2024/1.jpg',
    options: {
      // Alternatively, provide bucket name from console and associated region
      bucket: {
        bucketName: 'second-bucket-name-from-console',
        region: 'us-east-2'
      }
    }
  }).result;
} catch (error) {
  console.log(`Error: ${error}`);
}
Connect your app code to the storage backend
The Amplify Storage library provides client APIs that connect to the backend resources you defined.

Configure Amplify in project
Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example index.js in React or main.ts in Angular.

import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
Make sure you call Amplify.configure as early as possible in your applications life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.

Upload your first file
Next, let's a photo to the picture-submissions/ path.

import React from 'react';
import { uploadData } from 'aws-amplify/storage';

function App() {
  const [file, setFile] = React.useState();

  const handleChange = (event) => {
    setFile(event.target.files?.[0]);
  };

  const handleClick = () => {
    if (!file) {
      return;
    }
    uploadData({
      path: `picture-submissions/${file.name}`,
      data: file,
    });
  };

  return (
    <div>
      <input type="file" onChange={handleChange} />
      <button onClick={handleClick}>Upload</button>
    </div>
  );
}
Manage files in Amplify console
After successfully publishing your storage backend and connecting your project with client APIs, you can manage files and folders in the Amplify console. You can perform on-demand actions like upload, download, copy, and more under the Storage tab in the console. Refer to Manage files in Amplify Console guide for additional information.

Conclusion
Congratulations! You finished the Set up Amplify Storage guide. In this guide, you set up and connected to backend resources, customized your file paths and access definitions, and connected your application to the backend to implement features like file uploads and downloads.

Next steps
Now that you have completed setting up storage in your Amplify app, you can proceed to add file management features to your app. You can use the following guides to implement upload and download functionality, or you can access more capabilities from the side navigation.

- Customize authorization rules - 
Customize authorization for your storage bucket by defining access to file paths for guests, authenticated users, and user groups. Access can also be defined for functions that require access to the storage bucket.

Refer to the following examples to understand how you can further customize authorization against different user types.

Access Types
Authentication is required to continue using Amplify Storage, please make sure you set it up if you haven't already - documentation to set up Auth.

Note: Paths in access definitions cannot have a '/' at the beginning of the string.

By default, all paths are denied to all types of users unless explicitly granted within defineStorage using the access callback as shown below.

Guest Users
Authenticated Users
User Groups
Owners
Functions
To grant all guest (i.e. not signed in) users of your application read access to files under media/, use the following access values.

amplify/storage/resource.ts
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [
      allow.guest.to(['read']) // additional actions such as "write" and "delete" can be specified depending on your use case
    ]
  })
});
Access definition rules
There are some rules for the types of paths that can be specified at the same time in the storage access definition.

All paths must end with /*.
Only one level of nesting is allowed. For example, you can define access controls on media/* and media/albums/* but not on media/albums/photos/* because there are two other definitions along the same path.
Wildcards cannot conflict with the {entity_id} token. For example, you cannot have both media/* and media/{entity_id}/* defined because the wildcard in the first path conflicts with the {entity_id} token in the second path.
A path cannot be a prefix of another path with an {entity_id} token. For example media/* and media/albums/{entity_id}/* is not allowed.
When one path is a subpath of another, the permissions on the subpath always override the permissions from the parent path. Permissions are not "inherited" from a parent path. Consider the following access definition example:

export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'media/*': [allow.authenticated.to(['read', 'write', 'delete'])],
    'media/profile-pictures/*': [allow.guest.to(['read'])],
    'media/albums/*': [allow.authenticated.to(['read'])],
    'other/*': [
      allow.guest.to(['read']),
      allow.authenticated.to(['read', 'write'])
    ]
  })
});
The access control matrix for this configuration is

Path	media/*	media/profile-pictures/*	media/albums/*	other/*
Authenticated Users	read, write, delete	NONE	read	read, write
Guest users	NONE	read	NONE	read
Authenticated users have access to read, write, and delete everything under media/* EXCEPT media/profile-pictures/* and media/albums/*. For those subpaths, the scoped down access overrides the access granted on the parent media/*

Available actions
When you configure access to a particular path, you can scope the access to one or more CRUDL actions.

Access	Corresponding Library APIs
read	getUrl, downloadData, list, and getProperties
get	getUrl and downloadData
list	list, and getProperties
write	uploadData, copy
delete	remove
Note: read is a combination of get and list access definitions and hence cannot be defined in the presence of get or list.

For Gen 1 public, protected, and private access pattern
To configure defineStorage in Amplify Gen 2 to behave the same way as the storage category in Gen 1, the following definition can be used.

amplify/storage/resource.ts
export const storage = defineStorage({
  name: 'myProjectFiles',
  access: (allow) => ({
    'public/*': [
      allow.guest.to(['read']),
      allow.authenticated.to(['read', 'write', 'delete']),
    ],
    'protected/{entity_id}/*': [
      allow.authenticated.to(['read']),
      allow.entity('identity').to(['read', 'write', 'delete'])
    ],
    'private/{entity_id}/*': [
      allow.entity('identity').to(['read', 'write', 'delete'])
    ]
  })
});

- Upload files -
Implement upload functionality
Note: Refer to the Transfer Acceleration documentation to learn how to enable transfer acceleration for storage APIs.

Upload from file
The following is an example of how you would upload a file from a file object, this could be retrieved from the local machine or a different source.

import React from 'react';
import { uploadData } from 'aws-amplify/storage';

function App() {
  const [file, setFile] = React.useState();

  const handleChange = (event) => {
    setFile(event.target.files?.[0]);
  };

  const handleClick = () => {
    if (!file) {
      return;
    }
    uploadData({
      path: `photos/${file.name}`,
      data: file,
    });
  };

  return (
    <div>
      <input type="file" onChange={handleChange} />
      <button onClick={handleClick}>Upload</button>
    </div>
  );
}
Upload from data
You can follow this example if you have data saved in memory and would like to upload this data to the cloud.

import { uploadData } from 'aws-amplify/storage';

try {
  const result = await uploadData({
    path: "album/2024/1.jpg",
    // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`
    data: file,
  }).result;
  console.log('Succeeded: ', result);
} catch (error) {
  console.log('Error : ', error);
}
Upload to a specified bucket
You can also perform an upload operation to a specific bucket by providing the bucket option. You can pass in a string representing the target bucket's assigned name in Amplify Backend.

import { uploadData } from 'aws-amplify/storage';

const result = await uploadData({
  path: 'album/2024/1.jpg',
  data: file,
  options: {
    // Specify a target bucket using name assigned in Amplify Backend
    bucket: 'assignedNameInAmplifyBackend'
  }
}).result;
Alternatively, you can also pass in an object by specifying the bucket name and region from the console.

import { uploadData } from 'aws-amplify/storage';

const result = await uploadData({
  path: 'album/2024/1.jpg',
  data: file,
  options: {
    // Alternatively, provide bucket name from console and associated region
    bucket: {
      bucketName: 'bucket-name-from-console',
      region: 'us-east-2'
    }
  }
}).result;
Monitor upload progress
Monitor progress of upload by using the onProgress option.

import { uploadData } from 'aws-amplify/storage';

const monitorUpload = async () => {
  try {
    const result = await uploadData({
      path: "album/2024/1.jpg",
      // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`
      data: file,
      options: {
        onProgress: ({ transferredBytes, totalBytes }) => {
          if (totalBytes) {
            console.log(
              `Upload progress ${Math.round(
                (transferredBytes / totalBytes) * 100
              )} %`
            );
          }
        },
      },
    }).result;
    console.log("Path from Response: ", result.path);
  } catch (error) {
    console.log("Error : ", error);
  }
}
Pause, resume, and cancel uploads
We have callback functions that support resuming, pausing, and cancelling uploadData requests.

import { uploadData, isCancelError } from 'aws-amplify/storage';

// Pause, resume, and cancel a task
const uploadTask = uploadData({ path, data: file });
//...
uploadTask.pause();
//...
uploadTask.resume();
//...
uploadTask.cancel();
//...
try {
  await uploadTask.result;
} catch (error) {
  if (isCancelError(error)) {
    // Handle error thrown by task cancellation
  }
}
Transfer with Object Metadata
Custom metadata can be associated with your uploaded object by passing the metadata option.

import { uploadData } from 'aws-amplify/storage';

const result = await uploadData({
  path: 'album/2024/1.jpg',
  data: file,
  options: {
    metadata: {
      customKey: 'customValue',
    },
  },
});
More upload options
The behavior of uploadData and properties of the uploaded object can be customized by passing in additional options.

import { uploadData } from 'aws-amplify/storage';

const result = await uploadData({
  path: 'album/2024/1.jpg',
  data: file,
  options: {
    // content-type header to be used when downloading
    contentType: "image/jpeg",
    // configure how object is presented
    contentDisposition: "attachment",
    // whether to use accelerate endpoint
    useAccelerateEndpoint: true,
    // the account ID that owns requested bucket
    expectedBucketOwner: "123456789012",
    // whether to check if an object with the same key already exists before completing the upload
    preventOverwrite: true,
    // whether to compute the checksum for the data to be uploaded, so the S3 can verify the data integrity
    checksumAlgorithm: "crc-32", // only 'crc-32' is supported currently
  },
});
Option	Type	Default	Description
bucket	string |
{ bucketName: string;
region: string; }	Default bucket and region from Amplify configuration	A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Read more at Configure additional storage buckets
contentType	string	application/octet-stream	The default content-type header value of the file when downloading it.

Read more at Content-Type documentation
contentEncoding	string		The default content-encoding header value of the file when downloading it.

Read more at Content-Encoding documentation
contentDisposition	string		Specifies presentational information for the object.

Read more at Content-Disposition documentation
metadata	map<string>		A map of metadata to store with the object in S3.

Read more at S3 metadata documentation
useAccelerateEndpoint	boolean	false	Whether to use accelerate endpoint.

Read more at Transfer Acceleration
expectedBucketOwner	string	-	The account ID that owns requested bucket.
preventOverwrite	boolean	false	Whether to check if an object with the same key already exists before completing the upload. If exists, a Precondition Failed error will be thrown
checksumAlgorithm	"crc-32"	-	Whether to compute the checksum for the data to be uploaded, so the S3 can verify the data integrity. Only 'crc-32' is supported currently
Uploads that were initiated over one hour ago will be cancelled automatically. There are instances (e.g. device went offline, user logs out) where the incomplete file remains in your Amazon S3 account. It is recommended to setup a S3 lifecycle rule to automatically cleanup incomplete upload requests.

MultiPart upload
Amplify will automatically perform an Amazon S3 multipart upload for objects that are larger than 5MB. For more information about S3's multipart upload, see Uploading and copying objects using multipart upload

- Download files - 
To further customize your in-app experience, you can use the getUrl or downloadData API from the Amplify Library for Storage.

Note: Refer to the Transfer Acceleration documentation to learn how to enable transfer acceleration for storage APIs.

Get or download file from a URL
With the getUrl API, you can get a presigned URL which is valid for 900 seconds or 15 minutes by default. You can use this URL to create a download link for users to click on. The expiresAt property is a Date object that represents the time at which the URL will expire.

import { getUrl } from 'aws-amplify/storage';

const linkToStorageFile = await getUrl({
  path: "album/2024/1.jpg",
  // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`
});
console.log('signed URL: ', linkToStorageFile.url);
console.log('URL expires at: ', linkToStorageFile.expiresAt);
Inside your template or JSX code, you can use the url property to create a link to the file:

<a href={linkToStorageFile.url.toString()} target="_blank" rel="noreferrer">
  {fileName} 
</a>
This function does not check if the file exists by default. As result, the signed URL may fail if the file to be downloaded does not exist.

More getUrl options
The behavior of the getUrl API can be customized by passing in options.

import { getUrl } from 'aws-amplify/storage';

const linkToStorageFile = await getUrl({
  path: "album/2024/1.jpg",
  options: {
    // specify a target bucket using name assigned in Amplify Backend
    bucket: 'assignedNameInAmplifyBackend',
    // ensure object exists before getting url
    validateObjectExistence: true, 
    // url expiration time in seconds.
    expiresIn: 300,
    // whether to use accelerate endpoint
    useAccelerateEndpoint: true,
    // The account ID that owns the requested bucket.
    expectedBucketOwner: '123456789012',
  }
});
Option	Type	Default	Description
bucket	string |
{ bucketName: string;
region: string; }	Default bucket and region from Amplify configuration	A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Read more at Configure additional storage buckets
validateObjectExistence	boolean	false	Whether to head object to make sure the object existence before downloading.
expiresIn	number	900	Number of seconds till the URL expires.

The expiration time of the presigned url is dependent on the session and will max out at 1 hour.
useAccelerateEndpoint	boolean	false	Whether to use accelerate endpoint.

Read more at Transfer Acceleration
expectedBucketOwner	string	Optional	The account ID that owns requested bucket.
Download to a file
Use the downloadData API to download the file locally.

import { downloadData } from 'aws-amplify/storage';

// Downloads file content to memory
const { body, eTag } = await downloadData({
  path: "album/2024/1.jpg"
}).result;
Get the text value of downloaded File
You can get the value of file in any of the three formats: blob, json, or text. You can call the respective method on the body property to consume the set data in the respective format.

import { downloadData } from 'aws-amplify/storage';

try {
  const downloadResult = await downloadData({
    path: "album/2024/1.jpg"
  }).result;
  const text = await downloadResult.body.text();
  // Alternatively, you can use `downloadResult.body.blob()`
  // or `downloadResult.body.json()` get read body in Blob or JSON format.
  console.log('Succeed: ', text);
} catch (error) {
  console.log('Error : ', error);
}
Download from a specified bucket
You can also perform an upload operation to a specific bucket by providing the bucket option. You can pass in a string representing the target bucket's assigned name in Amplify Backend.

import { downloadData } from 'aws-amplify/storage';

const result = await downloadData({
  path: 'album/2024/1.jpg',
  options: {
    // Specify a target bucket using name assigned in Amplify Backend
    bucket: 'assignedNameInAmplifyBackend'
  }
}).result;
Alternatively, you can also pass in an object by specifying the bucket name and region from the console.

import { downloadData } from 'aws-amplify/storage';

const result = await downloadData({
  path: 'album/2024/1.jpg',
  options: {
    // Alternatively, provide bucket name from console and associated region
    bucket: {
      bucketName: 'bucket-name-from-console',
      region: 'us-east-2'
    }
  }
}).result;
Monitor download progress
import { downloadData } from 'aws-amplify/storage';

// Download a file from S3 bucket
const { body, eTag } = await downloadData(
  {
    path: 'album/2024/1.jpg',
    options: {
      onProgress: (progress) {
        console.log(`Download progress: ${(progress.transferredBytes/progress.totalBytes) * 100}%`);
      }
    }
  }
).result;
Cancel download
import { downloadData, isCancelError } from 'aws-amplify/storage';

const downloadTask = downloadData({ path: 'album/2024/1.jpg' });
downloadTask.cancel();
try {
  await downloadTask.result;
} catch (error) {
  if (isCancelError(error)) {
    // Handle error thrown by task cancellation.
  }
}
More download options
The behavior of the downloadData API can be customized by passing in options.

import { downloadData } from 'aws-amplify/storage';

// Downloads file content to memory
const { body, eTag } = await downloadData({
  path: "album/2024/1.jpg",
  options: {
    // optional bytes range parameter to download a part of the file, the 2nd MB of the file in this example
    bytesRange: {
      start: 1024,
      end: 2048
    },
    useAccelerateEndpoint: true,
  }
}).result;
Option	Type	Default	Description
bucket	string |
{ bucketName: string;
region: string; }	Default bucket and region from Amplify configuration	A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Read more at Configure additional storage buckets
onProgress	callback		Callback function tracking the upload/download progress.
bytesRange	{ start: number; end:number; }		Bytes range parameter to download a part of the file.
useAccelerateEndpoint	boolean	false	Whether to use accelerate endpoint.

Read more at Transfer Acceleration
expectedBucketOwner	string	Optional	The account ID that owns requested bucket.
Frequently Asked Questions
Image compression or CloudFront CDN caching for your S3 buckets is not yet possible.
downloadData does not provide a cache control option and it replies on runtime HTTP caching behavior. If you need to bypass the cache, you can use the getUrl API to create a presigned URL for downloading the file.
downloadData does not support S3 object versioning, it always downloads the latest version.

- List file properties - 
You can list files without having to download all the files. You can do this by using the list API from the Amplify Library for Storage. You can also get properties individually for a file using the getProperties API.

List Files
import { list } from 'aws-amplify/storage';

const result = await list({
	path: 'album/photos/',
  // Alternatively, path: ({identityId}) => `album/${identityId}/photos/`
});
Note the trailing slash / - if you had requested list({ path : 'album/photos' }) it would also match against files like album/photos123.jpg alongside album/photos/123.jpg.

The format of the response will look similar to the below example:

{
  items: [
    {
      path: "album/photos/123.jpg",
      eTag: "30074401292215403a42b0739f3b5262",
      lastModified: "Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)",
      size: 138256
    },
    // ...
  ],
}
If the pageSize is set lower than the total file size, a single list call only returns a subset of all the files. To list all the files with multiple calls, users can use the nextToken flag:

import { list } from 'aws-amplify/storage';

const PAGE_SIZE = 20;
let nextToken;
// ...
const loadNextPage = async () => {
  const response = await list({
    path: 'photos/',
    // Alternatively, path: ({ identityId }) => `album/${identityId}/photos/`
    options: {
      pageSize: PAGE_SIZE,
      nextToken,
    },
  });
  if (response.nextToken) {
    nextToken = response.nextToken;
  } else {
    nextToken = undefined;
  }
  // render list items from response.items
};
List All files
import { list } from 'aws-amplify/storage';

const result = await list({
	path: 'album/photos/',
  // Alternatively, path: ({identityId}) => `album/${identityId}/photos/`,
  options: {
    listAll: true,
  }
});
Manually created folders will show up as files with a size of 0, but you can also match keys against a regex like file.key.match(/\.[0-9a-z]+$/i) to distinguish files from folders. Since "folders" are a virtual concept in Amazon S3, any file may declare any depth of folder just by having a / in its name.

To access the contents and subpaths of a "folder", you have two options:

Request the entire path and parse the contents.
Use the subpathStrategy option to retrieve only the files within the specified path (i.e. exclude files under subpaths).
Get all nested files within a path
This retrieves all files and folders under a given path. You may need to parse the result to get only the files within the specified path.

function processStorageList(response) {
  let files = [];
  let folders = new Set();
  response.items.forEach((res) => {
    if (res.size) {
      files.push(res);
      // sometimes files declare a folder with a / within then
      let possibleFolder = res.path.split('/').slice(0, -1).join('/');
      if (possibleFolder) folders.add(possibleFolder);
    } else {
      folders.add(res.path);
    }
  });
  return { files, folders };
}
If you need the files and folders in terms of a nested object instead (for example, to build an explorer UI), you could parse it recursively:

function processStorageList(response) {
  const filesystem = {};
  // https://stackoverflow.com/questions/44759750/how-can-i-create-a-nested-object-representation-of-a-folder-structure
  const add = (source, target, item) => {
    const elements = source.split('/');
    const element = elements.shift();
    if (!element) return; // blank
    target[element] = target[element] || { __data: item }; // element;
    if (elements.length) {
      target[element] =
        typeof target[element] === 'object' ? target[element] : {};
      add(elements.join('/'), target[element], item);
    }
  };
  response.items.forEach((item) => add(item.path, filesystem, item));
  return filesystem;
}
This places each item's data inside a special __data key.

Excluding subpaths
In addition to using the list API to get all the contents of a path, you can also use it to get only the files within a path while excluding files under subpaths.

For example, given the following keys in your path you may want to return only the jpg object, and not the "vacation" subpath and its contents:

photos/photo1.jpg
photos/vacation/
This can be accomplished with the subpathStrategy option:

src/main.ts
import { list } from "aws-amplify/storage";
const result = await list({ 
  path: "photos/",
  options:{
    subpathStrategy: { strategy:'exclude' }
  }
});
The response will include only the objects within the photos/ path and will also communicate any excluded subpaths:

{
    excludedSubpaths: [
      'photos/vacation/'
    ],
    items: [
      {
        path: "photos/photo1.jpg",
        eTag: "30074401292215403a42b0739f3b5262",
        lastModified: "Thu Oct 08 2020 23:59:31 GMT+0800 (Singapore Standard Time)",
        size: 138256
      },
    ]
}
The default delimiter character is '/', but this can be changed by supplying a custom delimiter:

src/main.ts
const result = await list({
  // Path uses '-' character to organize files rather than '/'
  path: 'photos-',
  options: {
    subpathStrategy: {
      strategy: 'exclude',
      delimiter: '-'
    }
  }
});
List files from a specified bucket
You can also perform an copy operation to a specific bucket by providing the bucket option. This option can either be a string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

import { list } from 'aws-amplify/storage';

const result = await list({
  path: 'photos/',
  options: {
    // Specify a target bucket using name assigned in Amplify Backend
    bucket: 'assignedNameInAmplifyBackend',
    // Alternatively, provide bucket name from console and associated region
    // bucket: {
    //   bucketName: 'generated-secondary-bucket-name',
    //   region: 'us-east-2'
    // }
  }
});
More list options
Option	Type	Default	Description
bucket	string |
{ bucketName: string;
region: string; }	Default bucket and region from Amplify configuration	A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Read more at Configure additional storage buckets
listAll	boolean	false	Set to true to list all files within the specified path
pageSize	number	1000	Sets the maximum number of files to be return. The range is 0 - 1000
nextToken	string		Indicates whether the list is being continued on this bucket with a token
subpathStrategy	{ strategy: 'include' } |
{ 'exclude',
delimiter?: string }	{ strategy: 'include' }	An object representing the subpath inclusion strategy and the delimiter used to group results for exclusion.

Read more at Excluding subpaths
useAccelerateEndpoint	boolean	false	Whether to use accelerate endpoint.

Read more at Transfer Acceleration
expectedBucketOwner	string	Optional	The account ID that owns requested bucket.
Get File Properties
You can also view the properties of an individual file.

import { getProperties } from 'aws-amplify/storage';

try {
  const result = await getProperties({
    path: 'album/2024/1.jpg',
    // Alternatively, path: ({ identityId }) => `album/${identityId}/1.jpg`
    options: {
      // Specify a target bucket using name assigned in Amplify Backend
      bucket: 'assignedNameInAmplifyBackend'
    }
  });
  console.log('File Properties ', result);
} catch (error) {
  console.log('Error ', error);
}
The properties and metadata will look similar to the below example

{
  path: "album/2024/1.jpg",
  contentType: "image/jpeg",
  contentLength: 6873,
  eTag: "\"56b32cf4779ff6ca3ba3f2d455fa56a7\"",
  lastModified: Wed Apr 19 2023 14:20:55 GMT-0700 (Pacific Daylight Time) {},
  metadata: { owner: 'aws' }
}
More getProperties options
Option	Type	Default	Description
bucket	string |
{ bucketName: string;
region: string; }	Default bucket and region from Amplify configuration	A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Read more at Configure additional storage buckets
useAccelerateEndpoint	boolean	false	Whether to use accelerate endpoint.
To get the metadata in result for all APIs you have to configure user defined metadata in CORS.

Learn more about how to setup an appropriate CORS Policy.

- Remove files - 
Files can be removed from a storage bucket using the remove API. If a file is protected by an identity Id, only the user who owns the file will be able to remove it.

You can also perform a remove operation from a specific bucket by providing the target bucket's assigned name from Amplify Backend in bucket option.

import { remove } from 'aws-amplify/storage';

try {
  await remove({ 
    path: 'album/2024/1.jpg',
    // Alternatively, path: ({identityId}) => `album/${identityId}/1.jpg`
    bucket: 'assignedNameInAmplifyBackend', // Specify a target bucket using name assigned in Amplify Backend
  });
} catch (error) {
  console.log('Error ', error);
}
Alternatively, you can also pass in an object by specifying the bucket name and region from the console.

import { remove } from 'aws-amplify/storage';

try {
  await remove({ 
    path: 'album/2024/1.jpg',
    // Alternatively, provide bucket name from console and associated region
    bucket: {
      bucketName: 'bucket-name-from-console',
      region: 'us-east-2'
    }

  });
} catch (error) {
  console.log('Error ', error);
}
More remove options
Option	Type	Default	Description
bucket	string |
{ bucketName: string;
region: string; }	Default bucket and region from Amplify configuration	A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Read more at Configure additional storage buckets
expectedBucketOwner	string	Optional	The account ID that owns requested bucket. 

- Copy files - 
Note: You can only copy files up to 5GB in a single operation

You can copy an existing file to a different path within the storage bucket using the copy API.

The copy method duplicates an existing file to a designated path and returns an object {path: 'destPath'} upon successful completion.

import { copy } from 'aws-amplify/storage';

const copyFile = async () => {
  try {
    const response = await copy({
      source: {
        path: `album/2024/${encodeURIComponent('#1.jpg')}`,
        // Alternatively, path: ({identityId}) => `album/${identityId}/${encodeURIComponent('#1.jpg')`
      },
      destination: {
        path: 'shared/2024/#1.jpg',
        // Alternatively, path: ({identityId}) => `shared/${identityId}/#1.jpg`
      },
    });
  } catch (error) {
    console.error('Error', err);
  }
};
The operation can fail if there's a special character in the source path. You should URI encode the source path with special character. You don't need to encode the destination path.

Cross identity ID copying is only allowed if the destination path has the the right access rules to allow other authenticated users writing to it.

Specify a bucket or copy across buckets / regions
You can also perform an copy operation to a specific bucket by providing the bucket option. This option can either be a string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

import { copy } from 'aws-amplify/storage';

const copyFile = async () => {
  try {
    const response = await copy({
      source: {
        path: 'album/2024/1.jpg',
        // Specify a target bucket using name assigned in Amplify Backend
        // or bucket name from console and associated region
        bucket: 'assignedNameInAmplifyBackend',
        expectedBucketOwner: '123456789012'
      },
      destination: {
        path: 'shared/2024/1.jpg',
        // Specify a target bucket using name assigned in Amplify Backend
        // or bucket name from console and associated region
        bucket: {
          bucketName: 'generated-second-bucket-name',
          region: 'us-east-2'
        },
        expectedBucketOwner: '123456789013'
      }
    });
  } catch (error) {
    console.error('Error', err);
  }
};
In order to copy to or from a bucket other than your default, both source and destination must have bucket explicitly defined.

Copy source and destination options
Option	Type	Default	Description
path	string |
({ identityId }) => string	Required	A string or callback that represents the path in source and destination bucket to copy the object to or from.
Each segment of the path in source must by URI encoded.
bucket	string |
{ bucketName: string;
region: string; }	Default bucket and region from Amplify configuration	A string representing the target bucket's assigned name in Amplify Backend or an object specifying the bucket name and region from the console.

Read more at Configure additional storage buckets.
eTag	string	Optional	The copy source object entity tag (ETag) value. Only Copies the object if its ETag matches the specified tag.
notModifiedSince	Date	Optional	Copies the source object if it hasn't been modified since the specified time.

This is evaluated only when eTag is NOT supplied
expectedBucketOwner	string	Optional	source.expectedBucketOwner: The account ID that owns the source bucket.

destination.expectedBucketOwner: The account ID that owns the destination bucket.

- Listen to storage events - 
Function triggers can be configured to enable event-based workflows when files are uploaded or deleted. To add a function trigger, modify the defineStorage configuration.

First, in your storage definition, add the following:

amplify/storage/resource.ts
export const storage = defineStorage({
  name: 'myProjectFiles',
  triggers: {
    onUpload: defineFunction({
      entry: './on-upload-handler.ts'
    }),
    onDelete: defineFunction({
      entry: './on-delete-handler.ts'
    })
  }
});
Then create the function definitions at amplify/storage/on-upload-handler.ts and amplify/storage/on-delete-handler.ts.

amplify/storage/on-upload-handler.ts
import type { S3Handler } from 'aws-lambda';

export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);
};
amplify/storage/on-delete-handler.ts
import type { S3Handler } from 'aws-lambda';

export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Delete handler invoked for objects [${objectKeys.join(', ')}]`);
};
Note: The S3Handler type comes from the @types/aws-lambda npm package. This package contains types for different kinds of Lambda handlers, events, and responses.

Now, when you deploy your backend, these functions will be invoked whenever an object is uploaded or deleted from the bucket.

More Advanced Triggers
The example listed above demonstrates what is exposed directly in your storage definition. Specifically, the use of the triggers option when you use defineStorage. This method is for simple triggers that always execute on file uploads or file deletions. There are no additional modifications you can make to the triggers defined in this way.

If you want the ability to do something more than simply handle the events onUpload and onDelete you will have to use .addEventNotification in your backend.ts. If you use this method, the triggers section in your storage/resource.ts file should be removed.

Here is an example of how you can add a Lambda trigger for an S3 object PUT event. This trigger will execute when a file that has been uploaded to the bucket defined in your storage/resource.ts has a matching prefix and suffix as that listed in the function input of addEventNotification.

amplify/backend.ts
import { EventType } from 'aws-cdk-lib/aws-s3';
import { LambdaDestination } from 'aws-cdk-lib/aws-s3-notifications';
import { defineBackend } from '@aws-amplify/backend';
import { storage } from './storage/resource';
import { yourLambda } from './functions/yourLambda/resource';

const backend = defineBackend({
  storage,
  yourLambda,
});

backend.storage.resources.bucket.addEventNotification(
	EventType.OBJECT_CREATED_PUT,
	new LambdaDestination(backend.yourLambda.resources.lambda),
	{
		prefix: 'protected/uploads/',
		suffix: '-uploadManifest.json',
	}
);
It's important to note that using this methodology does not require any changes your lambda function. This modification on your backend.ts file will create a new AWS CloudFormation handler for "Custom::S3BucketNotifications" resources (@aws-cdk/aws-s3) that specifically handles checking the prefix and suffix.

- Extend S3 resources - 
For Amplify-generated S3 resources
Amplify Storage generates Amazon S3 resources to offer storage features. You can access the underlying Amazon S3 resources to further customize your backend configuration by using the AWS Cloud Developer Kit (AWS CDK).

Example - Enable Transfer Acceleration
The following is an example of how you would enable Transfer Acceleration on the bucket (CDK documentation). In order to enable Transfer Acceleration on the bucket, you will have to unwrap the L1 CDK construct from the L2 CDK construct like the following.

import * as s3 from 'aws-cdk-lib/aws-s3';
import { defineBackend } from '@aws-amplify/backend';
import { storage } from './storage/resource';

const backend = defineBackend({
  storage
});

const s3Bucket = backend.storage.resources.bucket;

const cfnBucket = s3Bucket.node.defaultChild as s3.CfnBucket;

cfnBucket.accelerateConfiguration = {
  accelerationStatus: "Enabled" // 'Suspended' if you want to disable transfer acceleration
}
Read more about escape hatches in the CDK.

For Manually configured S3 resources
To make calls to your S3 bucket from your App, you need to set up a CORS Policy for your S3 bucket. This callout is only for manual configuration of your S3 bucket.

The following steps will set up your CORS Policy:

Go to Amazon S3 console and click on your project's userfiles bucket, which is normally named as [Bucket Name][Id]-dev. Go to [Amazon S3 Console]
Click on the Permissions tab for your bucket. Click on the Permissions tab for your bucket
Click the edit button in the Cross-origin resource sharing (CORS) section. Click the edit button in the Cross-origin resource sharing (CORS) section
Make the Changes and click on Save Changes. You can add required metadata to be exposed in ExposeHeaders with x-amz-meta-XXXX format. Click on Save Changes:
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["GET", "HEAD", "PUT", "POST", "DELETE"],
    "AllowedOrigins": ["*"],
    "ExposeHeaders": [
      "x-amz-server-side-encryption",
      "x-amz-request-id",
      "x-amz-id-2",
      "ETag",
      "x-amz-meta-foo"
    ],
    "MaxAgeSeconds": 3000
  }
]
Note: You can restrict the access to your bucket by updating AllowedOrigin to include individual domains.

- Use Amplify Storage with any S3 bucket - 
With Amplify Storage APIs, you can use your own S3 buckets instead of the Amplify-created ones.

Important: To utilize the storage APIs with an S3 bucket outside of Amplify, you must have Amplify Auth configured in your project.

Use storage resources with an Amplify backend
Add necessary permissions to the S3 bucket
For the specific Amazon S3 bucket that you want to use with these APIs, you need to make sure that the associated IAM role has the necessary permissions to read and write data to that bucket.

To do this, go to Amazon S3 console > Select the S3 bucket > Permissions > Edit Bucket Policy.

Showing Amplify console showing Storage tab selected

The policy will look something like this

{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "Statement1",
			"Principal": { "AWS": "arn:aws:iam::<AWS-account-ID>:role/<role-name>" },
			"Effect": "Allow",
			"Action": [
				"s3:PutObject",
				"s3:GetObject",
				"s3:DeleteObject",
				"s3:ListBucket"
			],
			"Resource": [
				"arn:aws:s3:::<bucket-name>/*"
			]
		}
	]
}
Replace <AWS-account-ID> with your AWS account ID and <role-name> with the IAM role associated with your Amplify Auth setup. Replace <bucket-name> with the S3 bucket name.

You can refer to Amazon S3's Policies and Permissions documentation for more ways to customize access to the bucket.

Specify S3 bucket in Amplify's backend config
Next, use the addOutput method from the backend definition object to define a custom s3 bucket by specifying the name and region of the bucket in your amplify/backend.ts file.

Important

You cannot use both a storage backend configured through Amplify and a custom S3 bucket at the same time.

If you specify a custom S3 bucket, no sandbox storage resource will be created. The provided custom S3 bucket will be used, even in the sandbox environment.

import { defineBackend } from '@aws-amplify/backend';
import { auth } from './auth/resource';
import { data } from './data/resource';

const backend = defineBackend({
  auth,
  data,
});

backend.addOutput({
  storage: {
    aws_region: "<region>",
    bucket_name: "<bucket-name>"
  },
});
Import latest amplify_outputs.json file
To ensure the local amplify_outputs.json file is up-to-date, you can run the npx ampx generate outputs command or download the latest amplify_outputs.json from the Amplify console as shown below.



Now that you've configured the necessary permissions, you can start using the storage APIs with your chosen S3 bucket.

Use storage resources without an Amplify backend
While using the Amplify Backend is the easiest way to get started, existing storage resources can also be integrated with Amplify Storage.

In addition to manually configuring your storage options, you will also need to ensure Amplify Auth is properly configured in your project and associated IAM roles have the necessary permissions to interact with your existing bucket. Read more about using existing auth resources without an Amplify backend.

Using Amplify configure
Existing storage resource setup can be accomplished by passing the resource metadata to Amplify.configure. This will configure the Amplify Storage client library to interact with the additional resources. It's recommended to add the Amplify configuration step as early as possible in the application lifecycle, ideally at the root entry point.

import { Amplify } from 'aws-amplify';

Amplify.configure({
  Auth: {
    // add your auth configuration
  },
  Storage: {
    S3: {
      bucket: '<your-default-bucket-name>',
      region: '<your-default-bucket-region>',
      // default bucket metadata should be duplicated below with any additional buckets
      buckets: {
        '<your-default-bucket-friendly-name>': {
          bucketName: '<your-default-bucket-name>',
          region: '<your-default-bucket-region>'
        },
        '<your-additional-bucket-friendly-name>': {
          bucketName: '<your-additional-bucket-name>',
          region: '<your-additional-bucket-region>'
        }
      }
    }
  }
});
Using Amplify outputs
Alternatively, existing storage resources can be used by creating or modifying the amplify_outputs.json file directly.

amplify_outputs.json
{
  "auth": {
    // add your auth configuration
  },
  "storage": {
    "aws_region": "<your-default-bucket-region>", 
    "bucket_name": "<your-default-bucket-name>",
    // default bucket metadata should be duplicated below with any additional buckets
    "buckets": [
      {
        "name": "<your-default-bucket-friendly-name>", 
        "bucket_name": "<your-default-bucket-name>", 
        "aws_region": "<your-default-bucket-region>" 
      },
      {
        "name": "<your-additional-bucket-friendly-name>",
        "bucket_name": "<your-additional-bucket-name>",
        "aws_region": "<your-additional-bucket-region>"
      }
    ]
  }
}

- Manage files with Amplify console - 
The File storage page in the Amplify console provides a user-friendly interface for managing your application's backend file storage. It allows for efficient testing and management of your files.

If you have not yet created a storage resource, visit the Storage setup guide.

Access File storage
After you've deployed your storage resource, you can access the manager on Amplify Console.

Log in to the Amplify console and choose your app.
Select the branch you would like to access.
Select Storage from the left navigation bar.
To upload a file
On the Storage page, select the Upload button
Select the file you would like to upload and then select Done
Alternatively, you can Drag and drop a file onto the Storage page.

To delete a file
On the Storage page, select the file you want to delete.
Select the Actions dropdown and then select Delete.
To copy a file
On the Storage page, select the file you want to copy.
Select the Actions dropdown and then select Copy to.
Select or create the folder you want a copy of your file to be saved to.
Select Copy to copy your file to the selected folder.
To move a file
On the Storage page, select the file you want to move.
Select the Actions dropdown and then select Move to.
Select or create the folder you want to move your file to.
Select Move to move your file to the selected folder.

- API Reference - 
copy
Copy an object from a source to a destination object within the same bucket.
Parameters
Option	Required	Type	Description
input	true	StorageCopyInputWithPath	
The CopyWithPathInput object.
Throws
service:S3Exception - Thrown when checking for existence of the object
validation:StorageValidationErrorCode - Thrown when source or destination path is not defined.
Returns
Promise<CopyWithPathOutput>
Output type with path for S3 copy API.
copy
Parameters
Option	Required	Type	Description
input	true	CopyInput	
The CopyInput object.
Throws
service:S3Exception - Thrown when checking for existence of the object
validation:StorageValidationErrorCode - Thrown when source or destination key is not defined.
Returns
Promise<CopyOutput>
Output type with path for S3 copy API.
downloadData
Download S3 object data to memory
Parameters
Option	Required	Type	Description
input	true	DownloadDataWithPathInput	
The DownloadDataWithPathInput object.
Throws
service:S3Exception - thrown when checking for existence of the object
validation:StorageValidationErrorCode - Validation errors
Returns
DownloadDataWithPathOutput
Output type with path for S3 downloadData API.
downloadData
Parameters
Option	Required	Type	Description
input	true	DownloadDataInput	
The DownloadDataInput object.
Throws
service:S3Exception - thrown when checking for existence of the object
validation:StorageValidationErrorCode - Validation errors
Returns
DownloadDataOutput
Output type for S3 downloadData API.
getProperties
Gets the properties of a file. The properties include S3 system metadata and the user metadata that was provided when uploading the file.
Parameters
Option	Required	Type	Description
input	true	GetPropertiesWithPathInput	
The GetPropertiesWithPathInput object.
Throws
AnS3Exception when the underlying S3 service returned error.
AStorageValidationErrorCode when API call parameters are invalid.
Returns
Promise<GetPropertiesWithPathOutput>
Output type with path for S3 getProperties API.
getProperties
Parameters
Option	Required	Type	Description
input	true	GetPropertiesInput	
The GetPropertiesInput object.
Throws
AnS3Exception when the underlying S3 service returned error.
AStorageValidationErrorCode when API call parameters are invalid.
Returns
Promise<GetPropertiesOutput>
Output type for S3 getProperties API.
getUrl
Get a temporary presigned URL to download the specified S3 object. The presigned URL expires when the associated role used to sign the request expires or the option expiresIn is reached. The expiresAt
property in the output object indicates when the URL MAY expire.
By default, it will not validate the object that exists in S3. If you set the options.validateObjectExistence to true, this method will verify the given object already exists in S3 before returning a presigned URL, and will throw StorageError if the object does not exist.
Parameters
Option	Required	Type	Description
input	true	GetUrlWithPathInput	
The GetUrlWithPathInput object.
Throws
service:S3Exception - thrown when checking for existence of the object
validation:StorageValidationErrorCode - Validation errors thrown either username or key are not defined.
Returns
Promise<GetUrlWithPathOutput>
Output type with path for S3 getUrl API.
getUrl
Parameters
Option	Required	Type	Description
input	true	GetUrlInput	
The GetUrlInput object.
Throws
service:S3Exception - thrown when checking for existence of the object
validation:StorageValidationErrorCode - Validation errors thrown either username or key are not defined.
Returns
Promise<GetUrlOutput>
Output type for S3 getUrl API.
isCancelError
Check if an error is caused by user calling cancel() on a upload/download task. If an overwriting error is supplied to task.cancel(errorOverwrite), this function will return false.
Parameters
Option	Required	Type	Description
error	true	unknown	
The unknown exception to be checked.
Returns
CanceledError
list
List files in pages with the given path. pageSize is defaulted to 1000. Additionally, the result will include a nextToken if there are more items to retrieve.
Parameters
Option	Required	Type	Description
input	true	ListPaginateWithPathInput	
The ListPaginateWithPathInput object.
Throws
service:S3Exception - S3 service errors thrown when checking for existence of bucket
validation:StorageValidationErrorCode - thrown when there are issues with credentials
Returns
Promise<ListPaginateWithPathOutput>
Output type with path for S3 list API. Lists bucket objects with pagination.
list
List all files from S3 for a given path. You can set listAll to true in options to get all the files from S3.
Parameters
Option	Required	Type	Description
input	true	ListAllWithPathInput	
The ListAllWithPathInput object.
Throws
service:S3Exception - S3 service errors thrown when checking for existence of bucket
validation:StorageValidationErrorCode - thrown when there are issues with credentials
Returns
Promise<ListAllWithPathOutput>
Output type with path for S3 list API. Lists all bucket objects.
list
Parameters
Option	Required	Type	Description
input	false	ListPaginateInput	
The ListPaginateInput object.
Throws
service:S3Exception - S3 service errors thrown when checking for existence of bucket
validation:StorageValidationErrorCode - thrown when there are issues with credentials
Returns
Promise<ListPaginateOutput>
list
Parameters
Option	Required	Type	Description
input	false	ListAllInput	
The ListAllInput object.
Throws
service:S3Exception - S3 service errors thrown when checking for existence of bucket
validation:StorageValidationErrorCode - thrown when there are issues with credentials
Returns
Promise<ListAllOutput>
remove
Remove a file from your S3 bucket.
Parameters
Option	Required	Type	Description
input	true	RemoveWithPathInput	
The RemoveWithPathInput object.
Throws
service:S3Exception - S3 service errors thrown while while removing the object.
validation:StorageValidationErrorCode - Validation errors thrown when there is no path or path is empty or path has a leading slash.
Returns
Promise<RemoveWithPathOutput>
Output type with path for S3 remove API.
remove
Parameters
Option	Required	Type	Description
input	true	RemoveInput	
The RemoveInput object.
Throws
service:S3Exception - S3 service errors thrown while while removing the object
validation:StorageValidationErrorCode - Validation errors thrown when there is no key or its empty.
Returns
Promise<RemoveOutput>
uploadData
Upload data to the specified S3 object path. By default uses single PUT operation to upload if the payload is less than 5MB. Otherwise, uses multipart upload to upload the payload. If the payload length cannot be determined, uses multipart upload.
Limitations: * Maximum object size is 5TB. * Maximum object size if the size cannot be determined before upload is 50GB.
Parameters
Option	Required	Type	Description
input	true	UploadDataWithPathInput	
A UploadDataWithPathInput object.
Throws
Service:S3Exception thrown when checking for existence of the object.
Validation:StorageValidationErrorCode thrown when a validation error occurs.
Returns
UploadDataWithPathOutput
Output type with path for S3 uploadData API.
uploadData
Upload data to the specified S3 object key. By default uses single PUT operation to upload if the payload is less than 5MB. Otherwise, uses multipart upload to upload the payload. If the payload length cannot be determined, uses multipart upload.
Limitations: * Maximum object size is 5TB. * Maximum object size if the size cannot be determined before upload is 50GB.
Parameters
Option	Required	Type	Description
input	true	UploadDataInput	
A UploadDataInput object.
Throws
Service:S3Exception thrown when checking for existence of the object.
Validation:StorageValidationErrorCode thrown when a validation error occurs.
Returns
UploadDataOutput
Output type for S3 uploadData API.

- Set up a Function -
Amplify Functions are powered by AWS Lambda, and allow you to perform a wide variety of customization through self-contained functions. Functions can respond to events from other resources, execute some logic in-between events like an authentication flow, or act as standalone jobs. They are used in a variety of settings and use cases:

Authentication flow customizations (e.g. attribute validations, allowlisting email domains)
Resolvers for GraphQL APIs
Handlers for individual REST API routes, or to host an entire API
Scheduled jobs
To get started, create a new directory and a resource file, amplify/functions/say-hello/resource.ts. Then, define the Function with defineFunction:

amplify/functions/say-hello/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const sayHello = defineFunction({
  // optionally specify a name for the Function (defaults to directory name)
  name: 'say-hello',
  // optionally specify a path to your handler (defaults to "./handler.ts")
  entry: './handler.ts'
});
Next, create the corresponding handler file at amplify/functions/say-hello/handler.ts. This is where your function code will go.

amplify/functions/say-hello/handler.ts
import type { Handler } from 'aws-lambda';

export const handler: Handler = async (event, context) => {
  // your function code goes here
  return 'Hello, World!';
};
The handler file must export a function named "handler". This is the entry point to your function. For more information on writing functions, refer to the AWS documentation for Lambda function handlers using Node.js.

Lastly, this function needs to be added to your backend.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { sayHello } from './functions/say-hello/resource';

defineBackend({
  sayHello
});
Now when you run npx ampx sandbox or deploy your app on Amplify, it will include your Function.

To invoke your Function, we recommend adding your Function as a handler for a custom query with your Amplify Data resource. This will enable you to strongly type Function arguments and the return statement, and use this to author your Function's business logic. To get started, open your amplify/data/resource.ts file and specify a new query in your schema:

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend"
import { sayHello } from "../functions/say-hello/resource"

const schema = a.schema({
  sayHello: a
    .query()
    .arguments({
      name: a.string(),
    })
    .returns(a.string())
    .authorization(allow => [allow.guest()])
    .handler(a.handler.function(sayHello)),
})

export type Schema = ClientSchema<typeof schema>

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "iam",
  },
})
Now you can use this query from the Schema export to strongly type your Function handler:

amplify/functions/say-hello/handler.ts
import type { Schema } from "../../data/resource"

export const handler: Schema["sayHello"]["functionHandler"] = async (event) => {
  // arguments typed from `.arguments()`
  const { name } = event.arguments
  // return typed from `.returns()`
  return `Hello, ${name}!`
}
Finally, use the data client to invoke your Function by calling its associated query.

src/main.ts
import type { Schema } from "./amplify/data/resource"
import { Amplify } from "aws-amplify"
import { generateClient } from "aws-amplify/api"
import outputs from "./amplify_outputs.json"

Amplify.configure(outputs)

const client = generateClient<Schema>()

client.queries.sayHello({
  name: "Amplify",
})
- Environment variables and secrets
Amplify Functions support setting environment variables and secrets on the environment property of defineFunction.

Note: do not store secret values in environment variables. Environment variables values are rendered in plaintext to the build artifacts located at .amplify/artifacts and may be emitted to CloudFormation stack event messages. To store secrets skip to the secrets section

Note: Environment variables and secrets configuration in defineFunction is not supported for Custom Functions.

Environment variables
Environment variables can be configured in defineFunction using the environment property.

amplify/functions/say-hello/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const sayHello = defineFunction({
  environment: {
    NAME: 'World'
  }
});
Any environment variables specified here will be available to the function at runtime.

Some environment variables are constant across all branches and deployments. But many environment values differ between deployment environments. Branch-specific environment variables can be configured for Amplify hosting deployments.

Suppose you created a branch-specific environment variable in hosting called "API_ENDPOINT" which had a different value for your "staging" vs "prod" branch. If you wanted that value to be available to your function you can pass it to the function using

amplify/functions/say-hello/resource.ts
export const sayHello = defineFunction({
  environment: {
    NAME: "World",
    API_ENDPOINT: process.env.API_ENDPOINT
  }
});
Accessing environment variables
Within your function handler, you can access environment variables using the normal process.env global object provided by the Node runtime. However, this does not make it easy to discover what environment variables will be available at runtime. Amplify generates an env symbol that can be used in your function handler and provides typings for all variables that will be available at runtime. Copy the following code to use it.

amplify/functions/say-hello/handler.ts
import { env } from '$amplify/env/say-hello'; // the import is '$amplify/env/<function-name>'

export const handler = async (event) => {
  // the env object has intellisense for all environment variables that are available to the function
  return `Hello, ${env.NAME}!`;
};
Learn more
Understanding the "env" symbol and how to manually configure your Amplify project to use it
Generated env files
When you configure your function with environment variables or secrets, Amplify's backend tooling generates a file using the function's name in .amplify/generated with references to your environment variables and secrets, as well as environment variables predefined by the Lambda runtime. This provides a type-safe experience for working with environment variables that does not require typing process.env manually.

Note: generated files are created before deployments when executing ampx sandbox or ampx pipeline-deploy

For example, if you have a function with the following definition:

amplify/functions/say-hello/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const sayHello = defineFunction({
  name: "say-hello",
  environment: {
    NAME: "World",
  },
});
Upon starting your next deployment, Amplify will create a file at the following location:

.amplify/generated/env/say-hello.ts
Using the TypeScript path alias, $amplify, you can import the file in your function's handler:

amplify/functions/say-hello/handler.ts
import { env } from "$amplify/env/say-hello"

export const handler = async (event) => {
  // the env object has intellisense for all environment variables that are available to the function
  return `Hello, ${env.NAME}!`;
};
Encountering issues with this file? Visit the troubleshooting guide for Cannot find module $amplify/env/<function-name>

Secrets
Sometimes it is necessary to provide a secret value to a function. For example, it may need a database password or an API key to perform some business use case. Environment variables should NOT be used for this because environment variable values are included in plaintext in the function configuration. Instead, secret access can be used.

Before using a secret in a function, you need to define a secret. After you have defined a secret, you can reference it in your function config.

amplify/functions/say-hello/resource.ts
import { defineFunction, secret } from '@aws-amplify/backend';

export const sayHello = defineFunction({
  environment: {
    NAME: "World",
    API_ENDPOINT: process.env.API_ENDPOINT,
    API_KEY: secret('MY_API_KEY') // this assumes you created a secret named "MY_API_KEY"
  }
});
You can use this secret value at runtime in your function the same as any other environment variable. However, you will notice that the value of the environment variable is not stored as part of the function configuration. Instead, the value is fetched when your function runs and is provided in memory.

amplify/functions/say-hello/handler.ts
import { env } from '$amplify/env/say-hello';

export const handler = async (event) => {
  const request = new Request(env.API_ENDPOINT, {
    headers: {
      // this is the value of secret named "MY_API_KEY"
      Authorization: `Bearer ${env.API_KEY}`
    }
  })
  // ...
  return `Hello, ${env.NAME}!`;
};
- Configure Functions -
defineFunction comes out-of-the-box with sensible but minimal defaults. The following options are provided to tweak the function configuration.

Note: The following options are not supported for Custom Functions except for resourceGroupName.

name
By default, functions are named based on the directory the defineFunction call is placed in. In the above example, defining the function in amplify/functions/my-demo-function/resource.ts will cause the function to be named my-demo-function by default.

If an entry is specified, then the name defaults to the basename of the entry path. For example, an entry of ./signup-trigger-handler.ts would cause the function name to default to signup-trigger-handler.

This optional property can be used to explicitly set the name of the function.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
  entry: './demo-function-handler.ts',
  name: 'overrideName' // explicitly set the name to override the default naming behavior
});
timeoutSeconds
By default, functions will time out after 3 seconds. This can be configured to any whole number of seconds up to 15 minutes.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
  timeoutSeconds: 60 // 1 minute timeout
});
memoryMB
By default, functions have 512 MB of memory allocated to them. This can be configured from 128 MB up to 10240 MB. Note that this can increase the cost of function invocation. For more pricing information see here.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
  memoryMB: 256 // allocate 256 MB of memory to the function.
});
ephemeralStorageSizeMB
By default, functions have 512MB of ephemeral storage to them. This can be configured from 512 MB upto 10240 MB. Note that this can increase the cost of function invocation. For more pricing information visit the Lambda pricing documentation.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
  ephemeralStorageSizeMB: 1024 // allocate 1024 MB of ephemeral storage to the function.
});
runtime
Currently, only Node runtimes are supported by defineFunction. However, you can change the Node version that is used by the function. The default is the oldest Node LTS version that is supported by AWS Lambda (currently Node 18).

If you wish to use an older version of Node, keep an eye on the Lambda Node version deprecation schedule. As Lambda removes support for old Node versions, you will have to update to newer supported versions.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
  runtime: 20 // use Node 20
});
entry
By default, Amplify will look for your function handler in a file called handler.ts in the same directory as the file where defineFunction is called. To point to a different handler location, specify an entry value.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
  entry: './path/to/handler.ts' // this path should either be absolute or relative to the current file
});
resourceGroupName
By default, functions are grouped together in a resource group named function. You can override this to group related function with other Amplify resources like auth, data, storage, or separate them into your own custom group. This is typically useful when you have resources that depend on each other and you want to group them together.

amplify/functions/my-demo-function/resource.ts
export const myDemoFunction = defineFunction({
  resourceGroupName: 'data'
});

- Scheduling Functions -
Amplify offers the ability to schedule Functions to run on specific intervals using natural language or cron expressions. To get started, specify the schedule property in defineFunction:

Note: Configuring the schedule in defineFunction is not supported for Custom Functions.

amplify/jobs/weekly-digest/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const weeklyDigest = defineFunction({
  name: "weekly-digest",
  schedule: "every week",
});
Function schedules are powered by Amazon EventBridge rules, and can be leveraged to address use cases such as:

generating a "front page" of top-performing posts
generating a weekly digest of top-performing posts
generating a monthly report of warehouse inventory
Their handlers can be typed using the EventBridgeHandler type:

amplify/jobs/weekly-digest/handler.ts
import type { EventBridgeHandler } from "aws-lambda";

export const handler: EventBridgeHandler<"Scheduled Event", null, void> = async (event) => {
  console.log("event", JSON.stringify(event, null, 2))
}
Note: AWS Lambda types can be installed with

Terminal
npm add --save-dev @types/aws-lambda
Schedules can either be a single interval, or multiple intervals:

amplify/jobs/generate-report/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const generateReport = defineFunction({
  name: "generate-report",
  schedule: ["every week", "every month", "every year"],
});
Schedules can also be defined to execute using minutes or hours with a shorthand syntax:

amplify/jobs/drink-some-water/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const drinkSomeWater = defineFunction({
  name: "drink-some-water",
  schedule: "every 1h"
})
Or combined to create complex schedules:

amplify/jobs/remind-me/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const remindMe = defineFunction({
  name: "remind-me",
  schedule: [
    // every sunday at midnight
    "every week",
    // every tuesday at 5pm
    "0 17 ? * 3 *",
    // every wednesday at 5pm
    "0 17 ? * 4 *",
    // every thursday at 5pm
    "0 17 ? * 5 *",
    // every friday at 5pm
    "0 17 ? * 6 *",
  ]
})
Using natural language
Schedules can be written using natural language, using terms you use every day. Amplify supports the following time periods:

day will always start at midnight
week will always start on Sunday at midnight
month will always start on the first of the month at midnight
year will always start on the first of the year at midnight
m for minutes
h for hours
Natural language expressions are prefixed with "every":

amplify/jobs/drink-some-water/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const drinkSomeWater = defineFunction({
  name: "drink-some-water",
  schedule: "every 1h"
})
Using cron expressions
Schedules can be written using cron expressions.

amplify/jobs/remind-me/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const remindMe = defineFunction({
  name: "remind-me-to-take-the-trash-out",
  schedule: [
    // every tuesday at 9am
    "0 9 ? * 3 *",
    // every friday at 9am
    "0 9 ? * 6 *",
  ]
})

- Streaming logs -
Amplify enables you to stream logs from your AWS Lambda functions directly to your terminal while running ampx sandbox. To get started, specify the --stream-function-logs option when starting sandbox:

Terminal
npx ampx sandbox --stream-function-logs
Note: this feature is only available for Sandbox

Streaming function logs directly to your terminal enable faster debug iterations, and greater insight into your functions' executions.

Filtering
By default, Amplify will stream all of your functions' logs. If you wish to only stream a subset of functions you can specify a filter by function name or a regular expression for function names. For example, if you have a collection of Auth triggers where the function names include "auth".

When working with more than 5 functions, we recommend using the --logs-filter flag to filter the log output to specific functions.

Terminal
npx ampx sandbox --stream-function-logs --logs-filter auth
After you successfully deploy your personal cloud sandbox, start your frontend application, and sign up for the first time, you will see logs from your triggers' executions printed to the terminal where sandbox is running.

Terminal
> npx ampx sandbox --stream-function-logs --logs-filter auth
...

  Total time: 158.44s

[Sandbox] Watching for file changes...
File written: amplify_outputs.json
[auth-pre-sign-up] 3:36:34 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-pre-sign-up] 3:36:34 PM START RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91 Version: $LATEST
[auth-pre-sign-up] 3:36:34 PM END RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91
[auth-pre-sign-up] 3:36:34 PM REPORT RequestId: 685be2bd-5df1-4dd5-9eb1-24f5f6337f91	Duration: 4.12 ms	Billed Duration: 5 ms	Memory Size: 512 MB	Max Memory Used: 67 MB	Init Duration: 173.67 ms
[auth-post-confirmation] 3:38:40 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-post-confirmation] 3:38:40 PM START RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7 Version: $LATEST
[auth-post-confirmation] 3:38:41 PM 2024-07-19T22:38:41.209Z	fce69b9f-b257-4af8-8a6e-821f84a39ce7	INFO	processed 412f8911-acfa-41c7-9605-fa0c40891ea9
[auth-post-confirmation] 3:38:41 PM END RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7
[auth-post-confirmation] 3:38:41 PM REPORT RequestId: fce69b9f-b257-4af8-8a6e-821f84a39ce7	Duration: 264.38 ms	Billed Duration: 265 ms	Memory Size: 512 MB	Max Memory Used: 93 MB	Init Duration: 562.19 ms
[auth-pre-authentication] 3:38:41 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-pre-authentication] 3:38:41 PM START RequestId: 9210ca3a-1351-4826-8544-123684765710 Version: $LATEST
[auth-pre-authentication] 3:38:41 PM END RequestId: 9210ca3a-1351-4826-8544-123684765710
[auth-pre-authentication] 3:38:41 PM REPORT RequestId: 9210ca3a-1351-4826-8544-123684765710	Duration: 3.47 ms	Billed Duration: 4 ms	Memory Size: 512 MB	Max Memory Used: 67 MB	Init Duration: 180.24 ms
[auth-post-authentication] 3:38:42 PM INIT_START Runtime Version: nodejs:18.v30	Runtime Version ARN: arn:aws:lambda:us-east-1::runtime:f89c264158db39a1cfcbb5f9b3741413df1cfce4d550c9a475a67d923e19e2f4
[auth-post-authentication] 3:38:42 PM START RequestId: 60c1d680-ea24-4a8b-93de-02d085859140 Version: $LATEST
[auth-post-authentication] 3:38:42 PM END RequestId: 60c1d680-ea24-4a8b-93de-02d085859140
[auth-post-authentication] 3:38:42 PM REPORT RequestId: 60c1d680-ea24-4a8b-93de-02d085859140	Duration: 4.61 ms	Billed Duration: 5 ms	Memory Size: 512 MB	Max Memory Used: 68 MB	Init Duration: 172.66 ms
Writing to a file
By default, Amplify will print logs to the terminal where sandbox is running, however you can alternatively write logs to a file by specifying --logs-out-file:

Terminal
npx ampx sandbox --stream-function-logs --logs-out-file sandbox.log
This can be combined with --logs-filter to create a log file of just your Auth-related functions, for example:

Terminal
npx ampx sandbox --stream-function-logs --logs-filter auth --logs-out-file sandbox-auth.log
However it cannot be combined multiple times to write logs to multiple files.

- Lambda Layers -
Amplify offers the ability to add layers to your functions which contain your library dependencies. Lambda layers allow you to separate your function code from its dependencies, enabling easier management of shared components across multiple functions and reducing deployment package sizes.

Note: Configuring or adding layers in defineFunction is not supported for Custom Functions.

To add a Lambda layer to your function, follow these steps:

First, create and set up your Lambda layer in AWS. You can do this through the AWS Console or using the AWS CLI. For guidance on creating layers, refer to the AWS documentation on creating Lambda layers.

Once your layer is created and available in AWS, you can reference it in your Amplify project as shown below.

Specify the layers property in defineFunction, for example:

amplify/functions/my-function/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const myFunction = defineFunction({
  name: "my-function",
  layers: {
   "@aws-lambda-powertools/logger":
      "arn:aws:lambda:us-east-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:12",
  },
});
The Lambda layer is represented by an object of key/value pairs where the key is the module name that is exported from your layer and the value is the ARN of the layer. The key (module name) is used to externalize the module dependency so it doesn't get bundled with your Lambda function. A maximum of 5 layers can be attached to a function, and they must be in the same region as the function.


Alternatively, you can specify the layer as myLayer:1 where myLayer is the name of the layer and 1 is the version of the layer. For example:

amplify/functions/my-function/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const myFunction = defineFunction({
  name: "my-function",
  layers: {
   "some-module": "myLayer:1"
  },
});
Amplify will automatically convert this to the full layer ARN format arn:aws:lambda:<region>:<account-id>:layer:myLayer:1 using your existing account ID and region.

When using layers, be mindful of versioning. The ARN includes a version number (e.g., :12 in the example). Ensure you're using the appropriate version and have a strategy for updating layers when new versions are released.

Then use the locally installed module in the function handler:

amplify/functions/my-function/handler.ts
import { Logger } from "@aws-lambda-powertools/logger";
import type { Handler } from "aws-lambda";

const logger = new Logger({ serviceName: "serverlessAirline" });

export const handler: Handler = async (event, context) => {
  logger.info("Hello World");
};
For further information on creating and managing your layers refer to AWS documentation for Lambda layers

- Grant access to other resources -
In order for Amplify Functions to interact with other resources they must be given access. There are two ways to grant Amplify Functions access to other resources:

Using the access property
Using the AWS Cloud Development Kit (CDK)
Using the access property
The access property is a property found in each of the define* functions for defining Amplify resources. It allows you specify the necessary actions using common language.

When you grant a function access to another resource in your Amplify backend (such as granting access to storage), it will configure environment variables for that function to make SDK calls to the AWS services it has access to. Those environment variables are typed and available as part of the env object.

Say you have a function that generates reports each month from your Data resource and needs to store the generated reports in Storage:

amplify/storage/resource.ts
import { defineStorage } from '@aws-amplify/backend';
import { generateMonthlyReports } from '../functions/generate-monthly-reports/resource';

export const storage = defineStorage({
  name: 'myReports',
  access: (allow) => ({
    'reports/*': [
      allow.resource(generateMonthlyReports).to(['read', 'write', 'delete'])
    ]
  })
});
This access definition will add the environment variable myReports_BUCKET_NAME to the function. This environment variable can be accessed on the env object.

Here's an example of how it can be used to upload some content to S3.

amplify/functions/generate-monthly-reports/handler.ts
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
import { env } from '$amplify/env/generate-monthly-reports';

const s3Client = new S3Client();

export const handler = async () => {
  const command = new PutObjectCommand({
    Bucket: env.MY_REPORTS_BUCKET_NAME,
    Key: `reports/${new Date().toISOString()}.csv`,
    Body: new Blob([''], { type: 'text/csv;charset=utf-8;' })
  });

  await s3Client.send(command);
};
Using CDK
When permissions are needed to access resources beyond the capabilities of the access property, you must use CDK.

Functions are created with an execution role, which is an IAM role that contains policies that dictate what resources your Function can interact with when it executes. This role can be extended using the addToRolePolicy() method:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"
import * as iam from "aws-cdk-lib/aws-iam"
import * as sns from "aws-cdk-lib/aws-sns"
import { weeklyDigest } from "./functions/weekly-digest/resource"

const backend = defineBackend({
  weeklyDigest,
})

const weeklyDigestLambda = backend.weeklyDigest.resources.lambda

const topicStack = backend.createStack("WeeklyDigest")
const topic = new sns.Topic(topicStack, "Topic", {
  displayName: "digest",
})

const statement = new iam.PolicyStatement({
  sid: "AllowPublishToDigest",
  actions: ["sns:Publish"],
  resources: [topic.topicArn],
})

weeklyDigestLambda.addToRolePolicy(statement)
However some constructs provide a grant* method to grant access to common policy actions. Revisiting the example above you can grant the same access with grantPublish:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"
import * as sns from "aws-cdk-lib/aws-sns"
import { weeklyDigest } from "./functions/weekly-digest/resource"

const backend = defineBackend({
  weeklyDigest,
})

const weeklyDigestLambda = backend.weeklyDigest.resources.lambda

const topicStack = backend.createStack("WeeklyDigest")
const topic = new sns.Topic(topicStack, "Topic", {
  displayName: "digest"
})

topic.grantPublish(weeklyDigestLambda)

- Email domain filtering - 
You can use defineAuth and defineFunction to create a Cognito pre sign-up Lambda trigger that performs filtering based on the user's email address. This can allow or deny user signups based on their email address.

To get started, install the aws-lambda package, which is used to define the handler type.

Terminal
npm add --save-dev @types/aws-lambda
Next, create a new directory and a resource file, amplify/auth/pre-sign-up/resource.ts. Then, define the Function with defineFunction:

amplify/auth/pre-sign-up/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const preSignUp = defineFunction({
  name: 'pre-sign-up',
  // optionally define an environment variable for your filter
  environment: {
    ALLOW_DOMAIN: 'amazon.com'
  }
});
Next, create the corresponding handler file, amplify/auth/pre-sign-up/handler.ts, file with the following contents:

amplify/auth/pre-sign-up/handler.ts
import type { PreSignUpTriggerHandler } from 'aws-lambda';
import { env } from '$amplify/env/pre-sign-up';

export const handler: PreSignUpTriggerHandler = async (event) => {
  const email = event.request.userAttributes['email'];

  if (!email.endsWith(env.ALLOW_DOMAIN)) {
    throw new Error('Invalid email domain');
  }

  return event;
};
Lastly, set the newly created Function resource on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';
import { preSignUp } from './pre-sign-up/resource';

export const auth = defineAuth({
  // ...
  triggers: {
    preSignUp
  }
});
After deploying the changes, whenever a user attempts to sign up without an amazon.com email address they will receive an error.

- Add user to group - 
You can use defineAuth and defineFunction to create a Cognito post confirmation Lambda trigger that extends the behavior to perform some action when a user is confirmed.

A user is "confirmed" when they verify their account. Typically this happens when the user confirms their email via the verification email. The post confirmation handler will not be triggered for federated sign-ins (i.e. social sign-in).

To get started, install the AWS SDK v3 package, which will be used to perform actions against your auth resource, and the @types/aws-lambda package, which is used to define the handler type:

Terminal
npm add --save-dev @aws-sdk/client-cognito-identity-provider @types/aws-lambda
Next, create a new directory and a resource file, amplify/auth/post-confirmation/resource.ts. Then, define the Function with defineFunction:

amplify/auth/post-confirmation/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const postConfirmation = defineFunction({
  name: 'post-confirmation',
  // optionally define an environment variable for your group name
  environment: {
    GROUP_NAME: 'EVERYONE'
  },
  resourceGroupName: 'auth'
});
After creating the Function definition you will need to:

create the EVERYONE group
grant access to your auth resource to ensure it can perform the addUserToGroup action
set the Function as the post confirmation trigger
amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend";
import { postConfirmation } from "./post-confirmation/resource"

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  groups: ["EVERYONE"],
  triggers: {
    postConfirmation,
  },
  access: (allow) => [
    allow.resource(postConfirmation).to(["addUserToGroup"]),
  ],
})
Then create the Function's corresponding handler file, amplify/auth/post-confirmation/handler.ts, file with the following contents:

amplify/auth/post-confirmation/handler.ts
import type { PostConfirmationTriggerHandler } from 'aws-lambda';
import {
  CognitoIdentityProviderClient,
  AdminAddUserToGroupCommand
} from '@aws-sdk/client-cognito-identity-provider';
import { env } from '$amplify/env/post-confirmation';

const client = new CognitoIdentityProviderClient();

// add user to group
export const handler: PostConfirmationTriggerHandler = async (event) => {
  const command = new AdminAddUserToGroupCommand({
    GroupName: env.GROUP_NAME,
    Username: event.userName,
    UserPoolId: event.userPoolId
  });
  const response = await client.send(command);
  console.log('processed', response.$metadata.requestId);
  return event;
};
After deploying the changes, whenever a user signs up and verifies their account they are automatically added to the group named "EVERYONE".

- Create a user profile record -
You can use defineAuth and defineFunction to create a Cognito post confirmation Lambda trigger to create a profile record when a user is confirmed.

A user is "confirmed" when they verify their account. Typically this happens when the user confirms their email via the verification email. The post confirmation handler will not be triggered for federated sign-ins (i.e. social sign-in).

To get started, install the aws-lambda package, which is used to define the handler type.

Terminal
npm add --save-dev @types/aws-lambda
Update the amplify/data/resource.ts file to define a data model for the user's profile:

Make sure to configure the authorization rule to allow the postConfirmation resource as highlighted below. Granting access to resources creates environment variables for your Function such as the GraphQL API endpoint. To learn more visit the environment variables and secrets documentation for Functions.

amplify/data/resource.ts
import { type ClientSchema, a, defineData } from "@aws-amplify/backend";
import { postConfirmation } from "../auth/post-confirmation/resource";

const schema = a
  .schema({
    UserProfile: a
      .model({
        email: a.string(),
        profileOwner: a.string(),
      })
      .authorization((allow) => [
        allow.ownerDefinedIn("profileOwner"),
      ]),
  })
  .authorization((allow) => [allow.resource(postConfirmation)]);
export type Schema = ClientSchema<typeof schema>;

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "apiKey",
    apiKeyAuthorizationMode: {
      expiresInDays: 30,
    },
  },
});
Create a new directory and a resource file, amplify/auth/post-confirmation/resource.ts. Then, define the Function with defineFunction:

amplify/auth/post-confirmation/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const postConfirmation = defineFunction({
  name: 'post-confirmation',
});
Then, create the corresponding handler file, amplify/auth/post-confirmation/handler.ts, file with the following contents:

amplify/auth/post-confirmation/handler.ts
import type { PostConfirmationTriggerHandler } from "aws-lambda";
import { type Schema } from "../../data/resource";
import { Amplify } from "aws-amplify";
import { generateClient } from "aws-amplify/data";
import { getAmplifyDataClientConfig } from '@aws-amplify/backend/function/runtime';
import { env } from "$amplify/env/post-confirmation";

const { resourceConfig, libraryOptions } = await getAmplifyDataClientConfig(
  env
);

Amplify.configure(resourceConfig, libraryOptions);

const client = generateClient<Schema>();

export const handler: PostConfirmationTriggerHandler = async (event) => {
  await client.models.UserProfile.create({
      email: event.request.userAttributes.email,
      profileOwner: `${event.request.userAttributes.sub}::${event.userName}`,
  });

  return event;
};
When configuring Amplify with getAmplifyDataClientConfig, your function consumes schema information from an S3 bucket created during backend deployment with grants for the access your function need to use it. Any changes to this bucket outside of backend deployment may break your function.

Lastly, set the newly created Function resource on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';
import { postConfirmation } from './post-confirmation/resource';

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    postConfirmation
  }
});
After deploying the changes, whenever a user signs up and verifies their account a profile record is automatically created.

 - Override ID token claims - 
You can use defineAuth and defineFunction to create an Amazon Cognito Pre token generation AWS Lambda trigger to override the token by adding a new claim or modifying the user's group membership.

To get started, install the aws-lambda package, which is used to define the handler type.

Terminal
npm add --save-dev @types/aws-lambda
Create a new directory and a resource file, amplify/auth/pre-token-generation/resource.ts. Then, define the function with defineFunction:

amplify/auth/pre-token-generation/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const preTokenGeneration = defineFunction({
  name: 'pre-token-generation',
  resourceGroupName: 'auth'
});
Then, create the corresponding handler file, amplify/auth/post-confirmation/pre-token-generation/handler.ts, file with the following contents:

amplify/auth/pre-token-generation/handler.ts
import type { PreTokenGenerationTriggerHandler } from "aws-lambda";

export const handler: PreTokenGenerationTriggerHandler = async (event) => {
  event.response = {
    claimsOverrideDetails: {
      groupOverrideDetails: {
        // This will add the user to the cognito group "amplify_group_1" 
        groupsToOverride: ["amplify_group_1"],
      },
      claimsToAddOrOverride: {
        // This will add the custom claim "amplfy_attribute" to the id token
        amplfy_attribute: "amplify_gen_2",
      },
    },
  };
  return event;
};
Lastly, set the newly created function resource on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';
import { preTokenGeneration } from './pre-token-generation/resource';

export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    preTokenGeneration
  }
});
After deploying the changes, The idToken of the user will be modified as per the trigger above.

{
  "cognito:groups": [
    "amplify_group_1"
  ],
  "email_verified": true,
  "iss": "...",
  "cognito:username": "...",
  "origin_jti": "...",
  "amplfy_attribute": "amplify_gen_2",
  "aud": "...",
}

- User attribute validation - 
You can use defineAuth and defineFunction to create a Cognito pre sign-up Lambda trigger that extends the behavior of sign-up to validate attribute values.

To get started, create a new directory and a resource file, amplify/auth/pre-sign-up/resource.ts. Then, define the function with defineFunction:

amplify/auth/pre-sign-up/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const preSignUp = defineFunction({
  name: "pre-sign-up",
  resourceGroupName: 'auth'
});
Next, create the corresponding handler file, amplify/auth/pre-sign-up/handler.ts, file with the following contents:

amplify/auth/pre-sign-up/handler.ts
import type { PreSignUpTriggerHandler } from "aws-lambda"

function isOlderThan(date: Date, age: number) {
  const comparison = new Date()
  comparison.setFullYear(comparison.getFullYear() - age)
  return date.getTime() > comparison.getTime()
}

export const handler: PreSignUpTriggerHandler = async (event) => {
  const birthdate = new Date(event.request.userAttributes["birthdate"])

  // you must be 13 years or older
  if (!isOlderThan(birthdate, 13)) {
    throw new Error("You must be 13 years or older to use this site")
  }

  return event
}
Lastly, set the newly created function resource on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';
import { preSignUp } from './pre-sign-up/resource';

export const auth = defineAuth({
  // ...
  triggers: {
    preSignUp
  }
});
After deploying the changes, whenever a user attempts to sign up this handler will verify the submitter's age is above 13 years.

- Custom message - 
You can use defineAuth and defineFunction to create an Amazon Cognito custom message AWS Lambda trigger thats sends an custom email or phone verification message, or a multi-factor authentication (MFA) code.

To get started, install @types/aws-lambda package that will be used to define the type of the handler:

Terminal
npm add --save-dev @types/aws-lambda
Next, create a new directory and a resource file, amplify/auth/custom-message/resource.ts. Then, define the function with defineFunction:

amplify/auth/custom-message/resource.ts
import { defineFunction } from '@aws-amplify/backend';

export const customMessage = defineFunction({
  name: "custom-message",
  resourceGroupName: 'auth'
});
Next, create the corresponding handler file, amplify/auth/custom-message/handler.ts, file with the following contents:

amplify/auth/custom-message/handler.ts
import type { CustomMessageTriggerHandler } from "aws-lambda";

export const handler: CustomMessageTriggerHandler = async (event) => {
  if (event.triggerSource === "CustomMessage_ForgotPassword") {
    const locale = event.request.userAttributes["locale"];
    if (locale === "en") {
      event.response.emailMessage = `Your new one-time code is ${event.request.codeParameter}`;
      event.response.emailSubject = "Reset my password";
    } else if (locale === "es") {
      event.response.emailMessage = `Tu nuevo cdigo de un solo uso es ${event.request.codeParameter}`;
      event.response.emailSubject = "Restablecer mi contrasea";
    }
  }

  return event;
};
Lastly, set the newly created function resource on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from '@aws-amplify/backend';
import { customMessage } from "./custom-message/resource";

export const auth = defineAuth({
  // ...
  triggers: {
    customMessage,
  }
});
After deploying the changes, whenever a user with user attribute locale set to es attempts to reset a password they will receive an email with a one-time code in Spanish.

- Google reCAPTCHA challenge - 
You can use defineAuth and defineFunction to create an auth experience that requires a reCAPTCHA v3 token. This can be accomplished by leveraging Amazon Cognito's feature to define a custom auth challenge and 3 triggers:

Create auth challenge
Define auth challenge
Verify auth challenge response
Create auth challenge trigger
To get started, create the first of the three triggers, create-auth-challenge. This is the trigger responsible for creating the reCAPTCHA challenge after a password is verified.

amplify/auth/create-auth-challenge/resource.ts
import { defineFunction } from "@aws-amplify/backend"

export const createAuthChallenge = defineFunction({
  name: "create-auth-challenge",
  resourceGroupName: 'auth'
})
After creating the resource file, create the handler with the following contents:

amplify/auth/create-auth-challenge/handler.ts
import type { CreateAuthChallengeTriggerHandler } from "aws-lambda"

export const handler: CreateAuthChallengeTriggerHandler = async (event) => {
  const { request, response } = event

  if (
    // session will contain 3 "steps": SRP, password verification, custom challenge
    request.session.length === 2 &&
    request.challengeName === "CUSTOM_CHALLENGE"
  ) {
    response.publicChallengeParameters = { trigger: "true" }
    response.privateChallengeParameters = { answer: "" }
    // optionally set challenge metadata
    response.challengeMetadata = "CAPTCHA_CHALLENGE"
  }

  return event
}
Define auth challenge trigger
Next, you will want to create the trigger responsible for defining the auth challenge flow, define-auth-challenge.

amplify/auth/define-auth-challenge/resource.ts
import { defineFunction } from "@aws-amplify/backend"

export const defineAuthChallenge = defineFunction({
  name: "define-auth-challenge",
  resourceGroupName: 'auth'
})
After creating the resource file, create the handler with the following contents:

amplify/auth/define-auth-challenge/handler.ts
import type { DefineAuthChallengeTriggerHandler } from "aws-lambda"

export const handler: DefineAuthChallengeTriggerHandler = async (event) => {
  const { response } = event
  const [srp, password, captcha] = event.request.session

  // deny by default
  response.issueTokens = false
  response.failAuthentication = true

  if (srp?.challengeName === "SRP_A") {
    response.failAuthentication = false
    response.challengeName = "PASSWORD_VERIFIER"
  }

  if (
    password?.challengeName === "PASSWORD_VERIFIER" &&
    password.challengeResult === true
  ) {
    response.failAuthentication = false
    response.challengeName = "CUSTOM_CHALLENGE"
  }

  if (
    captcha?.challengeName === "CUSTOM_CHALLENGE" &&
    // check for the challenge metadata set in "create-auth-challenge"
    captcha?.challengeMetadata === "CAPTCHA_CHALLENGE" &&
    captcha.challengeResult === true
  ) {
    response.issueTokens = true
    response.failAuthentication = false
  }

  return event
}
Verify auth challenge response trigger
Lastly, create the trigger responsible for verifying the challenge response, which in this case is the reCAPTCHA token verification.

If you have not done so already, you will need to register your application and retrieve a reCAPTCHA secret key. This can then be configured for use with your cloud sandbox using:

Terminal
npx ampx sandbox secret set GOOGLE_RECAPTCHA_SECRET_KEY
amplify/auth/verify-auth-challenge-response/resource.ts
import { defineFunction, secret } from "@aws-amplify/backend"

export const verifyAuthChallengeResponse = defineFunction({
  name: "verify-auth-challenge-response",
  environment: {
    GOOGLE_RECAPTCHA_SECRET_KEY: secret("GOOGLE_RECAPTCHA_SECRET_KEY"),
  },
  resourceGroupName: 'auth'
})
After creating the resource file, create the handler with the following contents:

amplify/auth/verify-auth-challenge-response/handler.ts
import type { VerifyAuthChallengeResponseTriggerHandler } from "aws-lambda"
import { env } from "$amplify/env/verify-auth-challenge-response"

/**
 * Google ReCAPTCHA verification response
 * @see https://developers.google.com/recaptcha/docs/v3#site_verify_response
 */
type GoogleRecaptchaVerifyResponse = {
  // whether this request was a valid reCAPTCHA token for your site
  success: boolean
  // the score for this request (0.0 - 1.0)
  score: number
  // the action name for this request (important to verify)
  action: string
  // timestamp of the challenge load (ISO format yyyy-MM-dd'T'HH:mm:ssZZ)
  challenge_ts: string
  // the hostname of the site where the reCAPTCHA was solved
  hostname: string
  // optional error codes
  "error-codes"?: unknown[]
}

export const handler: VerifyAuthChallengeResponseTriggerHandler = async (
  event
) => {
  if (!event.request.challengeAnswer) {
    throw new Error("Missing challenge answer")
  }

  // https://developers.google.com/recaptcha/docs/verify#api_request
  const url = new URL("https://www.google.com/recaptcha/api/siteverify")
  const params = new URLSearchParams({
    secret: env.GOOGLE_RECAPTCHA_SECRET_KEY,
    response: event.request.challengeAnswer,
  })
  url.search = params.toString()

  const request = new Request(url, {
    method: "POST",
  })

  const response = await fetch(request)
  const result = (await response.json()) as GoogleRecaptchaVerifyResponse

  if (!result.success) {
    throw new Error("Verification failed", { cause: result["error-codes"] })
  }

  // indicate whether the answer is correct
  event.response.answerCorrect = result.success

  return event
}
Configure auth resource
Finally, import and set the three triggers on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"
import { createAuthChallenge } from "./create-auth-challenge/resource"
import { defineAuthChallenge } from "./define-auth-challenge/resource"
import { verifyAuthChallengeResponse } from "./verify-auth-challenge-response/resource"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    createAuthChallenge,
    defineAuthChallenge,
    verifyAuthChallengeResponse,
  },
})

- Amazon Kinesis Data Streams -
With AWS Lambda, you can seamlessly integrate various event sources, such as Amazon Kinesis, Amazon SQS, and others, to trigger Lambda functions in response to real-time events. This feature enables you to build responsive, event-driven applications that react to changes in data or system state without the need for polling services.

In this guide, let us configure a Lambda function with a Kinesis data stream as an event source. The Lambda function is automatically triggered whenever new data is published to the stream - whether you're processing streaming data, reacting to application events, or automating workflows.

To get started, install the AWS Lambda Powertools Logger, which provides structured logging capabilities for your Lambda function, and the aws-lambda package, which is used to define the handler type.

Terminal
npm add @aws-lambda-powertools/logger @types/aws-lambda
Second, create a new directory and a resource file, amplify/functions/kinesis-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/kinesis-function/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const myKinesisFunction = defineFunction({
  name: "kinesis-function",
});
Third, create the corresponding handler file, amplify/functions/kinesis-function/handler.ts, file with the following contents:

amplify/functions/kinesis-function/handler.ts
import type {
  KinesisStreamBatchResponse,
  KinesisStreamHandler,
  KinesisStreamRecordPayload,
} from "aws-lambda";
import { Buffer } from "node:buffer";
import { Logger } from "@aws-lambda-powertools/logger";

const logger = new Logger({
  logLevel: "INFO",
  serviceName: "kinesis-stream-handler",
});

export const handler: KinesisStreamHandler = async (
  event,
  context
): Promise<KinesisStreamBatchResponse> => {
  for (const record of event.Records) {
    try {
      logger.info(`Processed Kinesis Event - EventID: ${record.eventID}`);
      const recordData = await getRecordDataAsync(record.kinesis);
      logger.info(`Record Data: ${recordData}`);
    } catch (err) {
      logger.error(`An error occurred ${err}`);
      /*
      When processing stream data, if any item fails, returning the failed item's position immediately
      prompts Lambda to retry from this item forward, ensuring continuous processing without skipping data.
      */
      return {
        batchItemFailures: [{ itemIdentifier: record.kinesis.sequenceNumber }],
      };
    }
  }
  logger.info(`Successfully processed ${event.Records.length} records.`);
  return { batchItemFailures: [] };
};

async function getRecordDataAsync(
  payload: KinesisStreamRecordPayload
): Promise<string> {
  const data = Buffer.from(payload.data, "base64").toString("utf-8");
  await Promise.resolve(1); // Placeholder for an async process
  return data;
}
Lastly, create the Kinesis stream and add it as a event source in the amplify/backend.ts file:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { Stream } from "aws-cdk-lib/aws-kinesis";
import { StartingPosition } from "aws-cdk-lib/aws-lambda";
import { KinesisEventSource } from "aws-cdk-lib/aws-lambda-event-sources";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { myKinesisFunction } from "./functions/kinesis-function/resource";

const backend = defineBackend({
  auth,
  data,
  myKinesisFunction,
});

const kinesisStack = backend.createStack("kinesis-stack");

const kinesisStream = new Stream(kinesisStack, "KinesisStream", {
  streamName: "myKinesisStream",
  shardCount: 1,
});

const eventSource = new KinesisEventSource(kinesisStream, {
  startingPosition: StartingPosition.LATEST,
  reportBatchItemFailures: true,
});

backend.myKinesisFunction.resources.lambda.addEventSource(eventSource);
For examples on streaming analytics data to the Kinesis stream from your frontend, see the Streaming analytics data documentation.

- DynamoDB Streams - 
With AWS Lambda, you can seamlessly integrate various event sources, such as Amazon DynamoDB, Amazon SQS, and others, to trigger Lambda functions in response to real-time events. This feature enables you to build responsive, event-driven applications that react to changes in data or system state without the need for polling services.

In this guide, lets configure a Lambda function with an Amazon DynamoDB stream as an event source. The Lambda function is automatically triggered whenever an item is added, updated, or deleted from the table, enabling you to build real-time applications that react to changes in your data. In this example, we will use a Todo table created by a data model on the GraphQL API.

To get started, install the AWS Lambda Powertools Logger, which provides structured logging capabilities for your Lambda function, and the aws-lambda package, which is used to define the handler type.

Terminal
npm add --save-dev @aws-lambda-powertools/logger @types/aws-lambda
Second, create a new directory and a resource file, amplify/functions/dynamoDB-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/dynamoDB-function/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const myDynamoDBFunction = defineFunction({
  name: "dynamoDB-function",
  resourceGroupName: "data",
});
Third, create the corresponding handler file, amplify/functions/dynamoDB-function/handler.ts, file with the following contents:

amplify/functions/dynamoDB-function/handler.ts
import type { DynamoDBStreamHandler } from "aws-lambda";
import { Logger } from "@aws-lambda-powertools/logger";

const logger = new Logger({
  logLevel: "INFO",
  serviceName: "dynamodb-stream-handler",
});

export const handler: DynamoDBStreamHandler = async (event) => {
  for (const record of event.Records) {
    logger.info(`Processing record: ${record.eventID}`);
    logger.info(`Event Type: ${record.eventName}`);

    if (record.eventName === "INSERT") {
      // business logic to process new records
      logger.info(`New Image: ${JSON.stringify(record.dynamodb?.NewImage)}`);
    }
  }
  logger.info(`Successfully processed ${event.Records.length} records.`);

  return {
    batchItemFailures: [],
  };
};
Lastly, create DynamoDB table as event source in the amplify/backend.ts file:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { Stack } from "aws-cdk-lib";
import { Policy, PolicyStatement, Effect } from "aws-cdk-lib/aws-iam";
import { StartingPosition, EventSourceMapping } from "aws-cdk-lib/aws-lambda";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { myDynamoDBFunction } from "./functions/dynamoDB-function/resource";

const backend = defineBackend({
  auth,
  data,
  myDynamoDBFunction,
});

const todoTable = backend.data.resources.tables["Todo"];
const policy = new Policy(
  Stack.of(todoTable),
  "MyDynamoDBFunctionStreamingPolicy",
  {
    statements: [
      new PolicyStatement({
        effect: Effect.ALLOW,
        actions: [
          "dynamodb:DescribeStream",
          "dynamodb:GetRecords",
          "dynamodb:GetShardIterator",
          "dynamodb:ListStreams",
        ],
        resources: ["*"],
      }),
    ],
  }
);
backend.myDynamoDBFunction.resources.lambda.role?.attachInlinePolicy(policy);

const mapping = new EventSourceMapping(
  Stack.of(todoTable),
  "MyDynamoDBFunctionTodoEventStreamMapping",
  {
    target: backend.myDynamoDBFunction.resources.lambda,
    eventSourceArn: todoTable.tableStreamArn,
    startingPosition: StartingPosition.LATEST,
  }
);

mapping.node.addDependency(policy);

- S3 Upload confirmation -
You can use defineStorage and defineFunction to create a function trigger to confirm uploading a file.

To get started, install the @types/aws-lambda package, which contains types for different kinds of Lambda handlers, events, and responses.

Terminal
npm add --save @types/aws-lambda
Update your storage definition to define the onUpload trigger as below:

amplify/storage/resource.ts
import { defineFunction, defineStorage } from "@aws-amplify/backend";

export const storage = defineStorage({
  name: 'myProjectFiles',
  triggers: {
    onUpload: defineFunction({
      entry: './on-upload-handler.ts'
      resourceGroupName: 'storage',
    })
  }
});
Next, create a file named amplify/storage/on-upload-handler.ts and use the following code to log the object keys whenever an object is uploaded to the bucket. You can add your custom logic to this function as needed.

amplify/storage/on-upload-handler.ts
import type { S3Handler } from 'aws-lambda';

export const handler: S3Handler = async (event) => {
  const objectKeys = event.Records.map((record) => record.s3.object.key);
  console.log(`Upload handler invoked for objects [${objectKeys.join(', ')}]`);
};
Now, when you deploy your backend, this function will be invoked whenever an object is uploaded to the bucket.

- Custom Auth Challenge -
Secure Remote Password (SRP) is a cryptographic protocol enabling password-based authentication without transmitting the password over the network. In Amazon Cognito custom authentication flows, CUSTOM_WITH_SRP incorporates SRP steps for enhanced security, while CUSTOM_WITHOUT_SRP bypasses these for a simpler process. The choice between them depends on your application's security needs and performance requirements. This guide demonstrates how to implement both types of custom authentication flows using AWS Amplify with Lambda triggers.

You can use defineAuth and defineFunction to create an auth experience that uses CUSTOM_WITH_SRP and CUSTOM_WITHOUT_SRP. This can be accomplished by leveraging Amazon Cognito's feature to define a custom auth challenge and 3 triggers:

Create auth challenge
Define auth challenge
Verify auth challenge response
To get started, install the aws-lambda package, which is used to define the handler type.

Terminal
npm add --save-dev @types/aws-lambda
Create auth challenge trigger
To get started, create the first of the three triggers, create-auth-challenge. This is the trigger responsible for creating the reCAPTCHA challenge after a password is verified.

amplify/auth/create-auth-challenge/resource.ts
import { defineFunction } from "@aws-amplify/backend"

export const createAuthChallenge = defineFunction({
  name: "create-auth-challenge",
  resourceGroupName: 'auth'
})
After creating the resource file, create the handler with the following contents:

amplify/auth/create-auth-challenge/handler.ts
import type { CreateAuthChallengeTriggerHandler } from "aws-lambda";

export const handler: CreateAuthChallengeTriggerHandler = async (event) => {
  if (event.request.challengeName === "CUSTOM_CHALLENGE") {
    // Generate a random code for the custom challenge
    const challengeCode = "123456";

    event.response.challengeMetadata = "TOKEN_CHECK";

    event.response.publicChallengeParameters = {
      trigger: "true",
      code: challengeCode,
    };

    event.response.privateChallengeParameters = { trigger: "true" };
    event.response.privateChallengeParameters.answer = challengeCode;
  }
  return event;
};
Define auth challenge trigger
Next, you will want to create the trigger responsible for defining the auth challenge flow, define-auth-challenge.

amplify/auth/define-auth-challenge/resource.ts
import { defineFunction } from "@aws-amplify/backend"

export const defineAuthChallenge = defineFunction({
  name: "define-auth-challenge",
  resourceGroupName: 'auth'
})
After creating the resource file, create the handler with the following contents if you are using CUSTOM_WITHOUT_SRP:

amplify/auth/define-auth-challenge/handler.ts
import type { DefineAuthChallengeTriggerHandler } from "aws-lambda"

export const handler: DefineAuthChallengeTriggerHandler = async (event) => {
  // Check if this is the first authentication attempt
  if (event.request.session.length === 0) {
    // For the first attempt, we start with the custom challenge
    event.response.issueTokens = false;
    event.response.failAuthentication = false;
    event.response.challengeName = "CUSTOM_CHALLENGE";
  } else if (
    event.request.session.length === 1 &&
    event.request.session[0].challengeName === "CUSTOM_CHALLENGE" &&
    event.request.session[0].challengeResult === true
  ) {
    // If this is the second attempt (session length 1),
    // it was a CUSTOM_CHALLENGE, and the result was successful
    event.response.issueTokens = true;
    event.response.failAuthentication = false;
  } else {
    // If we reach here, it means either:
    // 1. The custom challenge failed
    // 2. We've gone through more attempts than expected
    // In either case, we fail the authentication
    event.response.issueTokens = false;
    event.response.failAuthentication = true;
  }

  return event;
};
Or if you are using CUSTOM_WITH_SRP:

amplify/auth/define-auth-challenge/handler.ts
import type { DefineAuthChallengeTriggerHandler } from "aws-lambda"

export const handler: DefineAuthChallengeTriggerHandler = async (event) => {
  // First attempt: Start with SRP_A (Secure Remote Password protocol, step A)
  if (event.request.session.length === 0) {
    event.response.issueTokens = false;
    event.response.failAuthentication = false;
    event.response.challengeName = "SRP_A";
  } else if (
    event.request.session.length === 1 &&
    event.request.session[0].challengeName === "SRP_A" &&
    event.request.session[0].challengeResult === true
  ) {
    // Second attempt: SRP_A was successful, move to PASSWORD_VERIFIER
    event.response.issueTokens = false;
    event.response.failAuthentication = false;
    event.response.challengeName = "PASSWORD_VERIFIER";
  } else if (
    event.request.session.length === 2 &&
    event.request.session[1].challengeName === "PASSWORD_VERIFIER" &&
    event.request.session[1].challengeResult === true
  ) {
    // Third attempt: PASSWORD_VERIFIER was successful, move to CUSTOM_CHALLENGE
    event.response.issueTokens = false;
    event.response.failAuthentication = false;
    event.response.challengeName = "CUSTOM_CHALLENGE";
  } else if (
    event.request.session.length === 3 &&
    event.request.session[2].challengeName === "CUSTOM_CHALLENGE" &&
    event.request.session[2].challengeResult === true
  ) {
    // Fourth attempt: CUSTOM_CHALLENGE was successful, authentication complete
    event.response.issueTokens = true;
    event.response.failAuthentication = false;
  } else {
    // If we reach here, it means one of the challenges failed or
    // we've gone through more attempts than expected
    event.response.issueTokens = false;
    event.response.failAuthentication = true;
  }

  return event;
};
Verify auth challenge response trigger
Lastly, create the trigger responsible for verifying the challenge response. For the purpose of this example, the verification check will always return true.

amplify/auth/verify-auth-challenge-response/resource.ts
import { defineFunction, secret } from "@aws-amplify/backend"

export const verifyAuthChallengeResponse = defineFunction({
  name: "verify-auth-challenge-response",
  resourceGroupName: 'auth'
})
After creating the resource file, create the handler with the following contents:

amplify/auth/verify-auth-challenge-response/handler.ts
import type { VerifyAuthChallengeResponseTriggerHandler } from "aws-lambda"

export const handler: VerifyAuthChallengeResponseTriggerHandler = async (
  event
) => {
  event.response.answerCorrect = true;
  return event;
};
Configure auth resource
Finally, import and set the three triggers on your auth resource:

amplify/auth/resource.ts
import { defineAuth } from "@aws-amplify/backend"
import { createAuthChallenge } from "./create-auth-challenge/resource"
import { defineAuthChallenge } from "./define-auth-challenge/resource"
import { verifyAuthChallengeResponse } from "./verify-auth-challenge-response/resource"

/**
 * Define and configure your auth resource
 * @see https://docs.amplify.aws/gen2/build-a-backend/auth
 */
export const auth = defineAuth({
  loginWith: {
    email: true,
  },
  triggers: {
    createAuthChallenge,
    defineAuthChallenge,
    verifyAuthChallengeResponse,
  },
})
After deploying the changes, whenever a user attempts to sign in with CUSTOM_WITH_SRP or CUSTOM_WITHOUT_SRP, the Lambda challenges will be triggered.

- Modify Amplify-generated Lambda resources with CDK -
Amplify Functions utilize the NodejsFunction construct from the AWS Cloud Development Kit (CDK). The underlying resources can be modified, overridden, or extended using CDK after setting the resource on your backend.

amplify/backend.ts
import { defineBackend } from '@aws-amplify/backend';
import { myFunction } from './functions/my-function';

const backend = defineBackend({
  myFunction
})

// CDK constructs can be accessed via
backend.myFunction.resources

// where the Lambda function can be found on
backend.myFunction.resources.lambda
The Lambda resource available is a representation of IFunction.

Adding IAM Policies
To learn how to add IAM policies to a Function's execution role, visit the documentation for granting access to other resources.

- Custom functions - 
AWS Amplify Gen 2 functions are AWS Lambda functions that can be used to perform tasks and customize workflows in your Amplify app. Functions can be written in Node.js, Python, Go, or any other language supported by AWS Lambda.

Note: Fullstack Git-based environments do not support Docker for functions bundling out of the box. To learn more skip to the Docker section.

Note: The following options in defineFunction are not supported for Custom Functions:

Environment variables and secrets
Scheduling configuration
Lambda layers
Function options
You'll need to configure these options directly in your CDK Function definition instead. However, resourceGroupName property is supported and can be used to group related resources together in your defineFunction definition.

In this guide, you will learn how to create Python and Go functions with Amplify functions. The examples shown in this guide do not use Docker to build functions. Instead, the examples use commands that run on your host system to build, and as such require the necessary tooling for the language you are using for your functions.

Python
To get started, create a new directory and a resource file, amplify/functions/say-hello/resource.ts. Then, define the function with defineFunction:

amplify/functions/say-hello/resource.ts
import { execSync } from "node:child_process";
import * as path from "node:path";
import { fileURLToPath } from "node:url";
import { defineFunction } from "@aws-amplify/backend";
import { DockerImage, Duration } from "aws-cdk-lib";
import { Code, Function, Runtime } from "aws-cdk-lib/aws-lambda";

const functionDir = path.dirname(fileURLToPath(import.meta.url));

export const sayHelloFunctionHandler = defineFunction(
  (scope) =>
    new Function(scope, "say-hello", {
      handler: "index.handler",
      runtime: Runtime.PYTHON_3_9, // or any other python version
      timeout: Duration.seconds(20), //  default is 3 seconds
      code: Code.fromAsset(functionDir, {
        bundling: {
          image: DockerImage.fromRegistry("dummy"), // replace with desired image from AWS ECR Public Gallery
          local: {
            tryBundle(outputDir: string) {
              execSync(
                `python3 -m pip install -r ${path.join(functionDir, "requirements.txt")} -t ${path.join(outputDir)} --platform manylinux2014_x86_64 --only-binary=:all:`
              );
              execSync(`cp -r ${functionDir}/* ${path.join(outputDir)}`);
              return true;
            },
          },
        },
      }),
    }),
    {
      resourceGroupName: "auth" // Optional: Groups this function with auth resource
    }
);
Next, create the corresponding handler file at amplify/functions/say-hello/index.py. This is where your function code will go.

amplify/functions/say-hello/index.py
import json

def handler(event, context):
  return {
      "statusCode": 200,
      "body": json.dumps({
          "message": "Hello World",
      }),
  }
The handler file must export a function named "handler". This is the entry point to your function. For more information on writing functions, refer to the AWS documentation for Lambda function handlers using Python.

If you need Python packages, you can add them to a requirements.txt file in the same directory as your handler file. The bundling option in the Code.fromAsset method will install these packages for you. Create a requirements.txt file in the same directory as your handler file. This file should contain the names of the packages you want to install. For example:

amplify/functions/say-hello/requirements.txt
request==2.25.1
some-other-package>=1.0.0
You're now ready to deploy your python function. Next is the same process as the Node.js/TypeScript function. Go to Common steps for all languages to continue.

Go
To get started, Create a new directory and a resource file, amplify/functions/say-hello/resource.ts. Then, define the function with defineFunction:

amplify/functions/say-hello/resource.ts
import { execSync } from "node:child_process";
import * as path from "node:path";
import { fileURLToPath } from "node:url";
import { defineFunction } from "@aws-amplify/backend";
import { DockerImage, Duration } from "aws-cdk-lib";
import { Code, Function, Runtime } from "aws-cdk-lib/aws-lambda";

const functionDir = path.dirname(fileURLToPath(import.meta.url));

export const sayHelloFunctionHandler = defineFunction(
  (scope) =>
    new Function(scope, "say-hello", {
      handler: "bootstrap",
      runtime: Runtime.PROVIDED_AL2023,
      timeout: Duration.seconds(3), //  default is 3 seconds
      code: Code.fromAsset(functionDir, {
        bundling: {
          image: DockerImage.fromRegistry("dummy"),
          local: {
            tryBundle(outputDir: string) {
              execSync(`rsync -rLv ${functionDir}/* ${path.join(outputDir)}`);
              execSync(
                `cd ${path.join(outputDir)} && GOARCH=amd64 GOOS=linux go build -tags lambda.norpc -o ${path.join(outputDir)}/bootstrap ${functionDir}/main.go`
              );
              return true;
            },
          },
        },
      }),
    }),
    {
      resourceGroupName: "auth" // Optional: Groups this function with auth resource
    }
);
Next, create the corresponding handler file at amplify/functions/say-hello/main.go. This is where your function code will go.

amplify/functions/say-hello/main.go
package main

import (
	"context"
	"fmt"

	"github.com/aws/aws-lambda-go/lambda"
)

type Event struct {
	Arguments Arguments `json:"arguments"`
}

type Arguments struct {
	Title string `json:"phone"`
	Msg   string `json:"msg"`
}

func HandleRequest(ctx context.Context, event Event) (string, error) {
	fmt.Println("Received event: ", event)

	// fmt.Println("Message sent to: ", event.Arguments.Msg)
	// You can use lambda arguments in your code

	return "Hello World!", nil
}

func main() {
	lambda.Start(HandleRequest)
}
Then you should run the following command to build the go function:

terminal
go mod init lambda
then run to install the dependencies.

terminal
go mod tidy
You're now ready to deploy your golang function. Next is the same process as the Node.js/TypeScript function.

Common steps for all languages
Regardless of the language used, your function needs to be added to your backend.

amplify/backend.ts
import { sayHelloFunctionHandler } from './functions/say-hello/resource';

defineBackend({
  sayHelloFunctionHandler,
});
Now when you run npx ampx sandbox or deploy your app on Amplify, it will include your function.

To invoke your function, we recommend adding your function as a handler for a custom query with your Amplify Data resource. To get started, open your amplify/data/resource.ts file and specify a new query in your schema:

amplify/data/resource.ts
import { sayHelloFunctionHandler } from "../functions/say-hello/resource"

const schema = a.schema({
  sayHello: a
    .query()
    .arguments({
      name: a.string(),
    })
    .returns(a.string())
    .handler(a.handler.function(sayHelloFunctionHandler)),
})

export type Schema = ClientSchema<typeof schema>

export const data = defineData({
  schema,
  authorizationModes: {
    defaultAuthorizationMode: "iam",
  },
})
Docker
Custom function may require Docker in order to build and bundle function's code. A deployment failing with CustomFunctionProviderDockerError error indicates that a custom function requires Docker but the Docker daemon was not found. In that case you need to provide a working Docker installation at runtime.

Personal sandboxes
Ensure that Docker is installed on your computer and that Docker daemon is running. You can check if Docker daemon is running using the following command:

terminal
docker info
Fullstack Git-based environments
Amplify does not provide Docker daemon out of the box in branch deployments. However, you have an option to provide your own image that meets Amplify requirements and includes a Docker installation.

For example, the aws/codebuild/amazonlinux-x86_64-standard:5.0 image (see definition) meets Amplify requirements and includes Docker installation.

- Server-Side Rendering - 
This guide walks through how to use Amplify Auth and Data APIs from Next.js server-side runtimes.

Install the Amplify Next.js adapter
Note: Amplify JS v6 supports Next.js with the version range: >=13.5.0 <16.0.0. Ensure you have the correct version to integrate with Amplify.

To use Amplify APIs server-side, you need to install the Amplify Next.js adapter in addition to the Amplify libraries:

Terminal
npm add aws-amplify @aws-amplify/adapter-nextjs
Configure Amplify in Next.js
Configure Amplify for server-side usage
Configure Amplify for client-side usage
You will need to create a runWithAmplifyServerContext function to use Amplify APIs on the server-side of your Next.js app.

You can create an amplifyServerUtils.ts file under a utils folder in your codebase. In this file, you will import the Amplify backend outputs from the amplify_outputs.json file that is generated by the Amplify CLI, and use the createServerRunner function to create the runWithAmplifyServerContext function.

For example, the utils/amplifyServerUtils.ts file may contain the following content:

src/utils/amplifyServerUtils.ts
import { createServerRunner } from '@aws-amplify/adapter-nextjs';
import outputs from '@/amplify_outputs.json';

export const { runWithAmplifyServerContext } = createServerRunner({
  config: outputs
});
You can use the exported runWithAmplifyServerContext function to call Amplify APIs within isolated request contexts. You can review examples under the Calling Amplify category APIs on the server side section.

Tip: You only need to call the createServerRunner function once and reuse the runWithAmplifyServerContext function throughout.

Authentication with Next.js server-side runtime
(Experimental) Perform authentication on the server side and enable HttpOnly cookies
Warning: This feature is experimental and may change in future releases.

Once you enable the server-side sign-in feature, auth tokens are stored in HttpOnly cookies and you may not change the HttpOnly attribute. Since these cookies are inaccessible from client-side scripts, you wont be able to use any Amplify JS APIs on the client side. Therefore, you dont need to configure Amplify on the client side. You can keep using these Amplify JS server-side APIs on the server side.

Additional setup is required to enable server-side authentication flows in your Next.js app.

Step 1 - Specify the origin of your app in environment variables
Add the following environment variable to your Next.js app. For example in a .env file:

.env
AMPLIFY_APP_ORIGIN=https://myapp.com
Ensure this environment variable is accessible in your Next.js app's server runtime.

Note: Token cookies are transmitted via server-side authentication flows. In production environments, it is recommended to use HTTPS as the origin for enhanced security.

Step 2 - Export the createAuthRouteHandlers function
The createAuthRouteHandlers function is created by the createServerRunner function call when you configure Amplify for server-side usage. You can export this function from your amplifyServerUtils.ts file. You can also configure cookie attributes with the runtimeOptions parameter.

src/utils/amplifyServerUtils.ts
import { createServerRunner } from '@aws-amplify/adapter-nextjs';
import outputs from '@/amplify_outputs.json';

export const {
  runWithAmplifyServerContext,
  createAuthRouteHandlers,
} = createServerRunner({
  config: outputs,
  runtimeOptions: {
    cookies: {
      domain: '.myapp.com', // making cookies available to all subdomains
      sameSite: 'strict',
      maxAge: 60 * 60 * 24 * 7 // 7 days
    }
  }
});
Step 3 - Set up the Auth API routes
Create an API route using the createAuthRouteHandlers function. For example:

App router
Pages router
src/app/api/auth/[slug]/route.ts
import { createAuthRouteHandlers } from "@/utils/amplifyServerUtils";

export const GET = createAuthRouteHandlers({
  redirectOnSignInComplete: "/home",
  redirectOnSignOutComplete: "/sign-in",
});
With the above example, Amplify generates the following API routes:

API Routes	What it does
/api/auth/sign-up	Upon navigating an end user to this route, theyll be redirected to the Amazon Cognito Managed Login sign-up form. After sign-up and sign-in, theyll be redirected back to the route /api/auth/sign-in-callback.
/api/auth/sign-in	Upon navigating an end user to this route, theyll be redirected to the Amazon Cognito Managed Login sign-in form. After sign-in, theyll be redirected back to the route /api/auth/sign-in-callback.
/api/auth/sign-in?provider=<social-provider-name>	Upon navigating an end user to this route, theyll be redirected first to the Amazon Cognito Managed Login and then the specified social provider sign-in page. After sign-in, theyll be redirected back to the route /api/auth/sign-in-callback.
/api/auth/sign-out	Upon navigating an end user to this route, the end user will be signed out and redirected to the route /api/auth/sign-out-callback.
/api/auth/sign-in-callback	Amazon Cognito Managed Login redirects an end user back to this route after signing in. Amplify exchanges auth tokens and stores them as HttpOnly cookies in the browser cookie store, then redirects the end user back to the route specified by the redirectOnSignInComplete parameter.
/api/auth/sign-out-callback	Amazon Cognito Managed Login redirects an end user back to this route after signing out, Amplify revokes access token and refresh token and removes token cookies from browser cookie store, then redirects the end user back to the route specified by the redirectOnSignOutComplete parameter.
Note: A signing-out call involves multiple steps, including signing out from Amazon Cognito Managed Login, revoking tokens, and removing cookies. If the user closes the browser during the process, the following may occur:

auth token have not been revoked - user remains signed in
auth token have been revoked but cookies have not been removed - cookies will be removed when the user visits the app again
Step 4 - Provide the redirect URLs to the Auth Resource in Amplify
You can provide the callback API routes as the redirect URLs in the Auth resource configuration. For example:

amplify/auth/resource.ts
export const auth = defineAuth({
  loginWith: {
    email: true,
    externalProviders: {
      callbackUrls: ["https://myapp.com/api/auth/sign-in-callback"],
      logoutUrls: ["https://myapp.com/api/auth/sign-out-callback"],
    },
  },
});
This enables Amazon Cognito Hosted UI to support the server-side authentication flows. You may upgrade to the latest Amazon Cognito Managed Login Branding to customize the sign-in and sign-up pages. See Amazon Cognito user pool managed login for more information.

Step 5 - Use Anchor link for initiating server-side authentication flows
Use HTML anchor links to navigate users to the sign-in and sign-up routes. For example:

Sign in button
Sign in with Google button
Sign up button
Sign out button
src/components/SignInButton.tsx
export default function SignInButton() {
  return (
    <a href="/api/auth/sign-in">
      Sign In
    </a>
  );
}
When an end user clicks on the buttons above, a corresponding server-side authentication flow will be initiated.

Validate user session with the Next.js Middleware
You can use the fetchAuthSession API to check the auth sessions that are attached to the incoming requests in the middleware of your Next.js app to protect your routes. For example:

src/middleware.ts
import { fetchAuthSession } from 'aws-amplify/auth/server';
import { NextRequest, NextResponse } from 'next/server';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';

export async function middleware(request: NextRequest) {
  const response = NextResponse.next();

  const authenticated = await runWithAmplifyServerContext({
    nextServerContext: { request, response },
    operation: async (contextSpec) => {
      try {
        const session = await fetchAuthSession(contextSpec);
        return (
          session.tokens?.accessToken !== undefined &&
          session.tokens?.idToken !== undefined
        );
      } catch (error) {
        console.log(error);
        return false;
      }
    }
  });

  if (authenticated) {
    return response;
  }

  return NextResponse.redirect(new URL('/sign-in', request.url));
}

export const config = {
  matcher: [
    /*
     * Match all request paths except for the ones starting with:
     * - api (API routes)
     * - _next/static (static files)
     * - _next/image (image optimization files)
     * - favicon.ico (favicon file)
     */
    '/((?!api|_next/static|_next/image|favicon.ico|sign-in).*)'
  ]
};
In this example, if the incoming request is not associated with a valid user session the request will be redirected to the /sign-in route.

Note: When calling fetchAuthSession with a response context, it will send the refreshed tokens (if any) back to the client via the Set-Cookie header in the response.

Calling Amplify category APIs on the server side
For the Auth categories to use Amplify APIs on the server in your Next.js app, you will need to:

Import the API from the /server sub path.
Use the runWithAmplifyServerContext helper function created by calling the createServerRunner function exported from @aws-amplify/adapter-nextjs to call the Amplify API in an isolated server context.
For the GraphQL API category, review Connect to data from Server-side Runtimes.

Note: A subset of Amplify APIs can now be called on the server side of a Next.js app. These APIs are exported from the /server sub paths. See the full list of supported APIs.

Note: If you use the Amplify server-side APIs in a server action and encounter the following error running next build:

./node_modules/@aws-amplify/core/node_modules/@aws-crypto/sha256-js/build/module/index.js + 12 modules

Cannot get final name for export 'fromUtf8' of ./node_modules/@smithy/util-utf8/dist-es/index.js

You can add the following to your next.config.js:

next.config.js
/** @type {import('next').NextConfig} */
const nextConfig = {
    serverComponentsPackages: ['@aws-crypto'],
};
See Next.js documentation on serverComponentsPackages for more details.

With Next.js App Router
Dynamic rendering in React server component
Dynamic rendering is based on a user session extracted from an incoming request.

import { cookies } from 'next/headers';
import { getCurrentUser } from 'aws-amplify/auth/server';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';

// This page always dynamically renders per request
export const dynamic = 'force-dynamic';

export default async function AuthGetCurrentUserServer() {
  try {
    const currentUser = await runWithAmplifyServerContext({
      nextServerContext: { cookies },
      operation: (contextSpec) => getCurrentUser(contextSpec)
    });

    return (
      <p>{`Hello, ${currentUser.username}`}</p>
    );
  } catch (error) {
    console.error(error);
    return <p>Something went wrong...</p>;
  }
}
Static rendering in React server component
Static rendering does not require a user session, so you can specify the nextServerContext parameter as null. This is useful for some use cases; for example, when you are using the Storage API with guest access (if you have enabled it in your backend).

import { getUrl } from 'aws-amplify/storage/server';
import Image from 'next/image';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';

// Re-render this page every 60 minutes
export const revalidate = 60 * 60; // in seconds

export default async function StaticallyRenderedPage() {
  try {
    const splashUrl = await runWithAmplifyServerContext({
      nextServerContext: null,
      operation: (contextSpec) =>
        getUrl(contextSpec, {
          key: 'splash.png'
        })
    });

    return (
      <Image
        src={splashUrl.url.toString()}
        alt="Splash Image"
        width={500}
        height={500}
      />
    );
  } catch (error) {
    console.error(error);
    return <p>Something went wrong...</p>;
  }
}
Note: The URL returned by the getUrl API expires in the above example. You may want to specify the revalidate parameter to rerender the page as required to ensure the URL gets regenerated.

In Route Handlers
In route handlers require implementing an API route that enables GET /apis/get-current-user.

import { getCurrentUser } from 'aws-amplify/auth/server';
import { cookies } from 'next/headers';
import { NextResponse } from 'next/server';
import { runWithAmplifyServerContext } from '@/utils/amplifyServerUtils';

export async function GET() {
  const user = await runWithAmplifyServerContext({
    nextServerContext: { cookies },
    operation: (contextSpec) => getCurrentUser(contextSpec)
  });

  return NextResponse.json({ user });
}
When you call fetch('/apis/get-current-user') it returns a payload that contains the user data for the current signed-in user.

With Next.js Pages Router
In getServerSideProps
The following example extracts current user data from the request and provides them to a page react component via its props.

export const getServerSideProps: GetServerSideProps = async ({ req, res }) => {
  const currentUser = await runWithAmplifyServerContext({
    nextServerContext: { request: req, response: res },
    operation: (contextSpec) => getCurrentUser(contextSpec)
  });

  return { props: { currentUser } };
};
In getStaticProps
Similar to static rendering with the App Router, you can pass null as the value of the nextServerContext parameter to use the Amplify Storage API with guest access.

export async function getStaticProps() {
  const splashUrl = await runWithAmplifyServerContext({
    nextServerContext: null,
    operation: (contextSpec) => getUrl(contextSpec, { key: 'splash.png' })
  });

  return {
    props: { imageUrl: splashUrl.url.toString() },
    revalidate: (splashUrl.expiresAt.getTime() - Date.now()) / 1000 // in seconds
  };
}
Supported APIs for Next.js server-side usage
All APIs that support use on the server are exported from the aws-amplify/<category>/server sub paths. You must use these APIs for any server-side use cases.

Category    APIs	Server (Node.js) Amplify Hosting/Vercel    Vercel Edge Runtime (middleware)
Auth	fetchAuthSession		
Auth	fetchUserAttributes		
Auth	getCurrentUser		
Data	generateServerClientUsingCookies		
Data	generateServerClientUsingReqRes		
Storage	getUrl		
Storage	getProperties		
Storage	list		
Storage	remove		
Storage	copy		
Have a server-side use case that isn't currently supported in Amplify JS? Consider using the AWS SDK for JavaScript.

- Set up Amplify Analytics - 
Amplify enables you to collect analytics data for your app. In order to use Analytics, you will enable Amazon Kinesis or Amazon Pinpoint using the AWS Cloud Development Kit (AWS CDK). The Analytics category uses Amazon Cognito identity pools to identify users in your app. Cognito allows you to receive data from authenticated, and unauthenticated users in your app.

Set up Analytics backend
Use the AWS CDK to create an analytics resource powered by Amazon Pinpoint.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { CfnApp } from "aws-cdk-lib/aws-pinpoint";
import { Stack } from "aws-cdk-lib/core";

const backend = defineBackend({
  auth,
  data,
  // additional resources
});

const analyticsStack = backend.createStack("analytics-stack");

// create a Pinpoint app
const pinpoint = new CfnApp(analyticsStack, "Pinpoint", {
  name: "myPinpointApp",
});

// create an IAM policy to allow interacting with Pinpoint
const pinpointPolicy = new Policy(analyticsStack, "PinpointPolicy", {
  policyName: "PinpointPolicy",
  statements: [
    new PolicyStatement({
      actions: ["mobiletargeting:UpdateEndpoint", "mobiletargeting:PutEvents"],
      resources: [pinpoint.attrArn + "/*"],
    }),
  ],
});

// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);

// patch the custom Pinpoint resource to the expected output configuration
backend.addOutput({
  analytics: {
    amazon_pinpoint: {
      app_id: pinpoint.ref,
      aws_region: Stack.of(pinpoint).region,
    }
  },
});
Install Amplify Libraries
First, install the aws-amplify library:

Terminal
npm add aws-amplify
Initialize Amplify Analytics
Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point.

src/index.js
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
Next Steps:

Congratulations! Now that you have Analytics' backend provisioned and Analytics library installed. Check out the following links to see Amplify Analytics use cases:

Record Events
Track Sessions
Identify User
References
Amazon Pinpoint Construct Library

Known Issues
You may encounter the following error when starting the bundler when using Amazon Kinesis (aws-amplify/analytics/kinesis), Amazon Kinesis Data Firehose (aws-amplify/analytics/kinesis-firehose), Personalize Event (aws-amplify/analytics/personalize):

Error: Unable to resolve module stream from /path/to/node_modules/@aws-sdk/... This is a known issue. Please follow the steps outlined in the issue to resolve the error.

- Record events - 
Recording Custom Events
To record custom events call the record API:

src/index.js
import { record } from 'aws-amplify/analytics';

record({
  name: 'albumVisit',
});
Analytics events are buffered in memory and periodically sent to the service and not saved locally between application sessions. If the session is ended before a buffered event is sent, it will be lost. Use the flushEvents API to manually send buffered events to the service.

Record a Custom Event with Attributes
The record API lets you add additional attributes to an event. For example, to record artist information with an albumVisit event:

src/index.js
import { record } from 'aws-amplify/analytics';

record({
  name: 'albumVisit',
  attributes: { genre: '', artist: '' },
});
Recorded events will be buffered and periodically sent to Amazon Pinpoint.

Record Engagement Metrics
Metrics can also be added to an event:

src/index.js
import { record } from 'aws-amplify/analytics';

record({
  name: 'albumVisit',
  metrics: { minutesListened: 30 },
});
Metric values must be a Number type such as a float or integer.

The Amazon Pinpoint event count updates in minutes after recording your event.

However, it can take upwards of 30 minutes for the event to display in the Filter section, and for its custom attributes to appear in Amazon Pinpoint.

Flush events
The recorded events are saved in a buffer and sent to the remote server periodically. If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

src/index.js
import { flushEvents } from 'aws-amplify/analytics';

flushEvents();

- Identify user - 
This API sends information about the current user to Amazon Pinpoint.

Additional information such as the user's name, email, location, and device can be included by specifying the UserProfile. Custom attributes can also be included by setting UserProfile.customProperties.

If the user was signed in through signIn you can retrieve the current user's ID as shown below:

src/index.js
import { identifyUser } from 'aws-amplify/analytics';
import { getCurrentUser } from 'aws-amplify/auth';

const location = {
  latitude: 47.606209,
  longitude: -122.332069,
  postalCode: '98122',
  city: 'Seattle',
  region: 'WA',
  country: 'USA'
};

const customProperties = {
  plan: ['plan'],
  phoneNumber: ['+11234567890'],
  age: ['25']
};

const userProfile = {
  location,
  name: 'username',
  email: 'name@example.com',
  customProperties
};

async function sendUserData() {
  const user = await getCurrentUser();

  identifyUser({
    userId: user.userId,
    userProfile
  });
}
Sending user information allows you to associate a user to their user profile and activities or actions in your app. The user's actions and attributes can also tracked across devices and platforms by using the same userId.

Some scenarios for identifying a user and their associated app activities are:

When a user completes app sign up
When a user completes sign in process
When a user launches your app
When a user modifies or updates their user profile

- Automatically track sessions - 
Analytics auto tracking helps you to automatically track user behaviors like sessions' start/stop, page view change and web events like clicking or mouseover.

Session Tracking
You can track the session both in a web app or a React Native app by using Analytics. A web session can be defined in different ways. To keep it simple, we define a web session as being active when the page is not hidden and inactive when the page is hidden. A session in a React Native app is active when the app is in the foreground and inactive when the app is in the background.

For example:

src/index.js
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  // REQUIRED, turn on/off the auto tracking
  enable: true,
  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'
  type: 'session',
  // OPTIONAL, additional options for the tracked event.
  options: {
    // OPTIONAL, the attributes of the event
    attributes: {
      customizableField: 'attr'
    }
  }
});
By default, when the page/app transitions to the foreground, the Analytics module will send an event to the Amazon Pinpoint Service.

{
  "eventType": "_session_start",
  "attributes": {
    "customizableField": "attr"
  }
}
This behavior can be disabled by calling configureAutoTrack:

src/index.js
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  enable: false,
  type: 'session'
});
Page View Tracking
Use this feature to track the most frequently viewed page/url in your webapp. It automatically sends events containing url information when a page is visited.

This behavior can be enabled by calling configureAutoTrack:

src/index.js
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  // REQUIRED, turn on/off the auto tracking
  enable: true,
  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'
  type: 'pageView',
  // OPTIONAL, additional options for the tracked event.
  options: {
    // OPTIONAL, the attributes of the event
    attributes: {
      customizableField: 'attr'
    },

    // OPTIONAL, the event name. By default, this is 'pageView'
    eventName: 'pageView',

    // OPTIONAL, the type of app under tracking. By default, this is 'multiPageApp'.
    // You will need to change it to 'singlePage' if your app is a single-page app like React
    appType: 'multiPageApp',

    // OPTIONAL, provide the URL for the event.
    urlProvider:  () => {
      // the default function
      return window.location.origin + window.location.pathname;
    }
  }
});
This behavior can be disabled by calling configureAutoTrack:

src/index.js
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  enable: false,
  type: 'pageView'
});
Page Event Tracking
Use page event tracking to track user interactions with specific elements on a page. Attach the specified selectors to your DOM element and turn on the auto tracking.

This behavior can be enabled by calling configureAutoTrack:

src/index.js
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  // REQUIRED, turn on/off the auto tracking
  enable: true,
  // REQUIRED, the event type, it's one of 'event', 'pageView' or 'session'
  type: 'event',
  // OPTIONAL, additional options for the tracked event.
  options: {
    // OPTIONAL, the attributes of the event
    attributes: {
      customizableField: 'attr'
    },
    // OPTIONAL, events you want to track. By default, this is 'click'
    events: ['click'],

    // OPTIONAL, the prefix of the selectors. By default, this is 'data-amplify-analytics-'
    // Per https://www.w3schools.com/tags/att_global_data.asp, always start
    // the prefix with 'data' to avoid collisions with the user agent
    selectorPrefix: 'data-amplify-analytics-'
  }
});
For example:

<!-- you want to track this button and send an event when it is clicked -->
<button
  data-amplify-analytics-on="click"
  data-amplify-analytics-name="click"
  data-amplify-analytics-attrs="attr1:attr1_value,attr2:attr2_value"
/>
When the button above is clicked, an event will be sent automatically. This is equivalent to doing:

<script>
  import { record } from 'aws-amplify/analytics';
  var sendEvent = function() {
    record({
      name: 'click',
      attributes: {
        attr: 'attr', // the default ones
        attr1: attr1_value, // defined in the button component
        attr2: attr2_value // defined in the button component
      }
    });
  };
</script>
<button onclick="sendEvent()" />
This behavior can be disabled by calling configureAutoTrack:

src/index.js
import { configureAutoTrack } from 'aws-amplify/analytics';

configureAutoTrack({
  enable: false,
  type: 'event'
});
Note: Amplify doesn't capture location automatically. Instead, you can add the location information in the default config when you configure Analytics or while updating the end point.

- Enable and disable analytics - 
Disable Analytics
Analytics are enabled by default when you configure it in your app. To disable Analytics in your app use the disable function:

src/index.js
import { disable } from 'aws-amplify/analytics';

disable();
Enable Analytics
To enable analytics you can use the enable function in your app:

src/index.js
import { enable } from 'aws-amplify/analytics';

enable();

- Streaming analytics data - 
The Amazon Kinesis analytics provider allows you to send analytics data to an Kinesis stream for real-time processing.

Setup Kinesis stream
The following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Kinesis.

amplify/backend.ts
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { Stream } from "aws-cdk-lib/aws-kinesis";
import { Stack } from "aws-cdk-lib/core";

const backend = defineBackend({
  auth, 
  data,
  // additional resources 
});

// create a new stack for the Kinesis stream
const kinesisStack = backend.createStack("kinesis-stack");

// create a new Kinesis stream with one shard
const kinesisStream = new Stream(kinesisStack, "KinesisStream", {
  streamName: "myKinesisStream",
  shardCount: 1,
});

// create a new policy to allow PutRecords to the Kinesis stream
const kinesisPolicy = new Policy(kinesisStack, "KinesisPolicy", {
  statements: [
    new PolicyStatement({
      actions: ["kinesis:PutRecords"],
      resources: [kinesisStream.streamArn],
    }),
  ],
});

// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(kinesisPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(kinesisPolicy);
Installation and Configuration
If you did not use the CLI, ensure you have setup IAM permissions for kinesis:PutRecords.

Example IAM policy for Amazon Kinesis:

{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "kinesis:PutRecords",
    "Resource": "arn:aws:kinesis:<your-aws-region>:<your-aws-account-id>:stream/<your-stream-name>" // replace the template fields
  }]
}
For more information visit the Amazon Kinesis Developer Documentation.

Configure Kinesis:

src/index.js
// Configure the plugin after adding it to the Analytics module
import { Amplify } from 'aws-amplify';
import { parseAmplifyConfig } from "aws-amplify/utils";
import outputs from '../amplify_outputs.json';

const amplifyConfig = parseAmplifyConfig(outputs);

Amplify.configure({
  ...amplifyConfig,
  Analytics: {
    Kinesis: {
      // REQUIRED -  Amazon Kinesis service region
      region: 'us-east-1',

      // OPTIONAL - The buffer size for events in number of items.
      bufferSize: 1000,

      // OPTIONAL - The number of events to be deleted from the buffer when flushed.
      flushSize: 100,

      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000, // 5s

      // OPTIONAL - The limit for failed recording retries.
      resendLimit: 5
    }
  }
});
Stream data
You can send a data to a Kinesis stream with the standard record() method:

src/index.js
import { record } from 'aws-amplify/analytics/kinesis';

record({
  data: {
    // The data blob to put into the record
  },
  partitionKey: 'myPartitionKey',
  streamName: 'myKinesisStream'
});
Flush events
The recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

src/index.js
import { flushEvents } from 'aws-amplify/analytics/kinesis';

flushEvents();
Known Issues
When importing alternative service providers listed below, instead of the default Pinpoint provider:

Kinesis (aws-amplify/analytics/kinesis)
Kinesis Data Firehose (aws-amplify/analytics/kinesis-firehose)
Personalize Event (aws-amplify/analytics/personalize)
you may encounter the following error when starting the bundler:

Error: Unable to resolve module stream from /path/to/node_modules/@aws-sdk/... This is a known issue. Please follow the steps outlined in the issue to resolve the error.

- Storing analytics data - 
The Amazon Data Firehose analytics provider allows you to send analytics data to an Amazon Data Firehose stream for reliably storing data.

Setup Firehose stream
The following is an example utilizing the AWS Cloud Development Kit (AWS CDK) to create the Analytics resource powered by Amazon Data Firehose.

Let's create a storage bucket to store the data from the Firehose stream.

amplify/storage/resource.ts
import { defineStorage } from "@aws-amplify/backend";

// Define the S3 bucket resource
export const storage = defineStorage({
  name: "FirehoseDestinationBucket",
});
next, let's create the Firehose resource.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import { storage } from "./storage/resource";
import { CfnDeliveryStream } from "aws-cdk-lib/aws-kinesisfirehose";
import { Stack } from "aws-cdk-lib/core";
import {
  Policy,
  PolicyStatement,
  Role,
  ServicePrincipal,
} from "aws-cdk-lib/aws-iam";

const backend = defineBackend({
  auth, 
  data,
  storage,
  // additional resources 
});

// Create a new stack for the Firehose resources
const firehoseStack = backend.createStack("firehose-stack");

// Access the S3 bucket resource
const s3Bucket = backend.storage.resources.bucket;

// Create a new IAM role for the Firehose
const firehoseRole = new Role(firehoseStack, "FirehoseRole", {
  assumedBy: new ServicePrincipal("firehose.amazonaws.com"),
});

// Grant the Firehose role read/write permissions to the S3 bucket
s3Bucket.grantReadWrite(firehoseRole);

// Create a new Firehose delivery stream
const myFirehose = new CfnDeliveryStream(firehoseStack, "MyFirehose", {
  deliveryStreamType: "DirectPut",
  s3DestinationConfiguration: {
    bucketArn: s3Bucket.bucketArn,
    roleArn: firehoseRole.roleArn,
  },
  deliveryStreamName: "myFirehose",
});

// Create a new IAM policy to allow users to write to the Firehose
const firehosePolicy = new Policy(firehoseStack, "FirehosePolicy", {
  statements: [
    new PolicyStatement({
      actions: ["firehose:PutRecordBatch"],
      resources: [myFirehose.attrArn],
    }),
  ],
});

// Attach the policy to the authenticated and unauthenticated IAM roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(firehosePolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(firehosePolicy);
Installation and Configuration
Ensure you have setup IAM permissions for firehose:PutRecordBatch.

Example IAM policy for Amazon Data Firehose:

{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "firehose:PutRecordBatch",
    // replace the template fields
    "Resource": "arn:aws:firehose:<your-aws-region>:<your-aws-account-id>:deliverystream/<your-stream-name>"
  }]
}
Configure Firehose:

src/index.js
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

const amplifyConfig = parseAmplifyConfig(outputs);

Amplify.configure({
  ...amplifyConfig,
  Analytics: {
    KinesisFirehose: {
      // REQUIRED -  Amazon Kinesis Firehose service region
      region: 'us-east-1',

      // OPTIONAL - The buffer size for events in number of items.
      bufferSize: 1000,

      // OPTIONAL - The number of events to be deleted from the buffer when flushed.
      flushSize: 100,

      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000, // 5s

      // OPTIONAL - The limit for failed recording retries.
      resendLimit: 5
    }
  }
});
Storing data
You can send a data to a Firehose stream with the standard record method. Any data is acceptable and streamName is required:

src/index.js
import { record } from 'aws-amplify/analytics/kinesis-firehose';

record({
  data: {
    // The data blob to put into the record
  },
  streamName: 'myFirehose'
});
Flush events
The recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

src/index.js
import { flushEvents } from 'aws-amplify/analytics/kinesis-firehose';

flushEvents();
Known Issues
When importing alternative service providers listed below, instead of the default Pinpoint provider:

Amazon Kinesis (aws-amplify/analytics/kinesis)
Amazon Data Firehose (aws-amplify/analytics/kinesis-firehose)
Personalize Event (aws-amplify/analytics/personalize)
you may encounter the following error when starting the bundler:

Error: Unable to resolve module stream from /path/to/node_modules/@aws-sdk/... This is a known issue. Please follow the steps outlined in the issue to resolve the error.

- Personalized recommendations - 
Amazon Personalize can create recommendations by using event data, historical data, or a combination of both. The event data can then be used to create recommendations.

To record event data, you need the following:

A dataset group
An event tracker.
For more information, see Record Events.

Installation and Configuration
After creating the Amazon Personalize dataset group, you need to add the personalize:PutEvents permission to your AWS Identity and Access Management (IAM) user roles.

An example IAM policy:

{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": "personalize:PutEvents",
    "Resource": "arn:aws:personalize:<your-aws-region>:<your-account-id>:event-tracker/<your-resource-name>"
  }]
}
You need the tracking ID of your event tracker. For more information, see Get a Tracking ID.

Configure Amazon Personalize:

src/index.js
import { Amplify } from 'aws-amplify';
import outputs from '../amplify_outputs.json';

const amplifyConfig = parseAmplifyConfig(outputs);

Amplify.configure({
  ...amplifyConfig,
  Analytics: {
    Personalize: {
      // REQUIRED - The trackingId to track the events
      trackingId: '<tracking-id>',
      // REQUIRED -  Amazon Personalize service region
      region: 'us-east-1',
      // OPTIONAL - The number of events to be deleted from the buffer when flushed.
      flushSize: 10,
      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000 // 5s
    }
  }
});
Working with the API
You can use the Identify event type to track a user identity. This lets you connect a user to their actions and record traits about them. To identify a user, specify a unique identifier for the userId property. Consider the following user interactions when choosing when and how often to call record with the Identify eventType:

After a user registers.
After a user logs in.
When a user updates their information (For example, changing or adding a new address).
Upon loading any pages that are accessible by a logged-in user (optional).
import { record } from 'aws-amplify/analytics/personalize';

record({
  eventType: 'Identify',
  properties: {
    userId: '<user-id>'
  }
});
You can send events to Amazon Personalize by calling the record operation. If you already use Identify to track end-user data, you can skip the userId, the SDK will fetch the userId based on current browser session. For information about the properties field, see Put Events.

import { record } from 'aws-amplify/analytics/personalize';

record({
  eventType: '<event-type>',
  userId: '<user-id>', // optional
  properties: {
    itemId: '<item-id>',
    eventValue: '<event-value>'
  }
});
You can track iframe and HTML5 media types by using the MediaAutoTrack event type. MediaAutoTrack tracks all media events of the media DOM element that you bind to. MediaAutoTracker will automatically track Play, Pause, Ended, TimeWatched, and Resume in eventType. The duration of the event compared to the total length of the media is stored as a percentage value in eventValue.

import { record } from 'aws-amplify/analytics/personalize';

record({
  eventType: 'MediaAutoTrack',
  userId: '<user-id>', // (optional)
  properties: {
    domElementId: 'media-dom-element-id',
    itemId: '<item-d>'
  }
});
Flush events
The recorded events are saved in a buffer and sent to the remote server periodically (You can tune it with the flushInterval option). If needed, you have the option to manually clear all the events from the buffer by using the 'flushEvents' API.

import { flushEvents } from 'aws-amplify/analytics/personalize';

flushEvents();

- Use existing AWS resources - 
To use existing Amazon Pinpoint resources with your Amplify backend or frontend application, use the addOutput method to surface backend resource outputs to the amplify_outputs.json file:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend"

const backend = defineBackend({})

backend.addOutput({
  analytics: {
    amazon_pinpoint: {
      aws_region: "<your-aws-region>",
      app_id: "<your-pinpoint-app-id>",
    },
  },
})
Configuring client library directly
Alternatively, you can configure the client library directly using Amplify.configure(). This manual setup enables you to use your existing Amazon Pinpoint resource in your app.

src/main.ts
import { Amplify } from 'aws-amplify';
import { parseAmplifyConfig } from "aws-amplify/utils";
import outputs from '../amplify_outputs.json';

const amplifyConfig = parseAmplifyConfig(outputs);

Amplify.configure({
  ...amplifyConfig,
  Analytics: {
    ...amplifyConfig.Analytics,
    Pinpoint: {
      // REQUIRED -  Amazon Pinpoint App Client ID
      appId: 'XXXXXXXXXXabcdefghij1234567890ab',

      // REQUIRED -  Amazon service region
      region: 'us-east-1',

      // OPTIONAL - How many events can be buffered at once.
      bufferSize: 1000,

      // OPTIONAL - How many events will be flushed from the buffer per batch.
      flushSize: 100,

      // OPTIONAL - The interval in milliseconds to perform a buffer check and flush if necessary.
      flushInterval: 5000, // 5s

      // OPTIONAL - The limit for failed recording retries.
      resendLimit: 5
    }
  }
});
Update your IAM Policy
Amazon Pinpoint requires an AWS Identity and Access Management (IAM) policy in order to use the record and identifyUser APIs:

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["mobiletargeting:UpdateEndpoint", "mobiletargeting:PutEvents"],
      "Resource": ["arn:aws:mobiletargeting:*:<your-account-id>:apps/<your-pinpoint-app-id>*"]
    }
  ]
}

- API Reference - 
configureAutoTrack
Configures automatic event tracking for Pinpoint. This API will automatically transmit an analytic event when configured events are detected within your application. This can include: DOM element events (via the event tracker), session events (via the session tracker), and page view events (via the pageView tracker).
Parameters
Option	Required	Type	Description
input	true	AnalyticsConfigureAutoTrackInput	
Throws
service:UpdateEndpointException - Thrown when the underlying Pinpoint service returns an error.
validation:AnalyticsValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect.
Returns
void
disable
Disables the Analytics category.
Returns
void
enable
Enables the Analytics category to permit the transmission of events.
Returns
void
flushEvents
Flushes all buffered Pinpoint events to the service.
Returns
void
identifyUser
Sends information about a user to Pinpoint. Sending user information allows you to associate a user to their user profile and activities or actions in your application. Activity can be tracked across devices & platforms by using the same userId.
Parameters
Option	Required	Type	Description
params	true	IdentifyUserInput	
The input object used to construct requests sent to Pinpoint's UpdateEndpoint API.
Throws
service:UpdateEndpointException - Thrown when the underlying Pinpoint service returns an error.
validation:AnalyticsValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect.
Returns
Promise<void>
record
Records an Analytic event to Pinpoint. Events will be buffered and periodically sent to Pinpoint.
Parameters
Option	Required	Type	Description
input	true	PinpointAnalyticsEvent	
Throws
validation:AnalyticsValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect.
Returns
void
Link Color Legend
Interface
Reference
Other

- Set up in-app messaging - 
Amplify allows interacting with In-App Messaging APIs, enabling you to send messages to your app users. In-App Messaging is a powerful tool to engage with your users and provide them with relevant information. A campaign is a messaging initiative that engages a specific audience segment. A campaign sends tailored messages according to a schedule that you define. You can use the AWS Cloud Development Kit (AWS CDK) to create a campaign that sends messages through any single channel that is supported by Amazon Pinpoint: Mobile Push, In-App, Email, SMS or Custom channels.

The following is an example utilizing the AWS CDK to create the In-App Messaging resource powered by Amazon Pinpoint. Note: there are no official hand-written (L2) constructs for this service yet.

Security Considerations
When implementing in-app messaging, please be aware of two important security considerations.

First, the endpointID generated by Amazon Pinpoint should be treated as confidential information. There is no built-in authorization mechanism based on endpointID, which means if an endpointID is compromised, other users could potentially access messages intended for different users. We recommend implementing appropriate security measures in your application to protect endpointID access.

Second, messages received from Amazon Pinpoint campaigns are delivered without any content sanitization. AWS Amplify acts as a pass-through service and does not perform any content validation or sanitization on these messages. To ensure application security, you should always sanitize message content before rendering it in your application to prevent potential security vulnerabilities such as cross-site scripting (XSS) attacks.

Note: Campaign start time must be at least 15 minutes in future. In-app messages can only be synced to local device once the campaign becomes active (Status should be "In Progress" in the campaigns screen of the Pinpoint console).

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { auth } from "./auth/resource";
import { data } from "./data/resource";
import {
  CfnApp,
  CfnCampaign,
  CfnSegment,
} from "aws-cdk-lib/aws-pinpoint";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { Stack } from "aws-cdk-lib/core";


const backend = defineBackend({
  auth, 
  data,
  // additional resources 
});

const inAppMessagingStack = backend.createStack("inAppMessaging-stack");

// create a Pinpoint app
const pinpoint = new CfnApp(inAppMessagingStack, "Pinpoint", {
  name: "myPinpointApp",
});

// create a segment 
const mySegment = new CfnSegment(inAppMessagingStack, "Segment", {
  applicationId: pinpoint.ref,
  name: "mySegment",
});

// create a campaign with event and in-app message template
new CfnCampaign(inAppMessagingStack, "Campaign", {
  applicationId: pinpoint.ref,
  name: "MyCampaign",
  segmentId: mySegment.attrSegmentId,
  schedule: {
    // ensure the start and end time are in the future
    startTime: "2024-02-23T14:39:34Z", 
    endTime: "2024-02-29T14:32:40Z",
    frequency: "IN_APP_EVENT",
    eventFilter: {
      dimensions: {
        eventType: {
          dimensionType: "INCLUSIVE",
          values: ["my_first_event"],
        },
      },
      filterType: "ENDPOINT",
    },
  },

  messageConfiguration: {
    inAppMessage: {
      layout: "TOP_BANNER",
      content: [
        {
          // define the content of the in-app message
          bodyConfig: {
            alignment: "CENTER",
            body: "This is an example in-app message.",
            textColor: "#FFFFFF",
          },
          backgroundColor: "#000000",
          headerConfig: {
            alignment: "CENTER",
            header: "Welcome!",
            textColor: "#FFFFFF",
          },
          // optionally, define buttons, images, etc.
        },
      ],
    },
  },
});

//create an IAM policy to allow interacting with Pinpoint in-app messaging
const pinpointPolicy = new Policy(inAppMessagingStack, "PinpointPolicy", {
  policyName: "PinpointPolicy",
  statements: [
    new PolicyStatement({
      actions: [
        "mobiletargeting:GetInAppMessages",
        "mobiletargeting:UpdateEndpoint",
        "mobiletargeting:PutEvents",
      ],
      resources: [pinpoint.attrArn + "/*", pinpoint.attrArn],
    }),
  ],
});

// apply the policy to the authenticated and unauthenticated roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(pinpointPolicy);

// patch the custom Pinpoint resource to the expected output configuration
backend.addOutput({
  notifications: {
    amazon_pinpoint_app_id: pinpoint.ref,
    aws_region: Stack.of(pinpoint).region,
    channels: ["IN_APP_MESSAGING"],
  },
});
Install Amplify Libraries
First, install the aws-amplify library:

Terminal
npm add aws-amplify
Initialize In-App Messaging
To finish setting up your application with Amplify, you need to configure it using the configure API. Next, to interact with In-App Messaging APIs, you need to first initialize In-App Messaging by calling the initializeInAppMessaging API directly imported from the in-app-messaging sub-path. This is required to be called as early as possible in the app lifecycle.

src/index.js
import { Amplify } from 'aws-amplify';
import { initializeInAppMessaging } from 'aws-amplify/in-app-messaging';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
initializeInAppMessaging();
Make sure you call Amplify.configure as early as possible in your applications life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs.

References
Amazon Pinpoint Construct Library

- Integrate your application - 
Install the Amplify React Native Package and other dependencies
Installing the @aws-amplify/react-native will bring in the necessary polyfills for React Native.

Instructions for React Native version 0.72 and below
Terminal
npm add @aws-amplify/react-native @react-native-community/netinfo @react-native-async-storage/async-storage
Install Amplify UI for React Native and its dependencies
Although Amplify In-App Messaging can be used as a standalone JavaScript library, this guide will show you how to use it together with Amplify UI, which currently supports integration with React and React Native, to get started quickly.

Learn more about Amplify In-App Messaging UI and how to fully unlock its capabilities here: Amplify UI for In-App Messaging

Terminal
npm add @aws-amplify/ui-react-native react-native-safe-area-context@^4.2.5
Install Amplify UI for React
Although Amplify In-App Messaging can be used as a standalone JavaScript library, this guide will show you how to use it together with Amplify UI, which currently supports integration with React and React Native, to get started quickly.

Learn more about Amplify In-App Messaging UI and how to fully unlock its capabilities here: Amplify UI for In-App Messaging

Terminal
npm add @aws-amplify/ui-react @aws-amplify/ui-react-notifications
Integrate Amplify UI
Amplify UI provides a Higher-Order Component for ease of integrating the In-App Messaging UI with your application. Simply wrap your application root component in, for example, App.js.

import { withInAppMessaging } from '@aws-amplify/ui-react-native';

const App = () => (
  {/* Your application code */}
);

export default withInAppMessaging(App);
Below is an example of what your entry file should look like:

src/index.js
import React, { useEffect } from 'react';
import { Button, View } from 'react-native';
import {
  initializeInAppMessaging,
  syncMessages,
  dispatchEvent
} from 'aws-amplify/in-app-messaging';
import { withInAppMessaging } from '@aws-amplify/ui-react-native';
import { record } from 'aws-amplify/analytics';
import outputs from '../amplify_outputs.json';

Amplify.configure(outputs);
initializeInAppMessaging();

// To display your in-app message, make sure this event name matches one you created
// in an In-App Messaging campaign!
const myFirstEvent = { name: 'my_first_event' };

const App = () => {
  useEffect(() => {
    // Messages from your campaigns need to be synced from the backend before they
    // can be displayed. You can trigger this anywhere in your app. Here you are
    // syncing just once when this component (your app) renders for the first time.
    syncMessages();
  }, []);

  return (
    <View>
      {/* This button has an example of an analytics event triggering the in-app message. */}
      <Button
        onPress={() => {
          record(myFirstEvent);
        }}
        title="Record Analytics Event"
      />

      {/* This button has an example of an In-app Messaging event triggering the in-app message.*/}
      <Button
        onPress={() => {
          dispatchEvent(myFirstEvent);
        }}
        title="Send In-App Messaging Event"
      />
    </View>
  );
};

export default withInAppMessaging(App);
You can now build and run your app in your terminal. If you click on one of the buttons shown in the above example, the in-app message you defined in the Pinpoint console should be displayed in your app.

- Sync messages -
To trigger messages, you must sync them from your In-App Messaging campaigns to your users' devices. These messages are then triggered with an analytics or In-App Messaging event. You can control when and how often this sync is performed.

src/index.js
import { syncMessages } from 'aws-amplify/in-app-messaging';

await syncMessages();
Note: Syncing messages will always overwrite existing messages currently on the user's device so that they are always up to date when the sync is performed.

- Display messages - 
In-app messages are displayed when an In-App Messaging or analytics event is sent and matches the criteria defined by your active In-App Messaging campaigns.

Analytics event
Now that messages have been synced to your users' devices, Amplify In-App Messaging will allow you to start displaying them with Amplify Analytics events with no additional integration steps. Any events you record or are already recording using the Analytics' record API are automatically picked up and processed by In-App Messaging. If the event matches the attributes and criteria defined in an in-app message, that message will be displayed.

src/index.js
import { record } from 'aws-amplify/analytics';

record({
  name: 'first_event',
  attributes: { color: 'red' },
  metrics: { quantity: 10 }
});
If the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.

In-App Messaging events
In addition to or instead of Amplify Analytics events, you can also dispatch In-App Messaging events to trigger an in-app message display programmatically.

src/index.js
import { dispatchEvent } from 'aws-amplify/in-app-messaging';

dispatchEvent({
  name: 'first_event',
  attributes: { color: 'red' },
  metrics: { quantity: 10 }
});
If the event name, attributes, and metrics match those set forth by one of your In-App Messaging campaigns, you should see the in-app message displayed in your app.

- Clear messages - 
Once messages have been synced to your user's device, clearMessages() can be used to clear the synced messages.

src/index.js
import { clearMessages } from 'aws-amplify/in-app-messaging';

await clearMessages();
Note: If your app has authentication implemented, we recommend calling clearMessages() in between user log-ins to remove messages targeted for specific user segments. This is especially important if you anticipate your application will be used in shared device scenarios.

- Identify a user - 
To fully harness the potential of In-App Messaging, you must segment and target your In-App Messaging campaigns to specific user subsets. By identifying users with additional information, including their device demographics, location and any attributes of your choosing, you will be able to display intelligent, targeted in-app messages to the right users.

src/index.js
import { identifyUser } from 'aws-amplify/in-app-messaging';

await identifyUser({
  userId: '', // E.g. user-id
  userProfile: {
    email: '', // E.g. example@service.com
    name: '', // E.g. name-of-the-user
    plan: '' // E.g. plan-they-subscribe-to
    customProperties: {
      // E.g. hobbies: ['cooking', 'knitting'],
    },
    demographic: {
      appVersion: '',
      locale: '', // E.g. en_US
      make: '', // E.g. Apple
      model: '', // E.g. iPhone
      modelVersion: '', // E.g. 13
      platform: '', // E.g. iOS
      platformVersion: '', // E.g. 15
      timezone: '' // E.g. Americas/Los_Angeles
    },
    location: {
      city: '', // E.g. Seattle
      country: '', // E.g. US,
      postalCode: '', // E.g. 98121
      region: '', // E.g. WA
      latitude: 0.0,
      longitude: 0.0
    },
    metrics: {
      // E.g. logins: 157
    },
  },
});
Identify a user with Amazon Pinpoint
When using identifyUser with Amazon Pinpoint, in addition to the other user info properties you can configure the address, optOut, and userAttributes properties under options.

src/index.js
import { identifyUser } from 'aws-amplify/in-app-messaging';

await identifyUser({
  userId: '', // E.g. user-id
  options: {
    address: '' // E.g. A device token or email address
    optOut: ''  // Either ALL or NONE
    userAttributes: {
      // E.g. interests: ['soccer', 'shoes'],
    }
  },
});

- Respond to interaction events - 
Your code can respond with additional behavior to your users interacting with in-app messages by adding interaction event listeners.

Message received
Add onMessageReceived listeners to respond to an in-app message being received from the library as the result of an event matching the criteria of a synced in-app message. This is required if you are implementing a custom UI so that your UI can respond to event-triggered campaign messages but you may also find it helpful to listen for these messages for any other reason your application requires.

src/index.js
import { onMessageReceived } from 'aws-amplify/in-app-messaging';

const myMessageReceivedHandler = (message) => {
  // Do something with the received message
};

const listener = onMessageReceived(myMessageReceivedHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
Message displayed
Add onMessageDisplayed listeners to respond to an in-app message being displayed to your user.

src/index.js
import { onMessageDisplayed } from 'aws-amplify/in-app-messaging';

const myMessageDisplayedHandler = (message) => {
  // Do something with the displayed message
};

const listener = onMessageDisplayed(myMessageDisplayedHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
Message dismissed
Add onMessageDismissed listeners to respond to an in-app message being dismissed by your user.

src/index.js
import { onMessageDismissed } from 'aws-amplify/in-app-messaging';

const myMessageDismissedHandler = (message) => {
  // Do something with the dismissed message
};

const listener = onMessageDismissed(myMessageDismissedHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
Message action taken
Add onMessageActionTaken listeners to respond to an action being taken on an in-app message. Typically, this means that the user has tapped or clicked a button on an in-app message.

src/index.js
import { onMessageActionTaken } from 'aws-amplify/in-app-messaging';

const myMessageActionTakenHandler = (message) => {
  // Do something with the message action was taken against
};

const listener = onMessageActionTaken(myMessageActionTakenHandler);

listener.remove(); // Remember to remove the listener when it is no longer needed
Notifying listeners
If you are using the Amplify In-App Messaging UI, interaction events notifications are already wired up for you. However, if you are implementing your own UI, it is highly recommended to notify listeners of interaction events through your UI code so that the library can take further actions prescribed by the installed provider (for example, automatically recording corresponding Analytics events).

src/index.js
import { notifyMessageInteraction } from 'aws-amplify/in-app-messaging';

const message = {
  // In-app message that you want to record an interaction on
}

/**
 * Interaction events that can be notified correspond to their respective listeners:
 *    'messageReceived'
 *    'messageDisplayed'
 *    'messageDismissed'
 *    'messageActionTaken'
 */
notifyMessageInteraction({ message, type: 'messageDisplayed' });

- Resolve conflicts -
In the rare case where an event is sent and meets the criteria set forth by multiple in-app messages, the library needs to decide which message to return. If such a conflict should arise, In-App Messaging will choose a message by:

Sorting the messages in order of campaign expiration
Returning the top message sorted (the closest message to expiry)
However, this may not be how you wish to resolve such conflicts so you may want to set your own conflict handler.

src/index.js
import { setConflictHandler } from 'aws-amplify/in-app-messaging';

/**
 * Regardless of your conflict resolution strategy the handler must always accept
 * an array of in-app messages and return a single in-app message.
 */
const myConflictHandler = (messages) => {
  // Return a random message
  const randomIndex = Math.floor(Math.random() * messages.length);
  return messages[randomIndex];
};

setConflictHandler(myConflictHandler);

- Create an in-app messaging campaign on AWS Console - 
As an alternative to writing AWS Cloud Development Kit (CDK) code, you can use the AWS console to create a campaign that sends messages through any single channel that is supported by Amazon Pinpoint: Mobile Push, In-App, Email, SMS or Custom channels. Learn how to create a campaign using Amazon Pinpoint to continue integrating in-app messages in your app with Amplify.

Login to the AWS Console, and Search for Pinpoint.

Click on your project from the list of available project. Your project name would be the name you provided when you created the pinpoint project using CDK.

Click on Campaigns from the left navigation menu, and then click on Create a campaign

A screenshot of the pinpoint campaign page on the AWS console highlighting the 'Campaigns' option on the left navigation menu and the 'Create a campaign' button on the main page

Add a name to your campaign, and keep the following options as follows and then click Next:

Campaign type: Standard campaign
Channel: In-App messaging
set prioritization: Fairly important
Click on the Create a segment radio button, add a name for your segment, and then click Next.

You can add as many segments as needed to the campaign. For this quickstart, you can use Include any audiences under the Segment group 1 section.
You can add a criteria to your segments to ensure that audiences that satisfy that criteria can receive the in-app message.
If you see an error message titled Segment might include multiple channels, click I understand to proceed.
A screenshot of the pinpoint page displaying a selected 'Create a segment' option on the 'Create a campaign' page. The page shows a input box called 'Name' with 'All my users' as an input. The page also displayed a 'Segment details' section with a radio button selected on 'Include any audiences'

Click on the Create a new in-app message radio button.

You have the ability to customize the following attributes of the in-app message:

Layout: Which includes all of the different messaging layout options.
Header: Title of the in-app message, including the text color/alignment.
Message: The body of the Message, including the text color/alignment.
Background: Control the background color of the in-app message.
Image URL: Add an image to be displayed as part of the in-app message body.
Primary button: Allows the addition of a button to add functionality to the in-app message.
Secondary button: Allows the addition of an extra button for additional functionality.
Custom Data: Allows the in-app message to pass additional data to the frontend app once it is triggered by an event.
As React Native does not support SVG rendering out of the box, Amplify cannot render SVG images by default. For SVG image support with In-App Messaging a custom UI implementation is required.

For this tutorial you can create a simple message as shown below. Customers in your application will see the same message once the event is triggered.

A screenshot of the 'In-app message details' page providing layout options, header, message and a sample phone display on the right side of the page. The page allows customizing the your applications in-app message displayed on various device displays

Once you have finished customizing your in-app message, click on Next.
Under Trigger events, add the name of the analytics trigger that will be sent from your frontend app.
You have the ability to customize the trigger to allow only certain attributes or metrics that are passed with the analytics event to trigger the in-app message. (Optional)
A screenshot of Campaign setup page, titled 'Choose when to send the campaign'. The page shows options such as trigger events, attributes, metrics, campaign dates and time zone. The options allow configuring a trigger event and when the campaign should start and end in a time zone

By default, the number of messages shown per session is 1. You can update this threshold during campaign setup.
A screenshot of the optional 'Edit campaign settings' page providing configuration options 'Maximum number of session messages viewed per endpoint', 'Maximum number of daily messages viewed per endpoint' and 'Maximum number of messages viewed per endpoint'. The 'Maximum number of session messages viewed per endpoint' is the maximum number of messages that can be viewed per session for this campaign which is set to 1 by default and can be increased on a campaign creation

Review your campaign, and then click on Launch campaign.
Your campaign is now setup, and you are ready to start integrating the In-App Messaging functionality into your app.

Note: Campaign start time must be at least 15 minutes in future. In-app messages can only be synced to local device once the campaign becomes active (status should be "In Progress" in the campaigns screen of the Pinpoint console).

- API Reference - 
clearMessages
Clear locally cached messages.
Throws
validation:InAppMessagingValidationErrorCode - Thrown if In App messaging hasn't been initialized.
Returns
Promise<void>
dispatchEvent
Triggers an In-App message to be displayed. Use this after your campaigns have been synced to the device using syncMessages. Based on the messages synced and the event passed to this API, it triggers the display of the In-App message that meets the criteria.
Parameters
Option	Required	Type	Description
input	true	InAppMessagingEvent	
The input object that holds the event to be dispatched.
Throws
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
serviceexceptions - Thrown when the underlying Pinpoint service returns an error.
Returns
Promise<void>
identifyUser
Sends information about a user to Pinpoint. Sending user information allows you to associate a user to their user profile and activities or actions in your application. Activity can be tracked across devices & platforms by using the same userId.
Parameters
Option	Required	Type	Description
input	true	IdentifyUserInput	
The input object that conforms to IdentifyUserInput used to construct requests sent to Pinpoint's UpdateEndpoint API.
Throws
service:UpdateEndpointException - Thrown when the underlying Pinpoint service returns an error.
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
Promise<void>
initializeInAppMessaging
Initialize and set up in-app messaging category. This API needs to be called to enable other InAppMessaging APIs.
Returns
void
notifyMessageInteraction
Notifies the respective listener of the specified type with the message given.
Parameters
Option	Required	Type	Description
input	true	NotifyMessageInteractionInput	
The input object that holds the type and message.
Throws
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
void
onMessageActionTaken
Registers a callback that will be invoked on messageActionTaken events.
Parameters
Option	Required	Type	Description
input	true	OnMessageInteractionEventHandler	
The input object that holds the callback handler.
Throws
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
OnMessageActionTakenOutput
Output type for OnMessageActionTaken API.
onMessageDismissed
Registers a callback that will be invoked on messageDismissed events.
Parameters
Option	Required	Type	Description
input	true	OnMessageInteractionEventHandler	
The input object that holds the callback handler.
Throws
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
OnMessageDismissedOutput
Output type for OnMessageDismissed API.
onMessageDisplayed
Registers a callback that will be invoked on messageDisplayed events.
Parameters
Option	Required	Type	Description
input	true	OnMessageInteractionEventHandler	
The input object that holds the callback handler.
Throws
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
OnMessageDisplayedOutput
Output type for OnMessageDisplayed API.
onMessageReceived
Registers a callback that will be invoked on messageReceived events.
Parameters
Option	Required	Type	Description
input	true	OnMessageInteractionEventHandler	
The input object that holds the callback handler.
Throws
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
OnMessageReceivedOutput
Output type for OnMessageReceived API.
setConflictHandler
Set a conflict handler that will be used to resolve conflicts that may emerge when matching events with synced messages.
Parameters
Option	Required	Type	Description
input	true	InAppMessageConflictHandler	
The input object that holds the conflict handler to be used.
Throws
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
void
syncMessages
Fetch and persist messages from Pinpoint campaigns. Calling this API is necessary to trigger InApp messages on the device.
Throws
serviceexceptions - Thrown when the underlying Pinpoint service returns an error.
validation:InAppMessagingValidationErrorCode - Thrown when the provided parameters or library configuration is incorrect, or if In App messaging hasn't been initialized.
Returns
Promise<void>
Link Color Legend
Interface
Reference
Other

- Set up Amplify REST API - 
Using the AWS Cloud Development Kit (AWS CDK), you can configure Amplify Functions as resolvers for routes of a REST API powered by Amazon API Gateway.

Set up REST API with Lambda Function
Create a new directory and a resource file, amplify/functions/api-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/api-function/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const myApiFunction = defineFunction({
  name: "api-function",
});
Create the corresponding handler file, amplify/functions/api-function/handler.ts, file with the following contents:

amplify/functions/api-function/handler.ts
import type { APIGatewayProxyHandler } from "aws-lambda";

export const handler: APIGatewayProxyHandler = async (event) => {
  console.log("event", event);
  return {
    statusCode: 200,
    // Modify the CORS settings below to match your specific requirements
    headers: {
      "Access-Control-Allow-Origin": "*", // Restrict this to domains you trust
      "Access-Control-Allow-Headers": "*", // Specify only the headers you need to allow
    },
    body: JSON.stringify("Hello from myFunction!"),
  };
};
Use the AWS CDK to create an REST API resource powered by Amazon API Gateway.

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { Stack } from "aws-cdk-lib";
import {
  AuthorizationType,
  CognitoUserPoolsAuthorizer,
  Cors,
  LambdaIntegration,
  RestApi,
} from "aws-cdk-lib/aws-apigateway";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { myApiFunction } from "./functions/api-function/resource";
import { auth } from "./auth/resource";
import { data } from "./data/resource";

const backend = defineBackend({
  auth,
  data,
  myApiFunction,
});

// create a new API stack
const apiStack = backend.createStack("api-stack");

// create a new REST API
const myRestApi = new RestApi(apiStack, "RestApi", {
  restApiName: "myRestApi",
  deploy: true,
  deployOptions: {
    stageName: "dev",
  },
  defaultCorsPreflightOptions: {
    allowOrigins: Cors.ALL_ORIGINS, // Restrict this to domains you trust
    allowMethods: Cors.ALL_METHODS, // Specify only the methods you need to allow
    allowHeaders: Cors.DEFAULT_HEADERS, // Specify only the headers you need to allow
  },
});

// create a new Lambda integration
const lambdaIntegration = new LambdaIntegration(
  backend.myApiFunction.resources.lambda
);

// create a new resource path with IAM authorization
const itemsPath = myRestApi.root.addResource("items", {
  defaultMethodOptions: {
    authorizationType: AuthorizationType.IAM,
  },
});

// add methods you would like to create to the resource path
itemsPath.addMethod("GET", lambdaIntegration);
itemsPath.addMethod("POST", lambdaIntegration);
itemsPath.addMethod("DELETE", lambdaIntegration);
itemsPath.addMethod("PUT", lambdaIntegration);

// add a proxy resource path to the API
itemsPath.addProxy({
  anyMethod: true,
  defaultIntegration: lambdaIntegration,
});

// create a new Cognito User Pools authorizer
const cognitoAuth = new CognitoUserPoolsAuthorizer(apiStack, "CognitoAuth", {
  cognitoUserPools: [backend.auth.resources.userPool],
});

// create a new resource path with Cognito authorization
const booksPath = myRestApi.root.addResource("cognito-auth-path");
booksPath.addMethod("GET", lambdaIntegration, {
  authorizationType: AuthorizationType.COGNITO,
  authorizer: cognitoAuth,
});

// create a new IAM policy to allow Invoke access to the API
const apiRestPolicy = new Policy(apiStack, "RestApiPolicy", {
  statements: [
    new PolicyStatement({
      actions: ["execute-api:Invoke"],
      resources: [
        `${myRestApi.arnForExecuteApi("*", "/items", "dev")}`,
        `${myRestApi.arnForExecuteApi("*", "/items/*", "dev")}`,
        `${myRestApi.arnForExecuteApi("*", "/cognito-auth-path", "dev")}`,
      ],
    }),
  ],
});

// attach the policy to the authenticated and unauthenticated IAM roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(
  apiRestPolicy
);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(
  apiRestPolicy
);

// add outputs to the configuration file
backend.addOutput({
  custom: {
    API: {
      [myRestApi.restApiName]: {
        endpoint: myRestApi.url,
        region: Stack.of(myRestApi).region,
        apiName: myRestApi.restApiName,
      },
    },
  },
});
Install Amplify Libraries
Use the package manager of your choice to install the Amplify JavaScript library. For example, with npm:

Terminal
npm add aws-amplify
Use the package manager of your choice to install the Amplify JavaScript library. For example, with npm:

Instructions for React Native version 0.72 and below
Terminal
npm add aws-amplify @aws-amplify/react-native
Initialize Amplify API
To initialize the Amplify API category you need to configure Amplify with Amplify.configure().

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example index.js in React or main.ts in Angular.

src/main.ts
import { Amplify } from 'aws-amplify';
import { parseAmplifyConfig } from "aws-amplify/utils";
import outputs from '../amplify_outputs.json';

const amplifyConfig = parseAmplifyConfig(outputs);

Amplify.configure({
  ...amplifyConfig,
  API: {
    ...amplifyConfig.API,
    REST: outputs.custom.API,
  },
});
Make sure you call Amplify.configure as early as possible in your applications life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.

- Set up Amplify HTTP API - 
Using the AWS Cloud Development Kit (AWS CDK), you can configure Amplify Functions as resolvers for routes of an HTTP API powered by Amazon API Gateway.

Set up HTTP API with Lambda Function
To get started, create a new directory and a resource file, amplify/functions/api-function/resource.ts. Then, define the function with defineFunction:

amplify/functions/api-function/resource.ts
import { defineFunction } from "@aws-amplify/backend";

export const myApiFunction = defineFunction({
  name: "api-function",
});
Then, create the corresponding handler file, amplify/functions/api-function/handler.ts, file with the following contents:

amplify/functions/api-function/handler.ts
import type { APIGatewayProxyHandlerV2 } from "aws-lambda";

export const handler: APIGatewayProxyHandlerV2 = async (event) => {
  console.log("event", event);
  return {
    statusCode: 200,
    // Modify the CORS settings below to match your specific requirements
    headers: {
      "Access-Control-Allow-Origin": "*", // Restrict this to domains you trust
      "Access-Control-Allow-Headers": "*", // Specify only the headers you need to allow
    },
    body: JSON.stringify("Hello from api-function!"),
  };
};
Next, using the AWS CDK, create an HTTP API in your backend file:

amplify/backend.ts
import { defineBackend } from "@aws-amplify/backend";
import { Stack } from "aws-cdk-lib";
import {
  CorsHttpMethod,
  HttpApi,
  HttpMethod,
} from "aws-cdk-lib/aws-apigatewayv2";
import {
  HttpIamAuthorizer,
  HttpUserPoolAuthorizer,
} from "aws-cdk-lib/aws-apigatewayv2-authorizers";
import { HttpLambdaIntegration } from "aws-cdk-lib/aws-apigatewayv2-integrations";
import { Policy, PolicyStatement } from "aws-cdk-lib/aws-iam";
import { myApiFunction } from "./functions/api-function/resource";
import { auth } from "./auth/resource";
import { data } from "./data/resource";

const backend = defineBackend({
  auth,
  data,
  myApiFunction,
});

// create a new API stack
const apiStack = backend.createStack("api-stack");

// create a IAM authorizer
const iamAuthorizer = new HttpIamAuthorizer();

// create a User Pool authorizer
const userPoolAuthorizer = new HttpUserPoolAuthorizer(
  "userPoolAuth",
  backend.auth.resources.userPool,
  {
    userPoolClients: [backend.auth.resources.userPoolClient],
  }
);

// create a new HTTP Lambda integration
const httpLambdaIntegration = new HttpLambdaIntegration(
  "LambdaIntegration",
  backend.myApiFunction.resources.lambda
);

// create a new HTTP API with IAM as default authorizer
const httpApi = new HttpApi(apiStack, "HttpApi", {
  apiName: "myHttpApi",
  corsPreflight: {
    // Modify the CORS settings below to match your specific requirements
    allowMethods: [
      CorsHttpMethod.GET,
      CorsHttpMethod.POST,
      CorsHttpMethod.PUT,
      CorsHttpMethod.DELETE,
    ],
    // Restrict this to domains you trust
    allowOrigins: ["*"],
    // Specify only the headers you need to allow
    allowHeaders: ["*"],
  },
  createDefaultStage: true,
});

// add routes to the API with a IAM authorizer and different methods
httpApi.addRoutes({
  path: "/items",
  methods: [HttpMethod.GET, HttpMethod.PUT, HttpMethod.POST, HttpMethod.DELETE],
  integration: httpLambdaIntegration,
  authorizer: iamAuthorizer,
});

// add a proxy resource path to the API
httpApi.addRoutes({
  path: "/items/{proxy+}",
  methods: [HttpMethod.ANY],
  integration: httpLambdaIntegration,
  authorizer: iamAuthorizer,
});

// add the options method to the route
httpApi.addRoutes({
  path: "/items/{proxy+}",
  methods: [HttpMethod.OPTIONS],
  integration: httpLambdaIntegration,
});

// add route to the API with a User Pool authorizer
httpApi.addRoutes({
  path: "/cognito-auth-path",
  methods: [HttpMethod.GET],
  integration: httpLambdaIntegration,
  authorizer: userPoolAuthorizer,
});

// create a new IAM policy to allow Invoke access to the API
const apiPolicy = new Policy(apiStack, "ApiPolicy", {
  statements: [
    new PolicyStatement({
      actions: ["execute-api:Invoke"],
      resources: [
        `${httpApi.arnForExecuteApi("*", "/items")}`,
        `${httpApi.arnForExecuteApi("*", "/items/*")}`,
        `${httpApi.arnForExecuteApi("*", "/cognito-auth-path")}`,
      ],
    }),
  ],
});

// attach the policy to the authenticated and unauthenticated IAM roles
backend.auth.resources.authenticatedUserIamRole.attachInlinePolicy(apiPolicy);
backend.auth.resources.unauthenticatedUserIamRole.attachInlinePolicy(apiPolicy);

// add outputs to the configuration file
backend.addOutput({
  custom: {
    API: {
      [httpApi.httpApiName!]: {
        endpoint: httpApi.url,
        region: Stack.of(httpApi).region,
        apiName: httpApi.httpApiName,
      },
    },
  },
});
Install Amplify Libraries
Use the package manager of your choice to install the Amplify JavaScript library. For example, with npm:

Terminal
npm add aws-amplify
Use the package manager of your choice to install the Amplify JavaScript library. For example, with npm:

Instructions for React Native version 0.72 and below
Terminal
npm add aws-amplify @aws-amplify/react-native
Initialize Amplify API
To initialize the Amplify API category you need to configure Amplify with Amplify.configure().

Import and load the configuration file in your app. It's recommended you add the Amplify configuration step to your app's root entry point. For example src/main.ts:

src/main.ts
import { Amplify } from 'aws-amplify';
import { parseAmplifyConfig } from "aws-amplify/utils";
import outputs from '../amplify_outputs.json';

const amplifyConfig = parseAmplifyConfig(outputs);

Amplify.configure({
  ...amplifyConfig,
  API: {
    ...amplifyConfig.API,
    REST: outputs.custom.API,
  },
});
Make sure you call Amplify.configure as early as possible in your applications life-cycle. A missing configuration or NoCredentials error is thrown if Amplify.configure has not been called before other Amplify JavaScript APIs. Review the Library Not Configured Troubleshooting guide for possible causes of this issue.

- Define authorization rules - 
When determining the authorization mode for your REST endpoint, there are a few customizations you can do.

IAM Authorization
By default, the API will be using IAM authorization and the requests will be signed for you automatically. IAM authorization has two modes: one using an unauthenticated role, and one using an authenticated role. When the user has not signed in, the unauthenticated role is used by default. Once the user has signed in, the authenticate role is used, instead.

API Key
If you want to configure a public REST API, you can set an API key in Amazon API Gateway or create one using the CDK construct. Then, you can set the API key header in the API configuration which will be applied to all requests.

Amplify.configure(outputs, {
  API: {
    REST: {
      headers: async () => {
        return { 'X-Api-Key': apiKey };
      }
    }
  }
});
Cognito User Pool Authorization
You can use the access token from configured Cognito User Pool to authenticate against REST endpoint. The JWT token can be retrieved from the Auth category.

import { fetchAuthSession } from 'aws-amplify/auth'

const session = await fetchAuthSession();
const token = session.tokens?.idToken
Then you need to set the Authorization header in the API category configuration. The following example shows how to set the Authorization header for all requests.

Amplify.configure(outputs, {
  API: {
    REST: {
      headers: async () => {
        return { Authorization: authToken };
      }
    }
  }
});
For more details on how to configure the API Gateway with the custom authorization, see this

Note related to use of Access Token or ID Token
The ID Token contains claims about the identity of the authenticated user such as name, email, and phone_number. On the Amplify Authentication category you can retrieve the Id Token using:

const session = await fetchAuthSession();
const token = session.tokens?.idToken
The Access Token contains scopes and groups and is used to grant access to authorized resources. This is a tutorial for enabling custom scopes. You can retrieve the Access Token using

const session = await fetchAuthSession();
const token = session.tokens?.accessToken
Custom Authorization Token
If you want to use a custom authorization token, you can set the token in the API category configuration. The custom authorization token will be applied to all requests.

Amplify.configure(outputs, {
  API: {
    REST: {
      headers: async () => {
        return { Authorization: customAuthToken };
      }
    }
  }
});
Setting Authorization Headers per Request
Alternatively, you can set the authorization headers per request. For example, if you want to use a custom header named Authorization for a specific REST request, you can set the following configuration:

async function updateItem() {
  await del({
    apiName: 'myRestApi',
    path: 'items/1',
    options: {
      headers: {
        Authorization: authToken
      }
    }
  }).response;
}

- Fetch data -
To invoke an endpoint, you need to set input object with required apiName option and optional headers, queryParams, and body options. API status code response > 299 are thrown as an ApiError instance. The error instance provides name and message properties parsed from the response.

GET requests
import { get } from 'aws-amplify/api';

async function getItem() {
  try {
    const restOperation = get({ 
      apiName: 'myRestApi',
      path: 'items' 
    });
    const response = await restOperation.response;
    console.log('GET call succeeded: ', response);
  } catch (error) {
    console.log('GET call failed: ', JSON.parse(error.response.body));
  }
}
Accessing response payload
You can consume the response payload by accessing the body property of the response object. Depending on the use case and the content type of the body, you can consume they payload in string, blob, or JSON.

// ...
const { body } = await restOperation.response;
// consume as a string:
const str = await body.text();
// OR consume as a blob:
const blob = await body.blob();
// OR consume as a JSON:
const json = await body.json();
You can not consume the response payload more than once.

Access HTTP response from errors
The REST API handler may throw an ApiError error instance. If the error is caused by an HTTP response with a non-2xx status code, the error instance will provide a response property. The response property contains following properties:

statusCode: HTTP status code
headers: HTTP response headers
body: HTTP response body as a string
The following example shows how to access the HTTP response from an ApiError instance, so that you can handle the error response from your REST API endpoint:

import { ApiError, get } from 'aws-amplify/api';

try {
  const restOperation = get({ 
    apiName: 'myRestApi',
    path: 'items' 
  });
  await restOperation.response;
} catch (error) {
  if (error instanceof ApiError) {
    if (error.response) {
      const { 
        statusCode, 
        headers, 
        body 
      } = error.response;
      console.error(`Received ${statusCode} error response with payload: ${body}`);
    }
    // Handle API errors not caused by HTTP response.
  }
  // Handle other errors.
}

- Post data - 
POST Requests
Send a POST request with a JSON body.

import { post } from 'aws-amplify/api';

async function postItem() {
  try {
    const restOperation = post({
      apiName: 'myRestApi',
      path: 'items',
      options: {
        body: {
          message: 'Mow the lawn'
        }
      }
    });

    const { body } = await restOperation.response;
    const response = await body.json();

    console.log('POST call succeeded');
    console.log(response);
  } catch (error) {
    console.log('POST call failed: ', JSON.parse(error.response.body));
  }
}

- Update data - 
PUT requests
To create or update a item via the API endpoint:

import { put } from 'aws-amplify/api';

async function updateItems() {
  try {
    const Item = { name: 'My first Item', message: 'Hello world!' };
    const restOperation = put({
      apiName: 'myRestApi',
      path: 'items/1',
      options: {
        body: Item
      }
    });
    const response = await restOperation.response;
    console.log('PUT call succeeded: ', response);
  } catch (error) {
    console.log('PUT call failed: ', JSON.parse(error.response.body));
  }

- Delete data -
DELETE requests
To delete an item via the API endpoint:

import { del } from 'aws-amplify/api';

async function deleteItem() {
  try {
    const restOperation = del({
      apiName: 'myRestApi',
      path: 'items/1'
    });
    await restOperation.response;
    console.log('DELETE call succeeded');
  } catch (e) {
    console.log('DELETE call failed: ', JSON.parse(e.response.body));
  }
}

- Test the REST API - 
Test the API from the terminal
If unauthenticated guest users have access to your REST API you can test it from the terminal using curl. curl is a command-line tool that lets you transfer data to and from a server using various protocols.

Curl is available in many distributions including Mac, Windows and Linux. Follow the install instructions in the docs.

Mac and Linux
Windows
GET method example
Terminal
curl <your-api-endpoint>/<your-api-stage>/items
POST method example
Terminal
curl -H "Content-Type: application/json" -d '{"name":"item-1"}' <your-api-endpoint>/<your-api-stage>/items
Test the API with API Gateway console
Let's test your new REST API using the route below with HTTP Method GET and path /items?limit=10 which includes a limit query string parameter.

Terminal
GET /items?limit=10
Sign in to the API Gateway console
Choose the myRestApi REST API
In the Resources pane, choose the method you want to test. Select GET right under /items.
Terminal
/                        
|_ /items               Main resource. Eg: /items  
  GET                   Methods  
  DELETE  
  PUT  
  POST  
  OPTIONS               Allow pre-flight requests in CORS by browser  
    |_ /{proxy+}         Proxy resource. Eg: /items/, /items/id, items/object/{id}  
    ANY                  Includes methods: DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT  
    OPTIONS              Allow pre-flight requests in CORS by browser
In the Method Execution pane, select TEST. Choose the GET method and add limit=10 to the query string {items} field.
Choose Test to run the test for GET /items?limit=10. The following information will be displayed: request, status, latency, response body, response headers and logs.
Terminal
Request
/items
Latency
111
Status
200
Response body
"Hello from myFunction!"
Response headers
{
  "Access-Control-Allow-Headers": "*",
  "Access-Control-Allow-Origin": "*",
  "X-Amzn-Trace-Id": "Root=1-661eee4b-f400fbebc6cfe65c3dadebcd;Parent=189f175e8de8d3a7;Sampled=0;lineage=c22c6ce1:0"
}
Log
Execution log for request 9bd9d8dc-95e2-494b-be1b-716393f83c49
Tue Apr 16 21:31:55 UTC 2024 : Starting execution for request: 9bd9d8dc-95e2-494b-be1b-716393f83c49
Tue Apr 16 21:31:55 UTC 2024 : HTTP Method: GET, Resource Path: /items
Tue Apr 16 21:31:55 UTC 2024 : Method request path: {}
Tue Apr 16 21:31:55 UTC 2024 : Method request query string: {}
Tue Apr 16 21:31:55 UTC 2024 : Method request headers: {}
Tue Apr 16 21:31:55 UTC 2024 : Method request body before transformations: 
Tue Apr 16 21:31:55 UTC 2024 : Endpoint request URI: https://lambda.us-east-1.amazonaws.com/2015-03-31/functions/arn:aws:lambda:us-east-1:[TRUNCATED:function:amplify-nextamplifygen2-y-testfunctionlambdaC407E8-zttuHxtL6x0V/invocations
Tue Apr 16 21:31:55 UTC 2024 : Endpoint request headers: {X-Amz-Date=20240416T213155Z, x-amzn-apigateway-api-id=bnyiitr69a, Accept=application/json, User-Agent=AmazonAPIGateway_bnyiitr69a, Host=lambda.us-east-1.amazonaws.com, X-Amz-Content-Sha256=246bd274ab578bc88286bd20a7371b0f08a1ec8cc2c8cacffb41e60430254c82, X-Amzn-Trace-Id=Root=1-661eee4b-f400fbebc6cfe65c3dadebcd, x-amzn-lambda-integration-tag=9bd9d8dc-95e2-494b-be1b-716393f83c49, Authorization=*********************************************************************************************************************************************************************************************************************************************************************************************************************************************bc00f2, X-Amz-Source-Arn=arn:aws:execute-api:us-east-1:[TRUNCATED]:bnyiitr69a/test-invoke-stage/GET/items, X-Amz-Security-Token= [TRUNCATED]
Tue Apr 16 21:31:55 UTC 2024 : Endpoint request body after transformations: {"resource":"/items","path":"/items","httpMethod":"GET","headers":null,"multiValueHeaders":null,"queryStringParameters":null,"multiValueQueryStringParameters":null,"pathParameters":null,"stageVariables":null,"requestContext":{"resourceId":"1m3yhu","resourcePath":"/items","httpMethod":"GET","extendedRequestId":"WVorzEQzoAMFubg=","requestTime":"16/Apr/2024:21:31:55 +0000","path":"/items","accountId":"[TRUNCATED]
","protocol":"HTTP/1.1","stage":"test-invoke-stage","domainPrefix":"testPrefix","requestTimeEpoch":1713303115234,"requestId":"9bd9d8dc-95e2-494b-be1b-716393f83c49","identity":{"cognitoIdentityPoolId":null,"cognitoIdentityId":null,"apiKey":"test-invoke-api-key","principalOrgId":null,"cognitoAuthenticationType":null,"userArn":"arn:aws:iam::[TRUNCATED]:user/ykethan","apiKeyId":"test-invoke-api-key-id","userAgent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36","accountId":"05364941472 [TRUNCATED]
Tue Apr 16 21:31:55 UTC 2024 : Sending request to https://lambda.us-east-1.amazonaws.com/2015-03-31/functions/arn:aws:lambda:us-east-1:[TRUNCATED]
:function:amplify-nextamplifygen2-y-testfunctionlambdaC407E8-zttuHxtL6x0V/invocations
Tue Apr 16 21:31:55 UTC 2024 : Received response. Status: 200, Integration latency: 108 ms
Tue Apr 16 21:31:55 UTC 2024 : Endpoint response headers: {Date=Tue, 16 Apr 2024 21:31:55 GMT, Content-Type=application/json, Content-Length=135, Connection=keep-alive, x-amzn-RequestId=67cfbdff-46cf-4355-8475-50a22e1f3234, x-amzn-Remapped-Content-Length=0, X-Amz-Executed-Version=$LATEST, X-Amzn-Trace-Id=root=1-661eee4b-f400fbebc6cfe65c3dadebcd;parent=189f175e8de8d3a7;sampled=0;lineage=c22c6ce1:0}
Tue Apr 16 21:31:55 UTC 2024 : Endpoint response body before transformations: {"statusCode":200,"headers":{"Access-Control-Allow-Origin":"*","Access-Control-Allow-Headers":"*"},"body":"\"Hello from myFunction!\""}
Tue Apr 16 21:31:55 UTC 2024 : Method response body after transformations: "Hello from myFunction!"
Tue Apr 16 21:31:55 UTC 2024 : Method response headers: {Access-Control-Allow-Origin=*, Access-Control-Allow-Headers=*, X-Amzn-Trace-Id=Root=1-661eee4b-f400fbebc6cfe65c3dadebcd;Parent=189f175e8de8d3a7;Sampled=0;lineage=c22c6ce1:0}
Tue Apr 16 21:31:55 UTC 2024 : Successfully completed execution
Tue Apr 16 21:31:55 UTC 2024 : Method completed with status: 200

- Use existing AWS resources -
Existing Amazon API Gateway resources can be used with the Amplify Libraries by calling Amplify.configure() with the API Gateway API name and options. Note, you will need to parse the Amplify configuration using parseAmplifyConfig before calling Amplify.configure(). The following example shows how to configure additional API Gateway resources to an existing Amplify application:

import { Amplify } from 'aws-amplify';
import { parseAmplifyConfig } from "aws-amplify/utils";
import outputs from '../amplify_outputs.json';

const amplifyConfig = parseAmplifyConfig(outputs);

// Add existing resource to the existing configuration.
Amplify.configure({
  ...amplifyConfig,
  API: {
    ...amplifyConfig.API,
    REST: {
      ...amplifyConfig.API?.REST,
      YourAPIName: {
        endpoint:
          'https://abcdefghij1234567890.execute-api.us-east-1.amazonaws.com/stageName',
        region: 'us-east-1' // Optional
      }
    }
  }
});
YourAPIName: Friendly name for the API
endpoint: The HTTPS endpoint of the API
region: AWS Region where the resources are provisioned. If not specified, the region will be inferred from the endpoint.
Note that before you can add an AWS resource to your application, the application must have the Amplify libraries installed. If you need to perform this step, see Install Amplify Libraries.

- API Reference -
del
DELETE HTTP request
Parameters
Option	Required	Type	Description
input	true	DeleteInput	
Input for DELETE operation
Throws
RestApiError
Returns
DeleteOperation
generateClient
Generates an API client that can work with models or raw GraphQL
Parameters
Option	Required	Type	Description
options	false	Options	
Throws
Error - Throws error when client cannot be generated due to configuration issues.
Returns
V6Client<T, Options>
get
GET HTTP request
Parameters
Option	Required	Type	Description
input	true	GetInput	
Input for GET operation
Throws
RestApiError
Returns
GetOperation
head
HEAD HTTP request
Parameters
Option	Required	Type	Description
input	true	HeadInput	
Input for HEAD operation
Throws
RestApiError
Returns
HeadOperation
isCancelError
Check if an error is caused by user calling cancel() in REST API.
Parameters
Option	Required	Type	Description
error	true	unknown	
The unknown exception to be checked.
Returns
CanceledError
patch
PATCH HTTP request
Parameters
Option	Required	Type	Description
input	true	PatchInput	
Input for PATCH operation
Throws
RestApiError
Returns
PatchOperation
post
POST HTTP request
Parameters
Option	Required	Type	Description
input	true	PostInput	
Input for POST operation
Throws
RestApiError
Returns
PostOperation
put
PUT HTTP request
Parameters
Option	Required	Type	Description
input	true	PutInput	
Input for PUT operation
Throws
RestApiError
Returns
PutOperation
Link Color Legend
Interface
Reference
Other

